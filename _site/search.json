[
  {
    "objectID": "projects/suncounty-customer-segmentation.html",
    "href": "projects/suncounty-customer-segmentation.html",
    "title": "âœˆï¸ Customer Segmentation for Sun Country Airlines",
    "section": "",
    "text": "Sun County Airlines, a small U.S.-based carrier, faces pressure from larger competitors. To compete effectively, the company needs a deep understanding of its customersâ€™ behavior, demographics, and travel preferences. This project uses unsupervised machine learning to segment customers into distinct groups for targeted marketing and product development."
  },
  {
    "objectID": "projects/suncounty-customer-segmentation.html#project-overview",
    "href": "projects/suncounty-customer-segmentation.html#project-overview",
    "title": "âœˆï¸ Customer Segmentation for Sun Country Airlines",
    "section": "",
    "text": "Sun County Airlines, a small U.S.-based carrier, faces pressure from larger competitors. To compete effectively, the company needs a deep understanding of its customersâ€™ behavior, demographics, and travel preferences. This project uses unsupervised machine learning to segment customers into distinct groups for targeted marketing and product development."
  },
  {
    "objectID": "projects/suncounty-customer-segmentation.html#objectives",
    "href": "projects/suncounty-customer-segmentation.html#objectives",
    "title": "âœˆï¸ Customer Segmentation for Sun Country Airlines",
    "section": "ğŸ¯ Objectives",
    "text": "ğŸ¯ Objectives\n\nCombine and clean customer datasets from Excel\nIdentify key features relevant to customer behavior\nApply KMeans Clustering to uncover unique customer groups\nProvide insights for strategic marketing decisions"
  },
  {
    "objectID": "projects/suncounty-customer-segmentation.html#data-features",
    "href": "projects/suncounty-customer-segmentation.html#data-features",
    "title": "âœˆï¸ Customer Segmentation for Sun Country Airlines",
    "section": "ğŸ—‚ï¸ Data & Features",
    "text": "ğŸ—‚ï¸ Data & Features\nWe used two spreadsheets from Sun County Airlines containing customer booking and demographic data. After merging the data using Pandas in Google Colab, we selected the following variables:\n\nBirthdate (Age)\nBooking Class & Channel\nBase Fare Paid\nMembership Status\nProduct Type\nRoute Details\nGroup Size\nBooking Lead Time (days_pre_booked)\nSeasonality Habits"
  },
  {
    "objectID": "projects/suncounty-customer-segmentation.html#methodology",
    "href": "projects/suncounty-customer-segmentation.html#methodology",
    "title": "âœˆï¸ Customer Segmentation for Sun Country Airlines",
    "section": "ğŸ” Methodology",
    "text": "ğŸ” Methodology\nWe used K-means clustering after standardizing numerical features and encoding categorical ones. The Elbow method suggested that k = 5 was optimal.\n\n\n\n\nğŸ§® Tools Used\n\nPython (Pandas, Scikit-learn)\nGoogle Colab\nMatplotlib & Seaborn\nExcel (raw input files)"
  },
  {
    "objectID": "projects/suncounty-customer-segmentation.html#key-segments-marketing-strategies",
    "href": "projects/suncounty-customer-segmentation.html#key-segments-marketing-strategies",
    "title": "âœˆï¸ Customer Segmentation for Sun Country Airlines",
    "section": "ğŸ“Š Key Segments & Marketing Strategies",
    "text": "ğŸ“Š Key Segments & Marketing Strategies\n\nCluster 0 â€“ Middle-Aged Standard Travelers\nMost frequently fly solo or in pairs, book standard class, and fly year-round.\n\n\n\n\nğŸ’¸ Marketing Strategies:\nâ€¢ Boost Visibility on Travel Platforms: Partner with OTAs and meta-search engines (e.g., Expedia, Skyscanner) to secure premium listings and improve flight discoverability.\nâ€¢ Manage Reviews Proactively: Encourage satisfied customers to leave reviews and respond to feedback to build trust and reputation.\nâ€¢ Offer Destination Bundles: Create travel packages for popular routes (e.g., BOS, DFW, LAX) by bundling flights with hotels or car rentals to attract deal-seeking travelers.\n\n\n\nCluster 1 â€“ Spring Squad Adventurers\nGroup travelers, often younger, travel mainly during spring with discounted fares.\n\n\n\n\nğŸ’¸ Marketing Strategies:\nâ€¢ Promote Spring Travel Deals: Offer group discounts, family packages, and senior travel incentives to appeal to larger group travelers.\nâ€¢ Bundle Group Packages: Partner with tour providers for all-inclusive deals that combine flights, hotels, and activities, optimized for multi-passenger bookings.\nâ€¢ Highlight Senior-Friendly Services: Emphasize amenities like priority boarding, wheelchair assistance, and personalized service.\nâ€¢ Drive Ufly Program Adoption: Incentivize loyalty signups with group booking bonuses, Q1 travel discounts, and senior-exclusive perks.\n\n\n\nCluster 2 â€“ Adventurous Young Budget Travelers\nYoungest cluster, budget-conscious, often use mobile booking channels.\n\n\n\n\nğŸ’¸ Marketing Strategies:\nâ€¢ Emphasize Comfort & Loyalty Benefits: Promote premium features like extra legroom, priority boarding, and UFly bonus points to appeal to their comfort-seeking preferences.\nâ€¢ Encourage Early Bookings: Launch Q4 campaigns like â€œFly Home for the Holidaysâ€ with early-bird discounts and flexible booking options to match their organized travel habits.\n\n\n\nCluster 3 â€“ Early Minneapolis Travelers\nFrequent early months flights, loyal customers from Minneapolis hub.\n\n\n\n\nğŸ’¸ Marketing Strategies:\nâ€¢ Time Campaigns Around Booking Habits: Launch promotions in early October and late December to align with their 61-day pre-booking window and holiday shopping season.\nâ€¢ Seasonal Messaging: Use timely slogans like â€œFly into the new year with this great offer!â€ to boost early-year travel bookings.\nâ€¢ Reward MSP Loyalty: Offer exclusive perks such as lounge access, Wi-Fi, or local discounts to retain Minneapolis-based flyers.\n\n\n\nCluster 4 â€“ Age-Blend Bargain Birds\nWide age range, price-driven, high sensitivity to sales and promotions.\n\n\n\n\nğŸ’¸ Marketing Strategies:\nâ€¢ Highlight Affordability: Emphasize budget-friendly travel, value-for-money bundles, and exclusive online deals to attract this cost-conscious, age-diverse group.\nâ€¢ Inclusive Messaging: Use language that resonates with all age groups, focusing on the benefits of early planning and direct booking.\nâ€¢ Offer Age-Based & Bundle Discounts: Promote senior savings, youth specials, and flight + accommodation/car rental bundles to increase appeal and direct engagement on the SCA website."
  },
  {
    "objectID": "projects/suncounty-customer-segmentation.html#conclusion",
    "href": "projects/suncounty-customer-segmentation.html#conclusion",
    "title": "âœˆï¸ Customer Segmentation for Sun Country Airlines",
    "section": "ğŸ§¾ Conclusion",
    "text": "ğŸ§¾ Conclusion\nThrough the application of K-means clustering, we successfully identified five distinct customer segments for Sun Country Airlines. These clusters revealed meaningful patterns in booking behavior, travel timing, group sizes, and fare preferences. By segmenting customers in this way, the airline can personalize its marketing efforts, develop more tailored promotions, and optimize resource allocation for customer engagement.\nThis segmentation lays the groundwork for targeted marketing strategies, such as offering mobile booking incentives for younger travelers or loyalty perks for high-value solo fliers.\nThe process also demonstrated the power of combining raw Excel data with Python-based clustering and visualization tools to drive business insight. With scalable implementation, this approach could become part of a broader customer intelligence system at Sun Country."
  },
  {
    "objectID": "projects/suncounty-customer-segmentation.html#future-enhancements",
    "href": "projects/suncounty-customer-segmentation.html#future-enhancements",
    "title": "âœˆï¸ Customer Segmentation for Sun Country Airlines",
    "section": "ğŸ”„ Future Enhancements",
    "text": "ğŸ”„ Future Enhancements\n\nIncorporate additional behavioral data such as frequency of bookings and flight satisfaction\nExplore supervised models for predicting customer loyalty or churn\nBuild a dashboard (Tableau or Streamlit) for real-time cluster monitoring"
  },
  {
    "objectID": "projects/suncounty-customer-segmentation.html#github-repository",
    "href": "projects/suncounty-customer-segmentation.html#github-repository",
    "title": "âœˆï¸ Customer Segmentation for Sun Country Airlines",
    "section": "ğŸ“ GitHub Repository",
    "text": "ğŸ“ GitHub Repository\nğŸ‘‰ View Code on GitHub"
  },
  {
    "objectID": "projects/netflix-recommendation.html",
    "href": "projects/netflix-recommendation.html",
    "title": "ğŸ¬ Netflix Recommendation System & Chatbot",
    "section": "",
    "text": "This project combines Natural Language Processing (NLP), content clustering, and chatbot integration to create a personalized movie and TV show recommendation system using a dataset of Netflix titles. The goal was to improve content discoverability by grouping shows based on themes and responding to user preferences through an interactive chatbot interface."
  },
  {
    "objectID": "projects/netflix-recommendation.html#project-overview",
    "href": "projects/netflix-recommendation.html#project-overview",
    "title": "ğŸ¬ Netflix Recommendation System & Chatbot",
    "section": "",
    "text": "This project combines Natural Language Processing (NLP), content clustering, and chatbot integration to create a personalized movie and TV show recommendation system using a dataset of Netflix titles. The goal was to improve content discoverability by grouping shows based on themes and responding to user preferences through an interactive chatbot interface."
  },
  {
    "objectID": "projects/netflix-recommendation.html#objectives",
    "href": "projects/netflix-recommendation.html#objectives",
    "title": "ğŸ¬ Netflix Recommendation System & Chatbot",
    "section": "ğŸ¯ Objectives",
    "text": "ğŸ¯ Objectives\n\nBuild a content-based recommendation system using NLP techniques.\nExtract core themes and patterns from Netflix descriptions using tokenization and TF-IDF.\nImplement unsupervised clustering to group similar content.\nDeploy a chatbot that responds to user inputs and delivers tailored suggestions.\nEvaluate genre prediction and chatbot relevance using both quantitative and qualitative feedback."
  },
  {
    "objectID": "projects/netflix-recommendation.html#data-preprocessing-nlp-techniques",
    "href": "projects/netflix-recommendation.html#data-preprocessing-nlp-techniques",
    "title": "ğŸ¬ Netflix Recommendation System & Chatbot",
    "section": "ğŸ§¹ Data Preprocessing & NLP Techniques",
    "text": "ğŸ§¹ Data Preprocessing & NLP Techniques\n\nMissing Values: Dataset was complete with no missing fields.\nAge Classification: Converted age ratings into numeric values for content filtering.\nTokenization & Lemmatization: Applied NLTK to clean and standardize text descriptions.\nTF-IDF Vectorization: Extracted key terms and themes from descriptions for clustering and recommendations."
  },
  {
    "objectID": "projects/netflix-recommendation.html#clustering-insights",
    "href": "projects/netflix-recommendation.html#clustering-insights",
    "title": "ğŸ¬ Netflix Recommendation System & Chatbot",
    "section": "ğŸ§  Clustering Insights",
    "text": "ğŸ§  Clustering Insights\nUsed K-means clustering to group titles into 6 thematic categories:\n\n\n\n\n\n\n\n\nCluster\nTheme\nExamples\n\n\n\n\n1\nBig City Life & Personal Discovery\nBlood & Water, Ganglands\n\n\n2\nLove & Life Journeys\nMidnight Mass, Je Suis Karl\n\n\n3\nComing-of-Age\nKota Factory, Dhanak\n\n\n4\nMusic & Art\nNailed It!, Rhyme & Reason\n\n\n5\nConnection & Discovery\nSankofa, Great British Baking Show\n\n\n6\nDocumentaries & Real-Life Stories\nDick Johnson Is Dead, Intrusion"
  },
  {
    "objectID": "projects/netflix-recommendation.html#recommendation-system",
    "href": "projects/netflix-recommendation.html#recommendation-system",
    "title": "ğŸ¬ Netflix Recommendation System & Chatbot",
    "section": "ğŸ¤– Recommendation System",
    "text": "ğŸ¤– Recommendation System\nThe system processes user inputs like genre, actor, type, sentiment, and keywords to generate TF-IDF-based vectors. It then calculates cosine similarity scores and ranks top 5 content matches.\nExample Input:\nGenre: Comedy | Actor: Tom | Sentiment: funny | Keyword: vacation\nTop Match: Jim Gaffigan: Cinco (similarity score: 0.253)"
  },
  {
    "objectID": "projects/netflix-recommendation.html#chatbot-integration",
    "href": "projects/netflix-recommendation.html#chatbot-integration",
    "title": "ğŸ¬ Netflix Recommendation System & Chatbot",
    "section": "ğŸ’¬ Chatbot Integration",
    "text": "ğŸ’¬ Chatbot Integration\nA chatbot interface was developed to make recommendations conversational and intuitive. It:\n\nAccepts free-text user inputs\nParses for preferences (e.g., actor, genre, tone)\nReturns top-matching Netflix titles with similarity scores\n\n\nExample: The chatbot asks for your favorite actor (Ama Qamata) and genre (Comedy), then returns matching stand-up specials and light-hearted shows."
  },
  {
    "objectID": "projects/netflix-recommendation.html#conclusion",
    "href": "projects/netflix-recommendation.html#conclusion",
    "title": "ğŸ¬ Netflix Recommendation System & Chatbot",
    "section": "ğŸ§¾ Conclusion",
    "text": "ğŸ§¾ Conclusion\nThis project demonstrates how NLP and conversational AI can enhance media recommendations. Through clustering, tokenization, and cosine similarity, we created a dynamic, personalized content discovery experience. The chatbot allows users to interact naturally, making movie and TV recommendations feel more human and tailored."
  },
  {
    "objectID": "projects/netflix-recommendation.html#limitations",
    "href": "projects/netflix-recommendation.html#limitations",
    "title": "ğŸ¬ Netflix Recommendation System & Chatbot",
    "section": "âš ï¸ Limitations",
    "text": "âš ï¸ Limitations\nWhile the system provides personalized recommendations and interactive chatbot responses, there are a few limitations:\n\nMulti-label Genre Complexity: Many titles belong to multiple genres, making it difficult for models to predict accurately from tokenized descriptions alone.\nText Ambiguity: Descriptions often contain vague or overlapping themes, reducing classification precision.\nModel Performance: Genre classification models (e.g., Logistic Regression, Naive Bayes) yielded relatively low F1 scores, indicating room for improvement in multi-label learning.\nUser Input Limitations: The chatbot depends on structured inputs (e.g., genre, sentiment), and may struggle with ambiguous or unrelated queries.\nCold Start Problem: The system does not incorporate real-time user behavior or preferences, limiting adaptability for new users.\n\nFuture enhancements could include deep learning models, multi-label classification improvements, and feedback-based recommendation tuning."
  },
  {
    "objectID": "projects/netflix-recommendation.html#github-repository",
    "href": "projects/netflix-recommendation.html#github-repository",
    "title": "ğŸ¬ Netflix Recommendation System & Chatbot",
    "section": "ğŸ“ GitHub Repository",
    "text": "ğŸ“ GitHub Repository\nğŸ‘‰ View Code on GitHub"
  },
  {
    "objectID": "projects/project.html",
    "href": "projects/project.html",
    "title": "My Portfolio",
    "section": "",
    "text": "Used K-means clustering to segment airline customers by behavior and demographics, enabling targeted marketing strategies for each group.\nTools: Python, Pandas, K-means, Seaborn, Google Colab\n\n\n\n\nA personalized movie and TV recommender with chatbot interaction, using NLP, clustering, and TF-IDF similarity scoring.\nTools: Python, NLTK, Scikit-learn, Cosine Similarity, TF-IDF\n\n\n\n\nUsed machine learning to identify at-risk banking customers and reduce silent attrition through data-driven retention strategies.\nTools: Python, Random Forest, SMOTE, Pandas, Scikit-learn\n\n\n\n\nAnalyzed Amazon product reviews using NLP and classification models to uncover customer sentiment patterns.\nTools: Python, TF-IDF, Logistic Regression, Naive Bayes\n\n\n\n\nExplored cuisine trends and modeled restaurant success using Yelp reviews and machine learning.\nTools: Python, Random Forest, KNN, Data Visualization"
  },
  {
    "objectID": "projects/project.html#projects",
    "href": "projects/project.html#projects",
    "title": "My Portfolio",
    "section": "",
    "text": "Used K-means clustering to segment airline customers by behavior and demographics, enabling targeted marketing strategies for each group.\nTools: Python, Pandas, K-means, Seaborn, Google Colab\n\n\n\n\nA personalized movie and TV recommender with chatbot interaction, using NLP, clustering, and TF-IDF similarity scoring.\nTools: Python, NLTK, Scikit-learn, Cosine Similarity, TF-IDF\n\n\n\n\nUsed machine learning to identify at-risk banking customers and reduce silent attrition through data-driven retention strategies.\nTools: Python, Random Forest, SMOTE, Pandas, Scikit-learn\n\n\n\n\nAnalyzed Amazon product reviews using NLP and classification models to uncover customer sentiment patterns.\nTools: Python, TF-IDF, Logistic Regression, Naive Bayes\n\n\n\n\nExplored cuisine trends and modeled restaurant success using Yelp reviews and machine learning.\nTools: Python, Random Forest, KNN, Data Visualization"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Home",
    "section": "",
    "text": "Hi! Iâ€™m Jessica Felicia, a Masterâ€™s student in Business Analytics at UCIâ€™s Paul Merage School of Business. Iâ€™m passionate about uncovering insights through marketing analytics, customer segmentation, and storytelling with data.\nWith a technical foundation and hands-on project experience, I love solving problems where data meets strategy â€” especially when it helps companies understand their customers better and grow smarter.\nğŸ” About Me"
  },
  {
    "objectID": "index.html#what-i-do",
    "href": "index.html#what-i-do",
    "title": "Home",
    "section": "",
    "text": "ğŸ“Š Build machine learning models to predict churn, segment customers, and uncover patterns\nğŸ§  Apply NLP and clustering to personalize experiences\nğŸ“ˆ Create dashboards and visual stories using Tableau & Python\nğŸ¤ Communicate findings that drive strategic decisions"
  },
  {
    "objectID": "index.html#explore",
    "href": "index.html#explore",
    "title": "Home",
    "section": "",
    "text": "ğŸ™‹ğŸ»â€â™€ï¸ About Me\nğŸš€ Projects"
  },
  {
    "objectID": "index.html#get-in-touch",
    "href": "index.html#get-in-touch",
    "title": "Home",
    "section": "",
    "text": "GitHub\nLinkedIn\nEmail"
  },
  {
    "objectID": "about.html#core-interests-strengths",
    "href": "about.html#core-interests-strengths",
    "title": "About Me",
    "section": "ğŸ“Œ Core Interests & Strengths",
    "text": "ğŸ“Œ Core Interests & Strengths\n\nData & Marketing Analytics\nCustomer Segmentation & Personalization\nData Visualization & Storytelling\nMachine Learning"
  },
  {
    "objectID": "about.html#technical-toolkit",
    "href": "about.html#technical-toolkit",
    "title": "About Me",
    "section": "ğŸ”§ Technical Toolkit",
    "text": "ğŸ”§ Technical Toolkit\n\nLanguages: Python, SQL, Java, R (basic)\nTools: Tableau, Excel, Google Colab, Git\nLibraries: Pandas, Scikit-learn, Matplotlib, Seaborn"
  },
  {
    "objectID": "about.html#goals-mindset",
    "href": "about.html#goals-mindset",
    "title": "About Me",
    "section": "ğŸ¯ Goals & Mindset",
    "text": "ğŸ¯ Goals & Mindset\nAs an aspiring data-driven professional, Iâ€™m always learning and eager to work on impactful projects that connect analytics to business value. Whether itâ€™s optimizing customer journeys, exploring behavior through clustering, or crafting dashboards for decision-makers, I aim to bring clarity through data.\nLetâ€™s connect and create something meaningful together!"
  },
  {
    "objectID": "projects/yelp-restaurant-ratings-analysis.html",
    "href": "projects/yelp-restaurant-ratings-analysis.html",
    "title": "ğŸ½ï¸ Yelp Restaurant Ratings Analysis",
    "section": "",
    "text": "This project analyzes Yelp restaurant data across California to identify key drivers behind customer ratings and provide actionable insights for small restaurant owners. Using machine learning models and data visualizations, the study reveals how cuisine type, location, and customer feedback influence restaurant success."
  },
  {
    "objectID": "projects/yelp-restaurant-ratings-analysis.html#project-overview",
    "href": "projects/yelp-restaurant-ratings-analysis.html#project-overview",
    "title": "ğŸ½ï¸ Yelp Restaurant Ratings Analysis",
    "section": "",
    "text": "This project analyzes Yelp restaurant data across California to identify key drivers behind customer ratings and provide actionable insights for small restaurant owners. Using machine learning models and data visualizations, the study reveals how cuisine type, location, and customer feedback influence restaurant success."
  },
  {
    "objectID": "projects/yelp-restaurant-ratings-analysis.html#objectives",
    "href": "projects/yelp-restaurant-ratings-analysis.html#objectives",
    "title": "ğŸ½ï¸ Yelp Restaurant Ratings Analysis",
    "section": "ğŸ¯ Objectives",
    "text": "ğŸ¯ Objectives\n\nIdentify popular cuisines and their rating patterns\nUnderstand the impact of location and number of reviews on ratings\nPredict restaurant success using classification models\nSupport small restaurant owners with data-driven strategies"
  },
  {
    "objectID": "projects/yelp-restaurant-ratings-analysis.html#data-methods",
    "href": "projects/yelp-restaurant-ratings-analysis.html#data-methods",
    "title": "ğŸ½ï¸ Yelp Restaurant Ratings Analysis",
    "section": "ğŸ—‚ï¸ Data & Methods",
    "text": "ğŸ—‚ï¸ Data & Methods\n\nData Source: Yelp data scraped via Python (2,177 restaurant entries)\nFeatures: Cuisine type, review count, price range, location (lat/lon), rating\nTools: Python, Pandas, Scikit-learn, Matplotlib\nModels Used: Decision Tree, K-Nearest Neighbor, Random Forest"
  },
  {
    "objectID": "projects/yelp-restaurant-ratings-analysis.html#key-insights",
    "href": "projects/yelp-restaurant-ratings-analysis.html#key-insights",
    "title": "ğŸ½ï¸ Yelp Restaurant Ratings Analysis",
    "section": "ğŸ“Š Key Insights",
    "text": "ğŸ“Š Key Insights\n\nTop Cuisines: Mexican, New American, and Italian are the most popular in California\nMexican Cuisine: Shows wide variability in ratings, indicating inconsistent experiences\nLocation & Review Count Matter: These were the most important predictors in rating performance"
  },
  {
    "objectID": "projects/yelp-restaurant-ratings-analysis.html#model-performance",
    "href": "projects/yelp-restaurant-ratings-analysis.html#model-performance",
    "title": "ğŸ½ï¸ Yelp Restaurant Ratings Analysis",
    "section": "ğŸ¤– Model Performance",
    "text": "ğŸ¤– Model Performance\n\n\n\nModel\nAccuracy\nF1 Score\nPrecision\nRecall\n\n\n\n\nDecision Tree\n61.7%\n0.72\n0.76\n0.69\n\n\nKNN (Tuned)\n64.1%\n0.77\n0.66\n0.93\n\n\nRandom Forest\n71.8%\n0.81\n0.74\n0.89\n\n\n\n\nRandom Forest performed best overall, identifying high-rated restaurants effectively.\nKNN excelled in recall, while Decision Tree had the fewest false positives."
  },
  {
    "objectID": "projects/yelp-restaurant-ratings-analysis.html#business-recommendations",
    "href": "projects/yelp-restaurant-ratings-analysis.html#business-recommendations",
    "title": "ğŸ½ï¸ Yelp Restaurant Ratings Analysis",
    "section": "ğŸ’¼ Business Recommendations",
    "text": "ğŸ’¼ Business Recommendations\n\nLocation Strategy: Choose areas with high traffic or market through social platforms to boost visibility in suburban areas.\nReview Management: Actively solicit and respond to reviews to enhance credibility and ratings.\nQuality Consistency: Standardize food and service quality, especially in cuisines with rating volatility like Mexican."
  },
  {
    "objectID": "projects/yelp-restaurant-ratings-analysis.html#conclusion",
    "href": "projects/yelp-restaurant-ratings-analysis.html#conclusion",
    "title": "ğŸ½ï¸ Yelp Restaurant Ratings Analysis",
    "section": "ğŸ§¾ Conclusion",
    "text": "ğŸ§¾ Conclusion\nThis project highlights how Yelp data can help small restaurants better understand customer behavior and optimize operations. By applying machine learning and analysis techniques, restaurant owners can gain strategic insights into location, cuisine impact, and review managementâ€”ultimately leading to better customer satisfaction and improved performance."
  },
  {
    "objectID": "projects/yelp-restaurant-ratings-analysis.html#github-repository",
    "href": "projects/yelp-restaurant-ratings-analysis.html#github-repository",
    "title": "ğŸ½ï¸ Yelp Restaurant Ratings Analysis",
    "section": "ğŸ“ GitHub Repository",
    "text": "ğŸ“ GitHub Repository\nğŸ‘‰ View Code on GitHub"
  },
  {
    "objectID": "projects/amazon-product-analysis.html",
    "href": "projects/amazon-product-analysis.html",
    "title": "ğŸ›ï¸ Amazon Product Reviews Sentiment Analysis",
    "section": "",
    "text": "This project analyzes customer sentiment from Amazon product reviews using natural language processing and machine learning techniques. The goal was to understand common customer opinions, how review length correlates with sentiment and rating, and to evaluate which models best classify review sentiment."
  },
  {
    "objectID": "projects/amazon-product-analysis.html#project-overview",
    "href": "projects/amazon-product-analysis.html#project-overview",
    "title": "ğŸ›ï¸ Amazon Product Reviews Sentiment Analysis",
    "section": "",
    "text": "This project analyzes customer sentiment from Amazon product reviews using natural language processing and machine learning techniques. The goal was to understand common customer opinions, how review length correlates with sentiment and rating, and to evaluate which models best classify review sentiment."
  },
  {
    "objectID": "projects/amazon-product-analysis.html#objectives",
    "href": "projects/amazon-product-analysis.html#objectives",
    "title": "ğŸ›ï¸ Amazon Product Reviews Sentiment Analysis",
    "section": "ğŸ¯ Objectives",
    "text": "ğŸ¯ Objectives\n\nIdentify common themes in positive vs.Â negative reviews\nExamine the relationship between review length, sentiment, and product rating\nEvaluate classification models for sentiment prediction"
  },
  {
    "objectID": "projects/amazon-product-analysis.html#data-methods",
    "href": "projects/amazon-product-analysis.html#data-methods",
    "title": "ğŸ›ï¸ Amazon Product Reviews Sentiment Analysis",
    "section": "ğŸ—‚ï¸ Data & Methods",
    "text": "ğŸ—‚ï¸ Data & Methods\n\nData: Amazon review dataset (1,465 reviews, 16 variables) from Kaggle\n\nText Preprocessing: Lowercasing, punctuation removal, stopword removal, tokenization\n\nFeature Engineering: TF-IDF with n-grams\n\nSentiment Labeling: VADER lexicon to classify sentiment as Positive, Neutral, or Negative\n\nModels Used: Logistic Regression, Random Forest, Support Vector Machine (SVM)"
  },
  {
    "objectID": "projects/amazon-product-analysis.html#key-insights",
    "href": "projects/amazon-product-analysis.html#key-insights",
    "title": "ğŸ›ï¸ Amazon Product Reviews Sentiment Analysis",
    "section": "ğŸ” Key Insights",
    "text": "ğŸ” Key Insights\n\nStrong Positive Bias: Majority of reviews were classified as positive; neutral and negative reviews were underrepresented.\nReview Length Matters: Longer reviews were slightly more likely to be positive, but the correlation was weak.\nThemes:\n\nPositive: â€œvalue for money,â€ â€œsound quality,â€ â€œlightweightâ€\nNegative: â€œpoor quality,â€ â€œcharging cable,â€ â€œdonâ€™t buyâ€"
  },
  {
    "objectID": "projects/amazon-product-analysis.html#model-performance",
    "href": "projects/amazon-product-analysis.html#model-performance",
    "title": "ğŸ›ï¸ Amazon Product Reviews Sentiment Analysis",
    "section": "ğŸ¤– Model Performance",
    "text": "ğŸ¤– Model Performance\n\n\n\n\n\n\n\n\n\nModel\nAccuracy\nStrengths\nWeaknesses\n\n\n\n\nLogistic Regression\n92%\nHigh recall for positive reviews\nPoor detection of neutral/negative\n\n\nRandom Forest\n91%\nRobust with positive sentiment\nWeak on negative (recall: 0.06)\n\n\nSVM\n92%\nBalanced and strong on positives\nMisclassified most negatives/neutral"
  },
  {
    "objectID": "projects/amazon-product-analysis.html#business-impact",
    "href": "projects/amazon-product-analysis.html#business-impact",
    "title": "ğŸ›ï¸ Amazon Product Reviews Sentiment Analysis",
    "section": "ğŸ’¡ Business Impact",
    "text": "ğŸ’¡ Business Impact\n\nProduct Improvement: Frequent negative terms flagged areas for design or quality fixes.\nMarketing: Highlighted strengths (e.g., sound quality) can inform ad copy and product positioning.\nCustomer Engagement: Long, detailed reviews suggest satisfaction; prompting longer feedback could yield richer insights."
  },
  {
    "objectID": "projects/amazon-product-analysis.html#limitations-future-enhancement",
    "href": "projects/amazon-product-analysis.html#limitations-future-enhancement",
    "title": "ğŸ›ï¸ Amazon Product Reviews Sentiment Analysis",
    "section": "ğŸ”„ Limitations & Future Enhancement",
    "text": "ğŸ”„ Limitations & Future Enhancement\n\nImbalanced dataset (mostly positive reviews) biased model performance\nModels underperformed on neutral and negative reviews\nFuture improvements: class balancing, hyperparameter tuning, and deep learning approaches"
  },
  {
    "objectID": "projects/amazon-product-analysis.html#conclusion",
    "href": "projects/amazon-product-analysis.html#conclusion",
    "title": "ğŸ›ï¸ Amazon Product Reviews Sentiment Analysis",
    "section": "ğŸ§¾ Conclusion",
    "text": "ğŸ§¾ Conclusion\nThis project demonstrated how sentiment analysis can uncover key customer insights from product reviews. Despite model limitations with neutral and negative classification, positive feedback was effectively captured. Further model tuning and data balancing could enhance accuracy across all sentiment categories, supporting more informed business decisions."
  },
  {
    "objectID": "projects/amazon-product-analysis.html#github-repository",
    "href": "projects/amazon-product-analysis.html#github-repository",
    "title": "ğŸ›ï¸ Amazon Product Reviews Sentiment Analysis",
    "section": "ğŸ“ GitHub Repository",
    "text": "ğŸ“ GitHub Repository\nğŸ‘‰ View Code on GitHub"
  },
  {
    "objectID": "projects/bank-churn-prediction.html",
    "href": "projects/bank-churn-prediction.html",
    "title": "ğŸ¦ Predicting Bank Customer Churn",
    "section": "",
    "text": "As digital banking continues to grow, identifying and preventing customer churnâ€”especially silent attritionâ€”has become critical for banks. This project applied multiple machine learning models to predict customer churn and uncover key behavioral and demographic risk factors to enable proactive retention strategies."
  },
  {
    "objectID": "projects/bank-churn-prediction.html#project-overview",
    "href": "projects/bank-churn-prediction.html#project-overview",
    "title": "ğŸ¦ Predicting Bank Customer Churn",
    "section": "",
    "text": "As digital banking continues to grow, identifying and preventing customer churnâ€”especially silent attritionâ€”has become critical for banks. This project applied multiple machine learning models to predict customer churn and uncover key behavioral and demographic risk factors to enable proactive retention strategies."
  },
  {
    "objectID": "projects/bank-churn-prediction.html#objectives",
    "href": "projects/bank-churn-prediction.html#objectives",
    "title": "ğŸ¦ Predicting Bank Customer Churn",
    "section": "ğŸ¯ Objectives",
    "text": "ğŸ¯ Objectives\n\nVisualize current customer behavior and demographics\nBuild predictive models to classify customers at risk of churn\nIdentify actionable drivers of attrition for strategic intervention"
  },
  {
    "objectID": "projects/bank-churn-prediction.html#data-methods",
    "href": "projects/bank-churn-prediction.html#data-methods",
    "title": "ğŸ¦ Predicting Bank Customer Churn",
    "section": "ğŸ—‚ï¸ Data & Methods",
    "text": "ğŸ—‚ï¸ Data & Methods\n\nData: 10,000 records from a European bank (Kaggle)\nFeatures: Age, Gender, Geography, Balance, Tenure, Products, Activity, etc.\nTools: Python, Scikit-learn, SMOTE, PCA\nModels Used: Logistic Regression, Gaussian Naive Bayes, Decision Tree, Random Forest"
  },
  {
    "objectID": "projects/bank-churn-prediction.html#model-performance-summary",
    "href": "projects/bank-churn-prediction.html#model-performance-summary",
    "title": "ğŸ¦ Predicting Bank Customer Churn",
    "section": "ğŸ¤– Model Performance Summary",
    "text": "ğŸ¤– Model Performance Summary\n\n\n\n\n\n\n\n\n\n\nModel\nAccuracy\nPrecision (Churn)\nRecall (Churn)\nF1-Score (Churn)\n\n\n\n\nLogistic Regression\n80.9%\n60%\n19% â†’ 77% (with SMOTE)\n29% â†’ 77%\n\n\nNaive Bayes\n78.7%\n36% â†’ 70%\n6% â†’ 74%\n11% â†’ 72%\n\n\nDecision Tree\n85% (after pruning)\n80%\n37%\n51%\n\n\nRandom Forest\n86% â†’ 84% (with SMOTE)\n76% â†’ 58%\n47% â†’ 64%\n58% â†’ 61%\n\n\n\n\nâœ… Random Forest with SMOTE achieved the best balance for identifying churners, despite a slight drop in precision."
  },
  {
    "objectID": "projects/bank-churn-prediction.html#feature-importance-logistic-regression",
    "href": "projects/bank-churn-prediction.html#feature-importance-logistic-regression",
    "title": "ğŸ¦ Predicting Bank Customer Churn",
    "section": "ğŸ” Feature Importance â€“ Logistic Regression",
    "text": "ğŸ” Feature Importance â€“ Logistic Regression\n\n\n\nThis chart displays the standardized coefficients from the Logistic Regression model, highlighting which features most influence customer churn predictions.\n\nAge and Balance are the strongest positive predictors of churn â€” older customers and those with higher balances are more likely to leave.\nIsActiveMember has the strongest negative coefficient, indicating active users are significantly less likely to churn.\nOther features like Geography, Estimated Salary, and Gender show smaller but still notable impacts.\n\nThese insights help the bank prioritize retention efforts around customer age, engagement, and account value."
  },
  {
    "objectID": "projects/bank-churn-prediction.html#key-insights",
    "href": "projects/bank-churn-prediction.html#key-insights",
    "title": "ğŸ¦ Predicting Bank Customer Churn",
    "section": "ğŸ” Key Insights",
    "text": "ğŸ” Key Insights\n\nDemographics: Older customers are more likely to churn; geographic differences (France/Germany higher than Spain).\nBehavioral Indicators:\n\nInactive members have a 27% churn rate vs.Â 14% for active.\nCustomers with fewer products are more likely to churn.\n\nTop Predictive Features: Age, Number of Products, Balance, IsActiveMember."
  },
  {
    "objectID": "projects/bank-churn-prediction.html#strategic-recommendations",
    "href": "projects/bank-churn-prediction.html#strategic-recommendations",
    "title": "ğŸ¦ Predicting Bank Customer Churn",
    "section": "ğŸ’¡ Strategic Recommendations",
    "text": "ğŸ’¡ Strategic Recommendations\n\nEngagement: Target inactive users and those with only 1â€“2 products via cross-sell campaigns.\nPersonalization: Design region-specific and age-aware outreach strategies.\nRetention: Monitor older customers and offer digital support to reduce disengagement.\nModel Use: Deploy Random Forest with SMOTE to support real-time churn alerts."
  },
  {
    "objectID": "projects/bank-churn-prediction.html#conclusion",
    "href": "projects/bank-churn-prediction.html#conclusion",
    "title": "ğŸ¦ Predicting Bank Customer Churn",
    "section": "ğŸ§¾ Conclusion",
    "text": "ğŸ§¾ Conclusion\nThis project shows how machine learning can effectively identify churn risk using behavioral and demographic signals. With Random Forest as the most effective model, supported by SMOTE balancing, banks can proactively reduce attrition by targeting the right customers at the right time. The insights gained can guide smarter customer engagement and long-term profitability."
  },
  {
    "objectID": "projects/bank-churn-prediction.html#github-repository",
    "href": "projects/bank-churn-prediction.html#github-repository",
    "title": "ğŸ¦ Predicting Bank Customer Churn",
    "section": "ğŸ“ GitHub Repository",
    "text": "ğŸ“ GitHub Repository\nğŸ‘‰ View Code on GitHub"
  },
  {
    "objectID": "projects/Customer Segmentation/suncounty-customer-segmentation.html",
    "href": "projects/Customer Segmentation/suncounty-customer-segmentation.html",
    "title": "âœˆï¸ Customer Segmentation for Sun Country Airlines",
    "section": "",
    "text": "Sun County Airlines, a small U.S.-based carrier, faces pressure from larger competitors. To compete effectively, the company needs a deep understanding of its customersâ€™ behavior, demographics, and travel preferences. This project uses unsupervised machine learning to segment customers into distinct groups for targeted marketing and product development."
  },
  {
    "objectID": "projects/Customer Segmentation/suncounty-customer-segmentation.html#project-overview",
    "href": "projects/Customer Segmentation/suncounty-customer-segmentation.html#project-overview",
    "title": "âœˆï¸ Customer Segmentation for Sun Country Airlines",
    "section": "",
    "text": "Sun County Airlines, a small U.S.-based carrier, faces pressure from larger competitors. To compete effectively, the company needs a deep understanding of its customersâ€™ behavior, demographics, and travel preferences. This project uses unsupervised machine learning to segment customers into distinct groups for targeted marketing and product development."
  },
  {
    "objectID": "projects/Customer Segmentation/suncounty-customer-segmentation.html#objectives",
    "href": "projects/Customer Segmentation/suncounty-customer-segmentation.html#objectives",
    "title": "âœˆï¸ Customer Segmentation for Sun Country Airlines",
    "section": "ğŸ¯ Objectives",
    "text": "ğŸ¯ Objectives\n\nCombine and clean customer datasets from Excel\nIdentify key features relevant to customer behavior\nApply KMeans Clustering to uncover unique customer groups\nProvide insights for strategic marketing decisions"
  },
  {
    "objectID": "projects/Customer Segmentation/suncounty-customer-segmentation.html#data-features",
    "href": "projects/Customer Segmentation/suncounty-customer-segmentation.html#data-features",
    "title": "âœˆï¸ Customer Segmentation for Sun Country Airlines",
    "section": "ğŸ—‚ï¸ Data & Features",
    "text": "ğŸ—‚ï¸ Data & Features\nWe used two spreadsheets from Sun County Airlines containing customer booking and demographic data. After merging the data using Pandas in Google Colab, we selected the following variables:\n\nBirthdate (Age)\nBooking Class & Channel\nBase Fare Paid\nMembership Status\nProduct Type\nRoute Details\nGroup Size\nBooking Lead Time (days_pre_booked)\nSeasonality Habits"
  },
  {
    "objectID": "projects/Customer Segmentation/suncounty-customer-segmentation.html#methodology",
    "href": "projects/Customer Segmentation/suncounty-customer-segmentation.html#methodology",
    "title": "âœˆï¸ Customer Segmentation for Sun Country Airlines",
    "section": "ğŸ” Methodology",
    "text": "ğŸ” Methodology\nWe used K-means clustering after standardizing numerical features and encoding categorical ones. The Elbow method suggested that k = 5 was optimal.\n\n\n\n\nğŸ§® Tools Used\n\nPython (Pandas, Scikit-learn)\nGoogle Colab\nMatplotlib & Seaborn\nExcel (raw input files)"
  },
  {
    "objectID": "projects/Customer Segmentation/suncounty-customer-segmentation.html#key-segments-marketing-strategies",
    "href": "projects/Customer Segmentation/suncounty-customer-segmentation.html#key-segments-marketing-strategies",
    "title": "âœˆï¸ Customer Segmentation for Sun Country Airlines",
    "section": "ğŸ“Š Key Segments & Marketing Strategies",
    "text": "ğŸ“Š Key Segments & Marketing Strategies\n\nCluster 0 â€“ Middle-Aged Standard Travelers\nMost frequently fly solo or in pairs, book standard class, and fly year-round.\n\n\n\n\nğŸ’¸ Marketing Strategies:\nâ€¢ Boost Visibility on Travel Platforms: Partner with OTAs and meta-search engines (e.g., Expedia, Skyscanner) to secure premium listings and improve flight discoverability.\nâ€¢ Manage Reviews Proactively: Encourage satisfied customers to leave reviews and respond to feedback to build trust and reputation.\nâ€¢ Offer Destination Bundles: Create travel packages for popular routes (e.g., BOS, DFW, LAX) by bundling flights with hotels or car rentals to attract deal-seeking travelers.\n\n\n\nCluster 1 â€“ Spring Squad Adventurers\nGroup travelers, often younger, travel mainly during spring with discounted fares.\n\n\n\n\nğŸ’¸ Marketing Strategies:\nâ€¢ Promote Spring Travel Deals: Offer group discounts, family packages, and senior travel incentives to appeal to larger group travelers.\nâ€¢ Bundle Group Packages: Partner with tour providers for all-inclusive deals that combine flights, hotels, and activities, optimized for multi-passenger bookings.\nâ€¢ Highlight Senior-Friendly Services: Emphasize amenities like priority boarding, wheelchair assistance, and personalized service.\nâ€¢ Drive Ufly Program Adoption: Incentivize loyalty signups with group booking bonuses, Q1 travel discounts, and senior-exclusive perks.\n\n\n\nCluster 2 â€“ Adventurous Young Budget Travelers\nYoungest cluster, budget-conscious, often use mobile booking channels.\n\n\n\n\nğŸ’¸ Marketing Strategies:\nâ€¢ Emphasize Comfort & Loyalty Benefits: Promote premium features like extra legroom, priority boarding, and UFly bonus points to appeal to their comfort-seeking preferences.\nâ€¢ Encourage Early Bookings: Launch Q4 campaigns like â€œFly Home for the Holidaysâ€ with early-bird discounts and flexible booking options to match their organized travel habits.\n\n\n\nCluster 3 â€“ Early Minneapolis Travelers\nFrequent early months flights, loyal customers from Minneapolis hub.\n\n\n\n\nğŸ’¸ Marketing Strategies:\nâ€¢ Time Campaigns Around Booking Habits: Launch promotions in early October and late December to align with their 61-day pre-booking window and holiday shopping season.\nâ€¢ Seasonal Messaging: Use timely slogans like â€œFly into the new year with this great offer!â€ to boost early-year travel bookings.\nâ€¢ Reward MSP Loyalty: Offer exclusive perks such as lounge access, Wi-Fi, or local discounts to retain Minneapolis-based flyers.\n\n\n\nCluster 4 â€“ Age-Blend Bargain Birds\nWide age range, price-driven, high sensitivity to sales and promotions.\n\n\n\n\nğŸ’¸ Marketing Strategies:\nâ€¢ Highlight Affordability: Emphasize budget-friendly travel, value-for-money bundles, and exclusive online deals to attract this cost-conscious, age-diverse group.\nâ€¢ Inclusive Messaging: Use language that resonates with all age groups, focusing on the benefits of early planning and direct booking.\nâ€¢ Offer Age-Based & Bundle Discounts: Promote senior savings, youth specials, and flight + accommodation/car rental bundles to increase appeal and direct engagement on the SCA website."
  },
  {
    "objectID": "projects/Customer Segmentation/suncounty-customer-segmentation.html#conclusion",
    "href": "projects/Customer Segmentation/suncounty-customer-segmentation.html#conclusion",
    "title": "âœˆï¸ Customer Segmentation for Sun Country Airlines",
    "section": "ğŸ§¾ Conclusion",
    "text": "ğŸ§¾ Conclusion\nThrough the application of K-means clustering, we successfully identified five distinct customer segments for Sun Country Airlines. These clusters revealed meaningful patterns in booking behavior, travel timing, group sizes, and fare preferences. By segmenting customers in this way, the airline can personalize its marketing efforts, develop more tailored promotions, and optimize resource allocation for customer engagement.\nThis segmentation lays the groundwork for targeted marketing strategies, such as offering mobile booking incentives for younger travelers or loyalty perks for high-value solo fliers.\nThe process also demonstrated the power of combining raw Excel data with Python-based clustering and visualization tools to drive business insight. With scalable implementation, this approach could become part of a broader customer intelligence system at Sun Country."
  },
  {
    "objectID": "projects/Customer Segmentation/suncounty-customer-segmentation.html#future-enhancements",
    "href": "projects/Customer Segmentation/suncounty-customer-segmentation.html#future-enhancements",
    "title": "âœˆï¸ Customer Segmentation for Sun Country Airlines",
    "section": "ğŸ”„ Future Enhancements",
    "text": "ğŸ”„ Future Enhancements\n\nIncorporate additional behavioral data such as frequency of bookings and flight satisfaction\nExplore supervised models for predicting customer loyalty or churn\nBuild a dashboard (Tableau or Streamlit) for real-time cluster monitoring"
  },
  {
    "objectID": "projects/Customer Segmentation/suncounty-customer-segmentation.html#github-repository",
    "href": "projects/Customer Segmentation/suncounty-customer-segmentation.html#github-repository",
    "title": "âœˆï¸ Customer Segmentation for Sun Country Airlines",
    "section": "ğŸ“ GitHub Repository",
    "text": "ğŸ“ GitHub Repository\nğŸ‘‰ View Code on GitHub"
  },
  {
    "objectID": "projects/Yelp Restaurant Rating /Yelp Analysis.html",
    "href": "projects/Yelp Restaurant Rating /Yelp Analysis.html",
    "title": "My Portfolio",
    "section": "",
    "text": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\n#Read the excel dataset\nYelp = pd.read_excel('/content/data programming project - yelp.xlsx')\n\n\n# Overview of the dataset\n#print(Yelp.head())\nprint(Yelp.info())\n#print(Yelp.describe())\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 2176 entries, 0 to 2175\nData columns (total 36 columns):\n #   Column                          Non-Null Count  Dtype  \n---  ------                          --------------  -----  \n 0   Name                            2176 non-null   object \n 1   Phone                           2073 non-null   object \n 2   Address                         2117 non-null   object \n 3   Email                           982 non-null    object \n 4   Website                         1683 non-null   object \n 5   ServiceArea                     12 non-null     object \n 6   Instagram                       1106 non-null   object \n 7   Facebook                        1046 non-null   object \n 8   Twitter                         268 non-null    object \n 9   Linkedin                        70 non-null     object \n 10  Youtube                         108 non-null    object \n 11  BusinessUrl                     2176 non-null   object \n 12  Rating                          2176 non-null   float64\n 13  ReviewCount                     2176 non-null   int64  \n 14  PriceRange                      1586 non-null   object \n 15  Longitude                       2176 non-null   float64\n 16  Latitude                        2176 non-null   float64\n 17  Alias                           2176 non-null   object \n 18  BizId                           2176 non-null   object \n 19  BusinessSectionUrls_open_hours  2176 non-null   object \n 20  BusinessSectionUrls_reviews     2176 non-null   object \n 21  Categories_0_title              2176 non-null   object \n 22  Categories_0_url                2176 non-null   object \n 23  Categories_1_title              1603 non-null   object \n 24  Categories_1_url                1603 non-null   object \n 25  Categories_2_title              1032 non-null   object \n 26  Categories_2_url                1032 non-null   object \n 27  FormattedAddress                0 non-null      float64\n 28  IsAd                            2176 non-null   bool   \n 29  Neighborhoods_0                 846 non-null    object \n 30  Open_time                       0 non-null      float64\n 31  ParentBusiness                  0 non-null      float64\n 32  Ranking                         2176 non-null   int64  \n 33  RenderAdInfo                    2176 non-null   bool   \n 34  ServicePricing                  0 non-null      float64\n 35  Snippet                         2150 non-null   object \ndtypes: bool(2), float64(7), int64(2), object(25)\nmemory usage: 582.4+ KB\nNone\n\n\n\n# Drop columns with more than 50% missing values as well as columns that are redundant\nYelp = Yelp.dropna(thresh=Yelp.shape[0] * 0.5, axis=1)\nYelp = Yelp.drop(columns=['Website','BusinessUrl','Alias','BizId','BusinessSectionUrls_open_hours','BusinessSectionUrls_reviews','IsAd','RenderAdInfo','Categories_0_url','Categories_1_title', 'Categories_1_url'])\n\n\nprint(Yelp.info(10))\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 2176 entries, 0 to 2175\nData columns (total 12 columns):\n #   Column              Non-Null Count  Dtype  \n---  ------              --------------  -----  \n 0   Name                2176 non-null   object \n 1   Phone               2073 non-null   object \n 2   Address             2117 non-null   object \n 3   Instagram           1106 non-null   object \n 4   Rating              2176 non-null   float64\n 5   ReviewCount         2176 non-null   int64  \n 6   PriceRange          1586 non-null   object \n 7   Longitude           2176 non-null   float64\n 8   Latitude            2176 non-null   float64\n 9   Categories_0_title  2176 non-null   object \n 10  Ranking             2176 non-null   int64  \n 11  Snippet             2150 non-null   object \ndtypes: float64(3), int64(2), object(7)\nmemory usage: 204.1+ KB\nNone\n\n\n\nprint(\"Number of rows (datasets) in the data:\", len(Yelp))\n\nNumber of rows (datasets) in the data: 2176\n\n\n\n#Count missing values in each categories\nmissing_per_column = Yelp.isnull().sum()\nprint(missing_per_column)\n\nName                     0\nPhone                  103\nAddress                 59\nInstagram             1070\nRating                   0\nReviewCount              0\nPriceRange             590\nLongitude                0\nLatitude                 0\nCategories_0_title       0\nRanking                  0\nSnippet                 26\ndtype: int64\n\n\n\n#We will use only Categories 0 title as ou main cuisine type as it has no missing values and correctly represent the true cuisine type of the restaurant\n#Find the most popular cuisine type in the dataset (Top 10)\nfood_category = Yelp['Categories_0_title'].value_counts()\ntop_10 = food_category.head(10)\nprint(top_10)\nplt.figure(figsize=(8, 4))\nsns.barplot(x=top_10.index,y=top_10.values,palette='pastel')\nplt.xlabel('Category')\nplt.ylabel('Count')\nplt.title('Top 10 Cuisine Type by Count')\nplt.xticks(rotation=45)\nplt.show()\n\nCategories_0_title\nMexican          161\nNew American     110\nItalian          108\nKorean            95\nSeafood           93\nJapanese          90\nPizza             80\nMediterranean     62\nChinese           59\nThai              58\nName: count, dtype: int64\n\n\nFutureWarning: \n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n\n  sns.barplot(x=top_10.index,y=top_10.values,palette='pastel')\n\n\n\n\n\n\n\n\n\n\n#Scatter plot to see the correlation between number of reviews and star ratings\nplt.figure(figsize=(8, 4))\nplt.scatter(Yelp['ReviewCount'], Yelp['Rating'], alpha=0.3, color='blue')\nplt.xlabel('Number of Reviews')\nplt.ylabel('Star Ratings')\nplt.title('Scatter Plot: Star Ratings vs. Number of Reviews')\nplt.show()\n\n\n\n\n\n\n\n\n\n# Calculate the correlation between 'ReviewCount' and 'Rating_numeric'\ncorrelation = Yelp['ReviewCount'].corr(Yelp['Rating'])\nprint(f\"Correlation between ReviewCount and Rating: {correlation}\")\n\nCorrelation between ReviewCount and Rating: 0.003222962567526092\n\n\n\n# boxplot to show rating distribution by cuisine types\ntop_categories = Yelp['Categories_0_title'].value_counts().head(10).index\nfiltered_data = Yelp[Yelp['Categories_0_title'].isin(top_categories)]\n\nplt.figure(figsize=(10, 6))\nsns.boxplot(x='Categories_0_title', y='Rating', data=filtered_data, palette=\"Set3\",order=top_categories)\n\nplt.xticks(rotation=45, ha='right')\nplt.title('Rating Distributions (Top 10 Cuisine Types)', fontsize=16)\nplt.xlabel('Cuisine Type', fontsize=14)\nplt.ylabel('Ratings', fontsize=14)\n\nplt.tight_layout()\nplt.show()\n\nFutureWarning: \n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n\n  sns.boxplot(x='Categories_0_title', y='Rating', data=filtered_data, palette=\"Set3\",order=top_categories)\n\n\n\n\n\n\n\n\n\n\n#Correlation between restaurant ranking and star ratings\ncorrelation = Yelp['Ranking'].corr(Yelp['Rating'])\nprint(\"Correlation between Review Count and Rating:\", correlation)\n\nCorrelation between Review Count and Rating: -0.12806450476948608\n\n\n\n#Most prevalent positive and negative words from the cuisine type\nfrom textblob import TextBlob\nfrom wordcloud import WordCloud\nimport matplotlib.pyplot as plt\n\n# Filter data for a specific cuisine type\ncuisine_type = \"Mexican\"\nfiltered_data = Yelp[Yelp['Categories_0_title'] == cuisine_type].copy()\n\n# Function to determine sentiment polarity\ndef get_sentiment(text):\n    try:\n        analysis = TextBlob(str(text))  # Ensure text is converted to a string\n        return \"Positive\" if analysis.sentiment.polarity &gt; 0 else \"Negative\"\n    except:\n        return \"Neutral\"\n\n# Drop NaN values in 'Snippet' and apply sentiment analysis\nfiltered_data = filtered_data.dropna(subset=['Snippet'])\nfiltered_data['Sentiment'] = filtered_data['Snippet'].apply(get_sentiment)\n\n# Combine positive and negative review snippets\npositive_reviews = \" \".join(filtered_data[filtered_data['Sentiment'] == \"Positive\"]['Snippet'])\nnegative_reviews = \" \".join(filtered_data[filtered_data['Sentiment'] == \"Negative\"]['Snippet'])\n\n# Generate word clouds\npositive_wordcloud = WordCloud(width=800, height=400, background_color='white', colormap='Blues').generate(positive_reviews)\nnegative_wordcloud = WordCloud(width=800, height=400, background_color='white', colormap='Reds').generate(negative_reviews)\n\n# Plot the word clouds\nplt.figure(figsize=(16, 8))\n\n# Positive word cloud\nplt.subplot(1, 2, 1)\nplt.imshow(positive_wordcloud, interpolation='bilinear')\nplt.title(f\"Positive Reviews Word Cloud ({cuisine_type})\", fontsize=16)\nplt.axis('off')\n\n# Negative word cloud\nplt.subplot(1, 2, 2)\nplt.imshow(negative_wordcloud, interpolation='bilinear')\nplt.title(f\"Negative Reviews Word Cloud ({cuisine_type})\", fontsize=16)\nplt.axis('off')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n#Most prevalent positive and negative words from the cuisine type\nfrom textblob import TextBlob\nfrom wordcloud import WordCloud\nimport matplotlib.pyplot as plt\n\n# Filter data for a specific cuisine type\ncuisine_type = \"Chinese\"\nfiltered_data = Yelp[Yelp['Categories_0_title'] == cuisine_type].copy()\n\n# Function to determine sentiment polarity\ndef get_sentiment(text):\n    try:\n        analysis = TextBlob(str(text))  # Ensure text is converted to a string\n        return \"Positive\" if analysis.sentiment.polarity &gt; 0 else \"Negative\"\n    except:\n        return \"Neutral\"\n\n# Drop NaN values in 'Snippet' and apply sentiment analysis\nfiltered_data = filtered_data.dropna(subset=['Snippet'])\nfiltered_data['Sentiment'] = filtered_data['Snippet'].apply(get_sentiment)\n\n# Combine positive and negative review snippets\npositive_reviews = \" \".join(filtered_data[filtered_data['Sentiment'] == \"Positive\"]['Snippet'])\nnegative_reviews = \" \".join(filtered_data[filtered_data['Sentiment'] == \"Negative\"]['Snippet'])\n\n# Generate word clouds\npositive_wordcloud = WordCloud(width=800, height=400, background_color='white', colormap='Blues').generate(positive_reviews)\nnegative_wordcloud = WordCloud(width=800, height=400, background_color='white', colormap='Reds').generate(negative_reviews)\n\n# Plot the word clouds\nplt.figure(figsize=(16, 8))\n\n# Positive word cloud\nplt.subplot(1, 2, 1)\nplt.imshow(positive_wordcloud, interpolation='bilinear')\nplt.title(f\"Positive Reviews Word Cloud ({cuisine_type})\", fontsize=16)\nplt.axis('off')\n\n# Negative word cloud\nplt.subplot(1, 2, 2)\nplt.imshow(negative_wordcloud, interpolation='bilinear')\nplt.title(f\"Negative Reviews Word Cloud ({cuisine_type})\", fontsize=16)\nplt.axis('off')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n#Most prevalent positive and negative words from the cuisine type\nfrom textblob import TextBlob\nfrom wordcloud import WordCloud\nimport matplotlib.pyplot as plt\n\n# Filter data for a specific cuisine type\ncuisine_type = \"Italian\"\nfiltered_data = Yelp[Yelp['Categories_0_title'] == cuisine_type].copy()\n\n# Function to determine sentiment polarity\ndef get_sentiment(text):\n    try:\n        analysis = TextBlob(str(text))  # Ensure text is converted to a string\n        return \"Positive\" if analysis.sentiment.polarity &gt; 0 else \"Negative\"\n    except:\n        return \"Neutral\"\n\n# Drop NaN values in 'Snippet' and apply sentiment analysis\nfiltered_data = filtered_data.dropna(subset=['Snippet'])\nfiltered_data['Sentiment'] = filtered_data['Snippet'].apply(get_sentiment)\n\n# Combine positive and negative review snippets\npositive_reviews = \" \".join(filtered_data[filtered_data['Sentiment'] == \"Positive\"]['Snippet'])\nnegative_reviews = \" \".join(filtered_data[filtered_data['Sentiment'] == \"Negative\"]['Snippet'])\n\n# Generate word clouds\npositive_wordcloud = WordCloud(width=800, height=400, background_color='white', colormap='Blues').generate(positive_reviews)\nnegative_wordcloud = WordCloud(width=800, height=400, background_color='white', colormap='Reds').generate(negative_reviews)\n\n# Plot the word clouds\nplt.figure(figsize=(16, 8))\n\n# Positive word cloud\nplt.subplot(1, 2, 1)\nplt.imshow(positive_wordcloud, interpolation='bilinear')\nplt.title(f\"Positive Reviews Word Cloud ({cuisine_type})\", fontsize=16)\nplt.axis('off')\n\n# Negative word cloud\nplt.subplot(1, 2, 2)\nplt.imshow(negative_wordcloud, interpolation='bilinear')\nplt.title(f\"Negative Reviews Word Cloud ({cuisine_type})\", fontsize=16)\nplt.axis('off')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n#Most prevalent positive and negative words from the cuisine type\nfrom textblob import TextBlob\nfrom wordcloud import WordCloud\nimport matplotlib.pyplot as plt\n\n# Filter data for a specific cuisine type\ncuisine_type = \"Seafood\"\nfiltered_data = Yelp[Yelp['Categories_0_title'] == cuisine_type].copy()\n\n# Function to determine sentiment polarity\ndef get_sentiment(text):\n    try:\n        analysis = TextBlob(str(text))  # Ensure text is converted to a string\n        return \"Positive\" if analysis.sentiment.polarity &gt; 0 else \"Negative\"\n    except:\n        return \"Neutral\"\n\n# Drop NaN values in 'Snippet' and apply sentiment analysis\nfiltered_data = filtered_data.dropna(subset=['Snippet'])\nfiltered_data['Sentiment'] = filtered_data['Snippet'].apply(get_sentiment)\n\n# Combine positive and negative review snippets\npositive_reviews = \" \".join(filtered_data[filtered_data['Sentiment'] == \"Positive\"]['Snippet'])\nnegative_reviews = \" \".join(filtered_data[filtered_data['Sentiment'] == \"Negative\"]['Snippet'])\n\n# Generate word clouds\npositive_wordcloud = WordCloud(width=800, height=400, background_color='white', colormap='Blues').generate(positive_reviews)\nnegative_wordcloud = WordCloud(width=800, height=400, background_color='white', colormap='Reds').generate(negative_reviews)\n\n# Plot the word clouds\nplt.figure(figsize=(16, 8))\n\n# Positive word cloud\nplt.subplot(1, 2, 1)\nplt.imshow(positive_wordcloud, interpolation='bilinear')\nplt.title(f\"Positive Reviews Word Cloud ({cuisine_type})\", fontsize=16)\nplt.axis('off')\n\n# Negative word cloud\nplt.subplot(1, 2, 2)\nplt.imshow(negative_wordcloud, interpolation='bilinear')\nplt.title(f\"Negative Reviews Word Cloud ({cuisine_type})\", fontsize=16)\nplt.axis('off')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n#Plot map to see if the location of the restaurant is correlated with the ratings\n!pip install pandas geopandas folium matplotlib\nimport folium\nfrom folium.plugins import MarkerCluster\n\nfiltered_data = Yelp[['Rating', 'Latitude', 'Longitude']].dropna()\n\naverage_lat = filtered_data['Latitude'].mean()\naverage_lon = filtered_data['Longitude'].mean()\nrating_map = folium.Map(location=[average_lat, average_lon], zoom_start=10)\n\nmarker_cluster = MarkerCluster().add_to(rating_map)\n\nfor index, row in filtered_data.iterrows():\n    folium.CircleMarker(\n        location=(row['Latitude'], row['Longitude']),\n        radius=5,\n        color='blue',\n        fill=True,\n        fill_opacity=0.7,\n        fill_color='green' if row['Rating'] &gt;= 4 else 'red',\n        popup=f\"Rating: {row['Rating']}\"\n    ).add_to(marker_cluster)\n\nrating_map.save(\"ratings_map.html\")\nrating_map\n\n\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\nRequirement already satisfied: geopandas in /usr/local/lib/python3.10/dist-packages (1.0.1)\nRequirement already satisfied: folium in /usr/local/lib/python3.10/dist-packages (0.18.0)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\nRequirement already satisfied: numpy&gt;=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\nRequirement already satisfied: python-dateutil&gt;=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\nRequirement already satisfied: pytz&gt;=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\nRequirement already satisfied: tzdata&gt;=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\nRequirement already satisfied: pyogrio&gt;=0.7.2 in /usr/local/lib/python3.10/dist-packages (from geopandas) (0.10.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from geopandas) (24.2)\nRequirement already satisfied: pyproj&gt;=3.3.0 in /usr/local/lib/python3.10/dist-packages (from geopandas) (3.7.0)\nRequirement already satisfied: shapely&gt;=2.0.0 in /usr/local/lib/python3.10/dist-packages (from geopandas) (2.0.6)\nRequirement already satisfied: branca&gt;=0.6.0 in /usr/local/lib/python3.10/dist-packages (from folium) (0.8.0)\nRequirement already satisfied: jinja2&gt;=2.9 in /usr/local/lib/python3.10/dist-packages (from folium) (3.1.4)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from folium) (2.32.3)\nRequirement already satisfied: xyzservices in /usr/local/lib/python3.10/dist-packages (from folium) (2024.9.0)\nRequirement already satisfied: contourpy&gt;=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\nRequirement already satisfied: cycler&gt;=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: fonttools&gt;=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.1)\nRequirement already satisfied: kiwisolver&gt;=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\nRequirement already satisfied: pillow&gt;=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.0.0)\nRequirement already satisfied: pyparsing&gt;=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\nRequirement already satisfied: MarkupSafe&gt;=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2&gt;=2.9-&gt;folium) (3.0.2)\nRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from pyogrio&gt;=0.7.2-&gt;geopandas) (2024.8.30)\nRequirement already satisfied: six&gt;=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil&gt;=2.8.2-&gt;pandas) (1.16.0)\nRequirement already satisfied: charset-normalizer&lt;4,&gt;=2 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;folium) (3.4.0)\nRequirement already satisfied: idna&lt;4,&gt;=2.5 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;folium) (3.10)\nRequirement already satisfied: urllib3&lt;3,&gt;=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;folium) (2.2.3)\n\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\n\n\n\n#Pre-processing the data for machine learning models\nfrom sklearn.preprocessing import LabelEncoder\n\n# Select relevant features and target\nfeatures = Yelp[['Categories_0_title', 'Longitude', 'Latitude', 'ReviewCount']]\ntarget = Yelp['Rating']\n\n# Encode the 'Cuisine_Type' column\nlabel_encoder = LabelEncoder()\nfeatures['Categories_0_title'] = label_encoder.fit_transform(features['Categories_0_title'])\n\n#Bin ratings into categories (e.g., Low, Medium, High)\n# 0 - 2 = low, 2 - 3.5 = medium, 3.5 - 5 = high\ntarget = pd.cut(target, bins=[0, 2.5, 4, 5], labels=['Low', 'Medium', 'High'])\n\nSettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  features['Categories_0_title'] = label_encoder.fit_transform(features['Categories_0_title'])\n\n\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.3, random_state=42)\n\n\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import classification_report, accuracy_score\n#handle missing values\nX_train = X_train.dropna()\ny_train = y_train.dropna()\ny_train = y_train.replace('nan', None).dropna()\ny_test = y_test.replace('nan', None).dropna()\n\nvalid_indices_train = X_train.index.intersection(y_train.index)\nX_train = X_train.loc[valid_indices_train]\ny_train = y_train.loc[valid_indices_train]\n\n# Filter y_test to remove invalid entries before predictions\nvalid_test_indices = y_test.replace('nan', None).dropna().index\ny_test_filtered = y_test.loc[valid_test_indices]\n\n\n#Decision Tree models\ndt_model = DecisionTreeClassifier(random_state=42)\ndt_model.fit(X_train, y_train)\n\n# Re-run predictions for the filtered test set\nX_test_filtered = X_test.loc[valid_test_indices]\ny_pred_dt_filtered = dt_model.predict(X_test_filtered)\n\n# Predict and evaluate\ny_pred_dt = dt_model.predict(X_test)\ny_test = y_test.astype(str)\ny_pred_dt = y_pred_dt.astype(str)\nprint(\"Decision Tree Accuracy:\", accuracy_score(y_test_filtered, y_pred_dt_filtered))\nprint(classification_report(y_test_filtered, y_pred_dt_filtered))\n\nDecision Tree Accuracy: 0.6170542635658914\n              precision    recall  f1-score   support\n\n        High       0.76      0.69      0.72       456\n         Low       0.00      0.00      0.00         6\n      Medium       0.38      0.45      0.41       183\n\n    accuracy                           0.62       645\n   macro avg       0.38      0.38      0.38       645\nweighted avg       0.64      0.62      0.63       645\n\n\n\n\n#Decision Tree model with pruning parameters\ndt_model = DecisionTreeClassifier(\n    random_state=42,\n    max_depth=5,\n    min_samples_split=10,\n    min_samples_leaf=5\n)\n\n# Train the model\ndt_model.fit(X_train, y_train)\n\n# Re-run predictions for the filtered test set\nX_test_filtered = X_test.loc[valid_test_indices]\ny_pred_dt_filtered = dt_model.predict(X_test_filtered)\n\n# Predict and evaluate\ny_pred_dt = dt_model.predict(X_test)\ny_test = y_test.astype(str)\ny_pred_dt = y_pred_dt.astype(str)\n\n# Evaluation metrics\nprint(\"Decision Tree Accuracy:\", accuracy_score(y_test_filtered, y_pred_dt_filtered))\nprint(classification_report(y_test_filtered, y_pred_dt_filtered))\n\nDecision Tree Accuracy: 0.703875968992248\n              precision    recall  f1-score   support\n\n        High       0.77      0.85      0.80       456\n         Low       0.00      0.00      0.00         6\n      Medium       0.48      0.37      0.42       183\n\n    accuracy                           0.70       645\n   macro avg       0.42      0.41      0.41       645\nweighted avg       0.68      0.70      0.69       645\n\n\n\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n\n\n\nfrom sklearn.impute import SimpleImputer\n\n# Apply SimpleImputer to fill missing values in the features with the mean (or median for better robustness)\nimputer = SimpleImputer(strategy='mean')\n\n# Impute missing values for numerical columns in the features\nfeatures_imputed = imputer.fit_transform(features)\n\n# Check for missing values after imputation\nprint(pd.DataFrame(features_imputed).isnull().sum())  # This should show no NaN values now\n\n# Drop rows with missing target values\ntarget = target.dropna()  # Remove rows with NaN in target\n\n# Make sure X aligns with the cleaned y\nfeatures_imputed = features_imputed[target.index]  # Ensure X and y are still aligned after dropping\n\nfrom sklearn.model_selection import train_test_split\n\n# Split the data\nX_train, X_test, y_train, y_test = train_test_split(features_imputed, target, test_size=0.2, random_state=42)\n\n# Check if there are any NaN values in the training and testing sets\nprint(f\"X_train NaNs: {pd.DataFrame(X_train).isnull().sum().sum()}\")\nprint(f\"y_train NaNs: {y_train.isnull().sum()}\")\nprint(f\"X_test NaNs: {pd.DataFrame(X_test).isnull().sum().sum()}\")\nprint(f\"y_test NaNs: {y_test.isnull().sum()}\")\n\n0    0\n1    0\n2    0\n3    0\ndtype: int64\nX_train NaNs: 0\ny_train NaNs: 0\nX_test NaNs: 0\ny_test NaNs: 0\n\n\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# Initialize Random Forest model\nrf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n\n# Train the model\nrf_model.fit(X_train, y_train)\n\n# Predict on the test set\ny_pred_rf = rf_model.predict(X_test)\n\n# Convert predictions and true labels to strings to handle any potential mismatches\ny_test = y_test.astype(str)\ny_pred_rf = y_pred_rf.astype(str)\n\n# Accuracy and classification report\nprint(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\nprint(classification_report(y_test, y_pred_rf))\n\n# Verify the shapes of X_test and y_test\nprint(f\"X_test shape: {X_test.shape}\")\nprint(f\"y_test shape: {y_test.shape}\")\n\nRandom Forest Accuracy: 0.7199074074074074\n              precision    recall  f1-score   support\n\n           0       0.75      0.88      0.81       284\n           1       0.00      0.00      0.00         4\n           2       0.64      0.42      0.51       144\n\n    accuracy                           0.72       432\n   macro avg       0.46      0.43      0.44       432\nweighted avg       0.70      0.72      0.70       432\n\nX_test shape: (432, 4)\ny_test shape: (432,)\n\n\n\nfrom sklearn.decomposition import PCA\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom sklearn.preprocessing import StandardScaler\n\n# Standardize the data (PCA works better with scaled data)\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Apply PCA to reduce dimensions\npca = PCA(n_components=0.95)  # Retain 95% of variance\nX_train_pca = pca.fit_transform(X_train_scaled)\nX_test_pca = pca.transform(X_test_scaled)\n\n# Initialize Random Forest model\nrf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n\n# Train the model on PCA-transformed data\nrf_model.fit(X_train_pca, y_train)\n\n# Predict on the PCA-transformed test set\ny_pred_rf = rf_model.predict(X_test_pca)\n\n# Convert predictions and true labels to strings to handle any potential mismatches\ny_test = y_test.astype(str)\ny_pred_rf = y_pred_rf.astype(str)\n\n# Accuracy and classification report\nprint(\"Random Forest Accuracy(PCA):\", accuracy_score(y_test, y_pred_rf))\nprint(classification_report(y_test, y_pred_rf))\n\n# Check how much variance is explained by the retained components\nexplained_variance = pca.explained_variance_ratio_\nprint(\"Explained Variance by PCA components:\", explained_variance)\nprint(f\"Number of PCA components retained: {pca.n_components_}\")\n\nRandom Forest Accuracy(PCA): 0.6574074074074074\n              precision    recall  f1-score   support\n\n        High       0.70      0.85      0.77       284\n         Low       0.00      0.00      0.00         4\n      Medium       0.49      0.29      0.37       144\n\n    accuracy                           0.66       432\n   macro avg       0.40      0.38      0.38       432\nweighted avg       0.62      0.66      0.63       432\n\nExplained Variance by PCA components: [0.49675527 0.25393994 0.24389005]\nNumber of PCA components retained: 3\n\n\n\n#Try to apply SMOTE to the random forest model\nfrom sklearn.impute import SimpleImputer\n\n# Impute missing values in numerical columns\nimputer = SimpleImputer(strategy='mean')\nX_train = imputer.fit_transform(X_train)\nX_test = imputer.transform(X_test)\n\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\nfrom sklearn.preprocessing import LabelEncoder\n\nlabel_encoder = LabelEncoder()\ny_train = label_encoder.fit_transform(y_train)\ny_test = label_encoder.transform(y_test)\n\nfrom sklearn.model_selection import GridSearchCV\n\nfrom imblearn.over_sampling import SMOTE\n\n# Apply SMOTE to balance the dataset\nsmote = SMOTE(random_state=42)\nX_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n\nrf_remodel = RandomForestClassifier(n_estimators=100, random_state=42)\nrf_remodel.fit(X_train_balanced, y_train_balanced)\n\n# 5. Predict on the test set\ny_pred_rf_remodel = rf_remodel.predict(X_test)\n\n# 6. Evaluate the model\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred_rf_remodel))\nprint(classification_report(y_test, y_pred_rf_remodel))\n\nAccuracy: 0.6620370370370371\n              precision    recall  f1-score   support\n\n           0       0.78      0.74      0.76       284\n           1       0.00      0.00      0.00         4\n           2       0.53      0.53      0.53       144\n\n    accuracy                           0.66       432\n   macro avg       0.44      0.42      0.43       432\nweighted avg       0.69      0.66      0.67       432\n\n\n\n\n#Cross Validation for Random Forest\nfrom sklearn.model_selection import StratifiedKFold, cross_val_score\n\nkf = StratifiedKFold(n_splits=5)\ncv_scores = cross_val_score(rf_model, X_train, y_train, cv=kf, scoring='accuracy')\nprint(\"Cross-Validation Accuracy:\", cv_scores.mean())\n\nCross-Validation Accuracy: 0.7041557128412539\n\n\n\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\n# Assuming 'features' is your dataset\n# If necessary, you can apply scaling (StandardScaler, MinMaxScaler) for better results\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nfeatures_scaled = scaler.fit_transform(features)\nwcss = []\nfor k in range(1, 11):  # Check for k values from 1 to 10\n    kmeans = KMeans(n_clusters=k, init='k-means++', max_iter=300, n_init=10, random_state=42)\n    kmeans.fit(features_scaled)\n    wcss.append(kmeans.inertia_)  # Inertia is the WCSS\nplt.figure(figsize=(8, 6))\nplt.plot(range(1, 11), wcss)\nplt.title('Elbow Method for Optimal k', fontsize=16)\nplt.xlabel('Number of Clusters (k)', fontsize=14)\nplt.ylabel('WCSS (Within-Cluster Sum of Squares)', fontsize=14)\nplt.xticks(range(1, 11))\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# Initialize KNN model\nknn_model = KNeighborsClassifier(n_neighbors=4)  # You can experiment with different values of k\n\n# Train the KNN model\nknn_model.fit(X_train, y_train)\n\n# Predict on the test set\ny_pred_knn = knn_model.predict(X_test)\n\n# Convert predictions and true labels to strings if necessary\ny_test = y_test.astype(str)\ny_pred_knn = y_pred_knn.astype(str)\n\n# Evaluate the KNN model\nprint(\"KNN Accuracy:\", accuracy_score(y_test, y_pred_knn))\nprint(classification_report(y_test, y_pred_knn))\n\n# Verify the shapes of X_test and y_test\nprint(f\"X_test shape: {X_test.shape}\")\nprint(f\"y_test shape: {y_test.shape}\")\n\nKNN Accuracy: 0.6689814814814815\n              precision    recall  f1-score   support\n\n           0       0.69      0.90      0.78       284\n           1       0.00      0.00      0.00         4\n           2       0.52      0.23      0.32       144\n\n    accuracy                           0.67       432\n   macro avg       0.41      0.38      0.37       432\nweighted avg       0.63      0.67      0.62       432\n\nX_test shape: (432, 4)\ny_test shape: (432,)\n\n\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n\n\n\n#KNN afer hyperparameter tune\nfrom sklearn.model_selection import GridSearchCV\n\n# Define parameter grid for tuning\nparam_grid = {'n_neighbors': [3, 5, 7, 9], 'weights': ['uniform', 'distance']}\n\n# Initialize GridSearchCV with cross-validation\ngrid_search = GridSearchCV(KNeighborsClassifier(), param_grid, cv=4, scoring='accuracy')\n\n# Fit the grid search\ngrid_search.fit(X_train, y_train)\n\n# Get the best parameters\nprint(\"Best Parameters:\", grid_search.best_params_)\n\n# Evaluate the model with the best parameters\nbest_knn_model = grid_search.best_estimator_\ny_pred_knn_best = best_knn_model.predict(X_test)\n\n# Convert predictions and true labels to strings if necessary\ny_test = y_test.astype(str)\ny_pred_knn_best = y_pred_knn_best.astype(str)\n\n# Accuracy and classification report for the best model\nprint(\"Best KNN Accuracy:\", accuracy_score(y_test, y_pred_knn_best))\nprint(classification_report(y_test, y_pred_knn_best))\n\nBest Parameters: {'n_neighbors': 9, 'weights': 'uniform'}\nBest KNN Accuracy: 0.6597222222222222\n              precision    recall  f1-score   support\n\n           0       0.70      0.87      0.77       284\n           1       0.00      0.00      0.00         4\n           2       0.49      0.26      0.34       144\n\n    accuracy                           0.66       432\n   macro avg       0.40      0.38      0.37       432\nweighted avg       0.62      0.66      0.62       432\n\n\n\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n\n\n\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# First, make sure to include only numeric columns for correlation\n# You can exclude non-numeric columns such as categorical columns.\ndf_numeric = Yelp.select_dtypes(include=['number'])\n\n# Compute the correlation matrix\ncorrelation_matrix = df_numeric.corr()\n\n# Print the correlation matrix\nprint(correlation_matrix)\n\n# Visualize the correlation matrix using a heatmap\nplt.figure(figsize=(10, 8))\nsns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)\nplt.title('Correlation Matrix')\nplt.show()\n\n               Rating  ReviewCount  Longitude  Latitude   Ranking\nRating       1.000000     0.003223   0.018082 -0.071159 -0.128065\nReviewCount  0.003223     1.000000   0.044630 -0.075662 -0.115116\nLongitude    0.018082     0.044630   1.000000 -0.976865 -0.025678\nLatitude    -0.071159    -0.075662  -0.976865  1.000000  0.002244\nRanking     -0.128065    -0.115116  -0.025678  0.002244  1.000000\n\n\n\n\n\n\n\n\n\n\n#Feature of importance from random forest\nimport matplotlib.pyplot as plt\n\nfeature_importances = rf_model.feature_importances_\n\n# Plot feature importances\nplt.figure(figsize=(10, 6))\nplt.bar(features.columns, feature_importances, color='skyblue')\nplt.xlabel('Features')\nplt.ylabel('Importance')\nplt.title('Feature Importance in Rating Prediction')\nplt.show()\n\n\n\n\n\n\n\n\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom imblearn.over_sampling import SMOTE\n\n# 1. Prepare features and target\nfeatures = Yelp[['Categories_0_title', 'Longitude', 'Latitude', 'ReviewCount']].copy()\nlabel_encoder = LabelEncoder()\nfeatures['Categories_0_title'] = label_encoder.fit_transform(features['Categories_0_title'].astype(str))\n\n# Bin the ratings into categories and remove NaN values\ntarget = Yelp['Rating'].dropna()\ntarget = pd.cut(target, bins=[0, 2, 3.5, 5], labels=['Low', 'Medium', 'High'])\ntarget = target.astype(str)  # Ensure the target is a string type for classification\n\n# 2. Split into training and test sets\nX_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n\n# Ensure no NaN values\nX_train = features.dropna()\ny_train = target[X_train.index]\n\n# 3. Apply SMOTE to balance classes\n# Apply SMOTE to balance classes\nsmote = SMOTE(random_state=42)\nX_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n\n# 4. Train the Decision Tree model\ndt_model = DecisionTreeClassifier(random_state=42)\ndt_model.fit(X_train_resampled, y_train_resampled)\n\n# 5. Predict on the test set\ny_pred = dt_model.predict(X_test)\n\n# 6. Evaluate the model\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\nprint(classification_report(y_test, y_pred))\n\nAccuracy: 1.0\n              precision    recall  f1-score   support\n\n        High       1.00      1.00      1.00       401\n      Medium       1.00      1.00      1.00        30\n         nan       1.00      1.00      1.00         5\n\n    accuracy                           1.00       436\n   macro avg       1.00      1.00      1.00       436\nweighted avg       1.00      1.00      1.00       436\n\n\n\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import LabelEncoder\n\n\n# Train and evaluate Decision Tree model\ndt_model.fit(X_train, y_train)\ny_pred_dt = dt_model.predict(X_test)\ndt_accuracy = accuracy_score(y_test, y_pred_dt)\nprint(\"Decision Tree Stratified Accuracy:\", dt_accuracy)\nprint(classification_report(y_test, y_pred_dt))\n\n# Train and evaluate Random Forest model\nrf_model.fit(X_train, y_train)\ny_pred_rf = rf_model.predict(X_test)\nrf_accuracy = accuracy_score(y_test, y_pred_rf)\nprint(\"Random Forest Stratified Accuracy:\", rf_accuracy)\nprint(classification_report(y_test, y_pred_rf))\n\nDecision Tree Stratified Accuracy: 1.0\n              precision    recall  f1-score   support\n\n        High       1.00      1.00      1.00       401\n      Medium       1.00      1.00      1.00        30\n         nan       1.00      1.00      1.00         5\n\n    accuracy                           1.00       436\n   macro avg       1.00      1.00      1.00       436\nweighted avg       1.00      1.00      1.00       436\n\nRandom Forest Stratified Accuracy: 1.0\n              precision    recall  f1-score   support\n\n        High       1.00      1.00      1.00       401\n      Medium       1.00      1.00      1.00        30\n         nan       1.00      1.00      1.00         5\n\n    accuracy                           1.00       436\n   macro avg       1.00      1.00      1.00       436\nweighted avg       1.00      1.00      1.00       436"
  },
  {
    "objectID": "projects/Amazon Product Analysis/amazon-product-analysis.html",
    "href": "projects/Amazon Product Analysis/amazon-product-analysis.html",
    "title": "ğŸ›ï¸ Amazon Product Reviews Sentiment Analysis",
    "section": "",
    "text": "This project analyzes customer sentiment from Amazon product reviews using natural language processing and machine learning techniques. The goal was to understand common customer opinions, how review length correlates with sentiment and rating, and to evaluate which models best classify review sentiment."
  },
  {
    "objectID": "projects/Amazon Product Analysis/amazon-product-analysis.html#project-overview",
    "href": "projects/Amazon Product Analysis/amazon-product-analysis.html#project-overview",
    "title": "ğŸ›ï¸ Amazon Product Reviews Sentiment Analysis",
    "section": "",
    "text": "This project analyzes customer sentiment from Amazon product reviews using natural language processing and machine learning techniques. The goal was to understand common customer opinions, how review length correlates with sentiment and rating, and to evaluate which models best classify review sentiment."
  },
  {
    "objectID": "projects/Amazon Product Analysis/amazon-product-analysis.html#objectives",
    "href": "projects/Amazon Product Analysis/amazon-product-analysis.html#objectives",
    "title": "ğŸ›ï¸ Amazon Product Reviews Sentiment Analysis",
    "section": "ğŸ¯ Objectives",
    "text": "ğŸ¯ Objectives\n\nIdentify common themes in positive vs.Â negative reviews\nExamine the relationship between review length, sentiment, and product rating\nEvaluate classification models for sentiment prediction"
  },
  {
    "objectID": "projects/Amazon Product Analysis/amazon-product-analysis.html#data-methods",
    "href": "projects/Amazon Product Analysis/amazon-product-analysis.html#data-methods",
    "title": "ğŸ›ï¸ Amazon Product Reviews Sentiment Analysis",
    "section": "ğŸ—‚ï¸ Data & Methods",
    "text": "ğŸ—‚ï¸ Data & Methods\n\nData: Amazon review dataset (1,465 reviews, 16 variables) from Kaggle\n\nText Preprocessing: Lowercasing, punctuation removal, stopword removal, tokenization\n\nFeature Engineering: TF-IDF with n-grams\n\nSentiment Labeling: VADER lexicon to classify sentiment as Positive, Neutral, or Negative\n\nModels Used: Logistic Regression, Random Forest, Support Vector Machine (SVM)"
  },
  {
    "objectID": "projects/Amazon Product Analysis/amazon-product-analysis.html#key-insights",
    "href": "projects/Amazon Product Analysis/amazon-product-analysis.html#key-insights",
    "title": "ğŸ›ï¸ Amazon Product Reviews Sentiment Analysis",
    "section": "ğŸ” Key Insights",
    "text": "ğŸ” Key Insights\n\nStrong Positive Bias: Majority of reviews were classified as positive; neutral and negative reviews were underrepresented.\nReview Length Matters: Longer reviews were slightly more likely to be positive, but the correlation was weak.\nThemes:\n\nPositive: â€œvalue for money,â€ â€œsound quality,â€ â€œlightweightâ€\nNegative: â€œpoor quality,â€ â€œcharging cable,â€ â€œdonâ€™t buyâ€"
  },
  {
    "objectID": "projects/Amazon Product Analysis/amazon-product-analysis.html#model-performance",
    "href": "projects/Amazon Product Analysis/amazon-product-analysis.html#model-performance",
    "title": "ğŸ›ï¸ Amazon Product Reviews Sentiment Analysis",
    "section": "ğŸ¤– Model Performance",
    "text": "ğŸ¤– Model Performance\n\n\n\n\n\n\n\n\n\nModel\nAccuracy\nStrengths\nWeaknesses\n\n\n\n\nLogistic Regression\n92%\nHigh recall for positive reviews\nPoor detection of neutral/negative\n\n\nRandom Forest\n91%\nRobust with positive sentiment\nWeak on negative (recall: 0.06)\n\n\nSVM\n92%\nBalanced and strong on positives\nMisclassified most negatives/neutral"
  },
  {
    "objectID": "projects/Amazon Product Analysis/amazon-product-analysis.html#business-impact",
    "href": "projects/Amazon Product Analysis/amazon-product-analysis.html#business-impact",
    "title": "ğŸ›ï¸ Amazon Product Reviews Sentiment Analysis",
    "section": "ğŸ’¡ Business Impact",
    "text": "ğŸ’¡ Business Impact\n\nProduct Improvement: Frequent negative terms flagged areas for design or quality fixes.\nMarketing: Highlighted strengths (e.g., sound quality) can inform ad copy and product positioning.\nCustomer Engagement: Long, detailed reviews suggest satisfaction; prompting longer feedback could yield richer insights."
  },
  {
    "objectID": "projects/Amazon Product Analysis/amazon-product-analysis.html#limitations-future-enhancement",
    "href": "projects/Amazon Product Analysis/amazon-product-analysis.html#limitations-future-enhancement",
    "title": "ğŸ›ï¸ Amazon Product Reviews Sentiment Analysis",
    "section": "ğŸ”„ Limitations & Future Enhancement",
    "text": "ğŸ”„ Limitations & Future Enhancement\n\nImbalanced dataset (mostly positive reviews) biased model performance\nModels underperformed on neutral and negative reviews\nFuture improvements: class balancing, hyperparameter tuning, and deep learning approaches"
  },
  {
    "objectID": "projects/Amazon Product Analysis/amazon-product-analysis.html#conclusion",
    "href": "projects/Amazon Product Analysis/amazon-product-analysis.html#conclusion",
    "title": "ğŸ›ï¸ Amazon Product Reviews Sentiment Analysis",
    "section": "ğŸ§¾ Conclusion",
    "text": "ğŸ§¾ Conclusion\nThis project demonstrated how sentiment analysis can uncover key customer insights from product reviews. Despite model limitations with neutral and negative classification, positive feedback was effectively captured. Further model tuning and data balancing could enhance accuracy across all sentiment categories, supporting more informed business decisions."
  },
  {
    "objectID": "projects/Amazon Product Analysis/amazon-product-analysis.html#github-repository",
    "href": "projects/Amazon Product Analysis/amazon-product-analysis.html#github-repository",
    "title": "ğŸ›ï¸ Amazon Product Reviews Sentiment Analysis",
    "section": "ğŸ“ GitHub Repository",
    "text": "ğŸ“ GitHub Repository\nğŸ‘‰ View Code on GitHub"
  },
  {
    "objectID": "projects/Netflix Recommendation/netflix-recommendation.html",
    "href": "projects/Netflix Recommendation/netflix-recommendation.html",
    "title": "ğŸ¬ Netflix Recommendation System & Chatbot",
    "section": "",
    "text": "This project combines Natural Language Processing (NLP), content clustering, and chatbot integration to create a personalized movie and TV show recommendation system using a dataset of Netflix titles. The goal was to improve content discoverability by grouping shows based on themes and responding to user preferences through an interactive chatbot interface."
  },
  {
    "objectID": "projects/Netflix Recommendation/netflix-recommendation.html#project-overview",
    "href": "projects/Netflix Recommendation/netflix-recommendation.html#project-overview",
    "title": "ğŸ¬ Netflix Recommendation System & Chatbot",
    "section": "",
    "text": "This project combines Natural Language Processing (NLP), content clustering, and chatbot integration to create a personalized movie and TV show recommendation system using a dataset of Netflix titles. The goal was to improve content discoverability by grouping shows based on themes and responding to user preferences through an interactive chatbot interface."
  },
  {
    "objectID": "projects/Netflix Recommendation/netflix-recommendation.html#objectives",
    "href": "projects/Netflix Recommendation/netflix-recommendation.html#objectives",
    "title": "ğŸ¬ Netflix Recommendation System & Chatbot",
    "section": "ğŸ¯ Objectives",
    "text": "ğŸ¯ Objectives\n\nBuild a content-based recommendation system using NLP techniques.\nExtract core themes and patterns from Netflix descriptions using tokenization and TF-IDF.\nImplement unsupervised clustering to group similar content.\nDeploy a chatbot that responds to user inputs and delivers tailored suggestions.\nEvaluate genre prediction and chatbot relevance using both quantitative and qualitative feedback."
  },
  {
    "objectID": "projects/Netflix Recommendation/netflix-recommendation.html#data-preprocessing-nlp-techniques",
    "href": "projects/Netflix Recommendation/netflix-recommendation.html#data-preprocessing-nlp-techniques",
    "title": "ğŸ¬ Netflix Recommendation System & Chatbot",
    "section": "ğŸ§¹ Data Preprocessing & NLP Techniques",
    "text": "ğŸ§¹ Data Preprocessing & NLP Techniques\n\nMissing Values: Dataset was complete with no missing fields.\nAge Classification: Converted age ratings into numeric values for content filtering.\nTokenization & Lemmatization: Applied NLTK to clean and standardize text descriptions.\nTF-IDF Vectorization: Extracted key terms and themes from descriptions for clustering and recommendations."
  },
  {
    "objectID": "projects/Netflix Recommendation/netflix-recommendation.html#clustering-insights",
    "href": "projects/Netflix Recommendation/netflix-recommendation.html#clustering-insights",
    "title": "ğŸ¬ Netflix Recommendation System & Chatbot",
    "section": "ğŸ§  Clustering Insights",
    "text": "ğŸ§  Clustering Insights\nUsed K-means clustering to group titles into 6 thematic categories:\n\n\n\n\n\n\n\n\nCluster\nTheme\nExamples\n\n\n\n\n1\nBig City Life & Personal Discovery\nBlood & Water, Ganglands\n\n\n2\nLove & Life Journeys\nMidnight Mass, Je Suis Karl\n\n\n3\nComing-of-Age\nKota Factory, Dhanak\n\n\n4\nMusic & Art\nNailed It!, Rhyme & Reason\n\n\n5\nConnection & Discovery\nSankofa, Great British Baking Show\n\n\n6\nDocumentaries & Real-Life Stories\nDick Johnson Is Dead, Intrusion"
  },
  {
    "objectID": "projects/Netflix Recommendation/netflix-recommendation.html#recommendation-system",
    "href": "projects/Netflix Recommendation/netflix-recommendation.html#recommendation-system",
    "title": "ğŸ¬ Netflix Recommendation System & Chatbot",
    "section": "ğŸ¤– Recommendation System",
    "text": "ğŸ¤– Recommendation System\nThe system processes user inputs like genre, actor, type, sentiment, and keywords to generate TF-IDF-based vectors. It then calculates cosine similarity scores and ranks top 5 content matches.\nExample Input:\nGenre: Comedy | Actor: Tom | Sentiment: funny | Keyword: vacation\nTop Match: Jim Gaffigan: Cinco (similarity score: 0.253)"
  },
  {
    "objectID": "projects/Netflix Recommendation/netflix-recommendation.html#chatbot-integration",
    "href": "projects/Netflix Recommendation/netflix-recommendation.html#chatbot-integration",
    "title": "ğŸ¬ Netflix Recommendation System & Chatbot",
    "section": "ğŸ’¬ Chatbot Integration",
    "text": "ğŸ’¬ Chatbot Integration\nA chatbot interface was developed to make recommendations conversational and intuitive. It:\n\nAccepts free-text user inputs\nParses for preferences (e.g., actor, genre, tone)\nReturns top-matching Netflix titles with similarity scores\n\n\nExample: The chatbot asks for your favorite actor (Ama Qamata) and genre (Comedy), then returns matching stand-up specials and light-hearted shows."
  },
  {
    "objectID": "projects/Netflix Recommendation/netflix-recommendation.html#conclusion",
    "href": "projects/Netflix Recommendation/netflix-recommendation.html#conclusion",
    "title": "ğŸ¬ Netflix Recommendation System & Chatbot",
    "section": "ğŸ§¾ Conclusion",
    "text": "ğŸ§¾ Conclusion\nThis project demonstrates how NLP and conversational AI can enhance media recommendations. Through clustering, tokenization, and cosine similarity, we created a dynamic, personalized content discovery experience. The chatbot allows users to interact naturally, making movie and TV recommendations feel more human and tailored."
  },
  {
    "objectID": "projects/Netflix Recommendation/netflix-recommendation.html#limitations",
    "href": "projects/Netflix Recommendation/netflix-recommendation.html#limitations",
    "title": "ğŸ¬ Netflix Recommendation System & Chatbot",
    "section": "âš ï¸ Limitations",
    "text": "âš ï¸ Limitations\nWhile the system provides personalized recommendations and interactive chatbot responses, there are a few limitations:\n\nMulti-label Genre Complexity: Many titles belong to multiple genres, making it difficult for models to predict accurately from tokenized descriptions alone.\nText Ambiguity: Descriptions often contain vague or overlapping themes, reducing classification precision.\nModel Performance: Genre classification models (e.g., Logistic Regression, Naive Bayes) yielded relatively low F1 scores, indicating room for improvement in multi-label learning.\nUser Input Limitations: The chatbot depends on structured inputs (e.g., genre, sentiment), and may struggle with ambiguous or unrelated queries.\nCold Start Problem: The system does not incorporate real-time user behavior or preferences, limiting adaptability for new users.\n\nFuture enhancements could include deep learning models, multi-label classification improvements, and feedback-based recommendation tuning."
  },
  {
    "objectID": "projects/Netflix Recommendation/netflix-recommendation.html#github-repository",
    "href": "projects/Netflix Recommendation/netflix-recommendation.html#github-repository",
    "title": "ğŸ¬ Netflix Recommendation System & Chatbot",
    "section": "ğŸ“ GitHub Repository",
    "text": "ğŸ“ GitHub Repository\nğŸ‘‰ View Code on GitHub"
  },
  {
    "objectID": "projects/Bank Churn Prediction/bank-churn-prediction.html",
    "href": "projects/Bank Churn Prediction/bank-churn-prediction.html",
    "title": "ğŸ¦ Predicting Bank Customer Churn",
    "section": "",
    "text": "As digital banking continues to grow, identifying and preventing customer churnâ€”especially silent attritionâ€”has become critical for banks. This project applied multiple machine learning models to predict customer churn and uncover key behavioral and demographic risk factors to enable proactive retention strategies."
  },
  {
    "objectID": "projects/Bank Churn Prediction/bank-churn-prediction.html#project-overview",
    "href": "projects/Bank Churn Prediction/bank-churn-prediction.html#project-overview",
    "title": "ğŸ¦ Predicting Bank Customer Churn",
    "section": "",
    "text": "As digital banking continues to grow, identifying and preventing customer churnâ€”especially silent attritionâ€”has become critical for banks. This project applied multiple machine learning models to predict customer churn and uncover key behavioral and demographic risk factors to enable proactive retention strategies."
  },
  {
    "objectID": "projects/Bank Churn Prediction/bank-churn-prediction.html#objectives",
    "href": "projects/Bank Churn Prediction/bank-churn-prediction.html#objectives",
    "title": "ğŸ¦ Predicting Bank Customer Churn",
    "section": "ğŸ¯ Objectives",
    "text": "ğŸ¯ Objectives\n\nVisualize current customer behavior and demographics\nBuild predictive models to classify customers at risk of churn\nIdentify actionable drivers of attrition for strategic intervention"
  },
  {
    "objectID": "projects/Bank Churn Prediction/bank-churn-prediction.html#data-methods",
    "href": "projects/Bank Churn Prediction/bank-churn-prediction.html#data-methods",
    "title": "ğŸ¦ Predicting Bank Customer Churn",
    "section": "ğŸ—‚ï¸ Data & Methods",
    "text": "ğŸ—‚ï¸ Data & Methods\n\nData: 10,000 records from a European bank (Kaggle)\nFeatures: Age, Gender, Geography, Balance, Tenure, Products, Activity, etc.\nTools: Python, Scikit-learn, SMOTE, PCA\nModels Used: Logistic Regression, Gaussian Naive Bayes, Decision Tree, Random Forest"
  },
  {
    "objectID": "projects/Bank Churn Prediction/bank-churn-prediction.html#model-performance-summary",
    "href": "projects/Bank Churn Prediction/bank-churn-prediction.html#model-performance-summary",
    "title": "ğŸ¦ Predicting Bank Customer Churn",
    "section": "ğŸ¤– Model Performance Summary",
    "text": "ğŸ¤– Model Performance Summary\n\n\n\n\n\n\n\n\n\n\nModel\nAccuracy\nPrecision (Churn)\nRecall (Churn)\nF1-Score (Churn)\n\n\n\n\nLogistic Regression\n80.9%\n60%\n19% â†’ 77% (with SMOTE)\n29% â†’ 77%\n\n\nNaive Bayes\n78.7%\n36% â†’ 70%\n6% â†’ 74%\n11% â†’ 72%\n\n\nDecision Tree\n85% (after pruning)\n80%\n37%\n51%\n\n\nRandom Forest\n86% â†’ 84% (with SMOTE)\n76% â†’ 58%\n47% â†’ 64%\n58% â†’ 61%\n\n\n\n\nâœ… Random Forest with SMOTE achieved the best balance for identifying churners, despite a slight drop in precision."
  },
  {
    "objectID": "projects/Bank Churn Prediction/bank-churn-prediction.html#feature-importance-logistic-regression",
    "href": "projects/Bank Churn Prediction/bank-churn-prediction.html#feature-importance-logistic-regression",
    "title": "ğŸ¦ Predicting Bank Customer Churn",
    "section": "ğŸ” Feature Importance â€“ Logistic Regression",
    "text": "ğŸ” Feature Importance â€“ Logistic Regression\n\n\n\nThis chart displays the standardized coefficients from the Logistic Regression model, highlighting which features most influence customer churn predictions.\n\nAge and Balance are the strongest positive predictors of churn â€” older customers and those with higher balances are more likely to leave.\nIsActiveMember has the strongest negative coefficient, indicating active users are significantly less likely to churn.\nOther features like Geography, Estimated Salary, and Gender show smaller but still notable impacts.\n\nThese insights help the bank prioritize retention efforts around customer age, engagement, and account value."
  },
  {
    "objectID": "projects/Bank Churn Prediction/bank-churn-prediction.html#key-insights",
    "href": "projects/Bank Churn Prediction/bank-churn-prediction.html#key-insights",
    "title": "ğŸ¦ Predicting Bank Customer Churn",
    "section": "ğŸ” Key Insights",
    "text": "ğŸ” Key Insights\n\nDemographics: Older customers are more likely to churn; geographic differences (France/Germany higher than Spain).\nBehavioral Indicators:\n\nInactive members have a 27% churn rate vs.Â 14% for active.\nCustomers with fewer products are more likely to churn.\n\nTop Predictive Features: Age, Number of Products, Balance, IsActiveMember."
  },
  {
    "objectID": "projects/Bank Churn Prediction/bank-churn-prediction.html#strategic-recommendations",
    "href": "projects/Bank Churn Prediction/bank-churn-prediction.html#strategic-recommendations",
    "title": "ğŸ¦ Predicting Bank Customer Churn",
    "section": "ğŸ’¡ Strategic Recommendations",
    "text": "ğŸ’¡ Strategic Recommendations\n\nEngagement: Target inactive users and those with only 1â€“2 products via cross-sell campaigns.\nPersonalization: Design region-specific and age-aware outreach strategies.\nRetention: Monitor older customers and offer digital support to reduce disengagement.\nModel Use: Deploy Random Forest with SMOTE to support real-time churn alerts."
  },
  {
    "objectID": "projects/Bank Churn Prediction/bank-churn-prediction.html#conclusion",
    "href": "projects/Bank Churn Prediction/bank-churn-prediction.html#conclusion",
    "title": "ğŸ¦ Predicting Bank Customer Churn",
    "section": "ğŸ§¾ Conclusion",
    "text": "ğŸ§¾ Conclusion\nThis project shows how machine learning can effectively identify churn risk using behavioral and demographic signals. With Random Forest as the most effective model, supported by SMOTE balancing, banks can proactively reduce attrition by targeting the right customers at the right time. The insights gained can guide smarter customer engagement and long-term profitability."
  },
  {
    "objectID": "projects/Bank Churn Prediction/bank-churn-prediction.html#github-repository",
    "href": "projects/Bank Churn Prediction/bank-churn-prediction.html#github-repository",
    "title": "ğŸ¦ Predicting Bank Customer Churn",
    "section": "ğŸ“ GitHub Repository",
    "text": "ğŸ“ GitHub Repository\nğŸ‘‰ View Code on GitHub"
  },
  {
    "objectID": "projects/Bank Churn Prediction/Group_8B_ML_Final_Project_ipynb_final.html",
    "href": "projects/Bank Churn Prediction/Group_8B_ML_Final_Project_ipynb_final.html",
    "title": "My Portfolio",
    "section": "",
    "text": "# Things to do\n# Clean Data\n# Build a model (1 for each)\n\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy.stats import ttest_ind, chi2_contingency\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report\n\n# Load the dataset\ndata = pd.read_csv('bank_churn.csv')  # Replace with your file path\n\n# Encode categorical variables\ndata['Geography'] = data['Geography'].astype('category').cat.codes\ndata['Gender'] = data['Gender'].astype('category').cat.codes\n\n# Separate features and target\nX = data.drop(['CustomerId', 'Surname', 'Exited'], axis=1)\ny = data['Exited']\n\n# Compare churners and non-churners\nchurners = data[data['Exited'] == 1]\nnon_churners = data[data['Exited'] == 0]\n\n# Statistical tests for numerical features\nfor col in X.columns:\n    stat, p_val = ttest_ind(churners[col], non_churners[col], equal_var=False)\n    print(f\"{col}: t-statistic={stat:.2f}, p-value={p_val:.2e}\")\n\n# Example: Plot distributions for balance\nsns.histplot(churners['Balance'], color='red', label='Churners', kde=True)\nsns.histplot(non_churners['Balance'], color='blue', label='Non-Churners', kde=True)\nplt.legend()\nplt.title('Balance Distribution')\nplt.show()\n\n# Predictive Modeling: Random Forest\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n\nrf_model = RandomForestClassifier(random_state=42)\nrf_model.fit(X_train, y_train)\ny_pred = rf_model.predict(X_test)\n\nprint(\"Random Forest Classification Report:\\n\", classification_report(y_test, y_pred))\n\n# Feature Importance\nfeature_importances = pd.DataFrame({\n    'Feature': X.columns,\n    'Importance': rf_model.feature_importances_\n}).sort_values(by='Importance', ascending=False)\n\nprint(feature_importances)\n\nCreditScore: t-statistic=-2.63, p-value=8.46e-03\nGeography: t-statistic=3.86, p-value=1.15e-04\nGender: t-statistic=-10.69, p-value=3.27e-26\nAge: t-statistic=30.42, p-value=4.71e-179\nTenure: t-statistic=-1.38, p-value=1.66e-01\nBalance: t-statistic=12.47, p-value=6.32e-35\nNumOfProducts: t-statistic=-3.70, p-value=2.19e-04\nHasCrCard: t-statistic=-0.71, p-value=4.78e-01\nIsActiveMember: t-statistic=-16.13, p-value=2.38e-56\nEstimatedSalary: t-statistic=1.20, p-value=2.29e-01\n\n\n\n\n\n\n\n\n\nRandom Forest Classification Report:\n               precision    recall  f1-score   support\n\n           0       0.88      0.97      0.92      1593\n           1       0.78      0.46      0.58       407\n\n    accuracy                           0.86      2000\n   macro avg       0.83      0.71      0.75      2000\nweighted avg       0.86      0.86      0.85      2000\n\n           Feature  Importance\n3              Age    0.239934\n9  EstimatedSalary    0.147069\n0      CreditScore    0.144104\n5          Balance    0.141194\n6    NumOfProducts    0.129134\n4           Tenure    0.081958\n8   IsActiveMember    0.039596\n1        Geography    0.038467\n7        HasCrCard    0.019583\n2           Gender    0.018959\n\n\n\n# Churn distribution (Exited = 1 means churned)\nchurn_counts = data['Exited'].value_counts(normalize=True)\nprint(\"Churn Distribution:\\n\", churn_counts)\n\n# Plot churn distribution\nsns.barplot(x=churn_counts.index, y=churn_counts.values, palette=\"coolwarm\")\nplt.title('Churn Distribution')\nplt.xlabel('Churn Status (0 = Non-Churn, 1 = Churn)')\nplt.ylabel('Proportion')\nplt.xticks([0, 1], ['Non-Churn', 'Churn'])\nplt.show()\n\n# Distribution of Age by Churn Status\nsns.histplot(data=data, x='Age', hue='Exited', kde=True, palette=\"coolwarm\", alpha=0.6)\nplt.title('Age Distribution by Churn Status')\nplt.xlabel('Age')\nplt.ylabel('Frequency')\nplt.legend(title='Churn Status', labels=['Non-Churn', 'Churn'])\nplt.show()\n\n# Gender distribution by Churn Status\nsns.countplot(data=data, x='Gender', hue='Exited', palette=\"coolwarm\")\nplt.title('Gender Distribution by Churn Status')\nplt.xlabel('Gender (0 = Male, 1 = Female)')\nplt.ylabel('Count')\nplt.legend(title='Churn Status', labels=['Non-Churn', 'Churn'])\nplt.show()\n\n# Product usage distribution by Churn Status\nsns.boxplot(data=data, x='Exited', y='NumOfProducts', palette=\"coolwarm\")\nplt.title('Number of Products by Churn Status')\nplt.xlabel('Churn Status (0 = Non-Churn, 1 = Churn)')\nplt.ylabel('Number of Products')\nplt.xticks([0, 1], ['Non-Churn', 'Churn'])\nplt.show()\n\n# Balance distribution by Churn Status\nsns.boxplot(data=data, x='Exited', y='Balance', palette=\"coolwarm\")\nplt.title('Account Balance by Churn Status')\nplt.xlabel('Churn Status (0 = Non-Churn, 1 = Churn)')\nplt.ylabel('Balance')\nplt.xticks([0, 1], ['Non-Churn', 'Churn'])\nplt.show()\n\nChurn Distribution:\n Exited\n0    0.7963\n1    0.2037\nName: proportion, dtype: float64\n\n\nFutureWarning: \n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n\n  sns.barplot(x=churn_counts.index, y=churn_counts.values, palette=\"coolwarm\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFutureWarning: \n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n\n  sns.boxplot(data=data, x='Exited', y='NumOfProducts', palette=\"coolwarm\")\n\n\n\n\n\n\n\n\n\nFutureWarning: \n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n\n  sns.boxplot(data=data, x='Exited', y='Balance', palette=\"coolwarm\")\n\n\n\n\n\n\n\n\n\n\n\n# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# 1. ë°ì´í„° ë¡œë“œ\nfile_path = '/content/Bank_Churn.csv'  # CSV íŒŒì¼ ê²½ë¡œ\ndata = pd.read_csv(file_path)\n\n# ë²”ì£¼í˜• ì—´ ìë™ ê°ì§€ í›„ ë³€í™˜\ncategorical_cols = data.select_dtypes(include=['object']).columns\ndata_dummy = pd.get_dummies(data, columns=categorical_cols, drop_first=True)\n\n# 2. ìˆ«ìí˜• ë³€ìˆ˜ ì„ íƒ\nnumeric_data = data.select_dtypes(include=['float64', 'int64'])  # ìˆ«ìí˜• ì—´ë§Œ ì„ íƒ\n\n# 3. ìƒê´€ í–‰ë ¬ ê³„ì‚°\ncorr_matrix = numeric_data.corr()  # ìƒê´€ ê³„ìˆ˜ ê³„ì‚°\n\n# 4. ìƒê´€ í–‰ë ¬ íˆíŠ¸ë§µ ì‹œê°í™”\nplt.figure(figsize=(10, 8))  # ê·¸ë˜í”„ í¬ê¸° ì„¤ì •\nsns.heatmap(\n    corr_matrix,\n    annot=True,  # ìƒê´€ ê³„ìˆ˜ ê°’ í‘œì‹œ\n    fmt=\".2f\",   # ê°’ í‘œì‹œ í˜•ì‹ (ì†Œìˆ˜ì  2ìë¦¬)\n    cmap='coolwarm',  # ìƒ‰ìƒ íŒ”ë ˆíŠ¸\n    cbar=True     # ì»¬ëŸ¬ ë°” í‘œì‹œ\n)\nplt.title(\"Correlation Matrix Heatmap\", fontsize=16)  # ì œëª© ì¶”ê°€\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nfrom scipy.stats import f_oneway\n\n# Churn rate by geography\nchurn_rate_by_geo = data.groupby('Geography')['Exited'].mean()\nprint(churn_rate_by_geo)\n\n# Visualize churn rates\nchurn_rate_by_geo.plot(kind='bar', color=['red', 'blue', 'green'])\nplt.title('Churn Rate by Geography')\nplt.xticks([0, 1, 2], ['France', 'Germany', 'Spain'], rotation=0)\nplt.show()\n\n# ANOVA test for Balance by Geography\nanova_stat, p_val = f_oneway(\n    data[data['Geography'] == 0]['Balance'],\n    data[data['Geography'] == 1]['Balance'],\n    data[data['Geography'] == 2]['Balance']\n)\nprint(f\"ANOVA Test: F-statistic={anova_stat:.2f}, p-value={p_val:.2e}\")\n\nGeography\n0    0.161548\n1    0.324432\n2    0.166734\nName: Exited, dtype: float64\n\n\n\n\n\n\n\n\n\nANOVA Test: F-statistic=958.43, p-value=0.00e+00\n\n\n\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\n\n# Scale features\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\n# Perform PCA for visualization (optional)\npca = PCA(n_components=2)\nX_pca = pca.fit_transform(X_scaled)\n\n# K-Means clustering\nkmeans = KMeans(n_clusters=4, random_state=42)\ndata['Cluster'] = kmeans.fit_predict(X_scaled)\n\n# Visualize clusters\nplt.scatter(X_pca[:, 0], X_pca[:, 1], c=data['Cluster'], cmap='viridis', alpha=0.7)\nplt.title('Customer Segments (PCA)')\nplt.xlabel('PC1')\nplt.ylabel('PC2')\nplt.colorbar(label='Cluster')\nplt.show()\n\n# Cluster profiles\ncluster_profiles = data.groupby('Cluster').mean()\nprint(cluster_profiles)\n\n\n\n\n\n\n\n\n\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\n/usr/local/lib/python3.10/dist-packages/pandas/core/groupby/groupby.py in _agg_py_fallback(self, how, values, ndim, alt)\n   1941         try:\n-&gt; 1942             res_values = self._grouper.agg_series(ser, alt, preserve_dtype=True)\n   1943         except Exception as err:\n\n/usr/local/lib/python3.10/dist-packages/pandas/core/groupby/ops.py in agg_series(self, obj, func, preserve_dtype)\n    863 \n--&gt; 864         result = self._aggregate_series_pure_python(obj, func)\n    865 \n\n/usr/local/lib/python3.10/dist-packages/pandas/core/groupby/ops.py in _aggregate_series_pure_python(self, obj, func)\n    884         for i, group in enumerate(splitter):\n--&gt; 885             res = func(group)\n    886             res = extract_result(res)\n\n/usr/local/lib/python3.10/dist-packages/pandas/core/groupby/groupby.py in &lt;lambda&gt;(x)\n   2453                 \"mean\",\n-&gt; 2454                 alt=lambda x: Series(x, copy=False).mean(numeric_only=numeric_only),\n   2455                 numeric_only=numeric_only,\n\n/usr/local/lib/python3.10/dist-packages/pandas/core/series.py in mean(self, axis, skipna, numeric_only, **kwargs)\n   6548     ):\n-&gt; 6549         return NDFrame.mean(self, axis, skipna, numeric_only, **kwargs)\n   6550 \n\n/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py in mean(self, axis, skipna, numeric_only, **kwargs)\n  12419     ) -&gt; Series | float:\n&gt; 12420         return self._stat_function(\n  12421             \"mean\", nanops.nanmean, axis, skipna, numeric_only, **kwargs\n\n/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py in _stat_function(self, name, func, axis, skipna, numeric_only, **kwargs)\n  12376 \n&gt; 12377         return self._reduce(\n  12378             func, name=name, axis=axis, skipna=skipna, numeric_only=numeric_only\n\n/usr/local/lib/python3.10/dist-packages/pandas/core/series.py in _reduce(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\n   6456                 )\n-&gt; 6457             return op(delegate, skipna=skipna, **kwds)\n   6458 \n\n/usr/local/lib/python3.10/dist-packages/pandas/core/nanops.py in f(values, axis, skipna, **kwds)\n    146             else:\n--&gt; 147                 result = alt(values, axis=axis, skipna=skipna, **kwds)\n    148 \n\n/usr/local/lib/python3.10/dist-packages/pandas/core/nanops.py in new_func(values, axis, skipna, mask, **kwargs)\n    403 \n--&gt; 404         result = func(values, axis=axis, skipna=skipna, mask=mask, **kwargs)\n    405 \n\n/usr/local/lib/python3.10/dist-packages/pandas/core/nanops.py in nanmean(values, axis, skipna, mask)\n    719     the_sum = values.sum(axis, dtype=dtype_sum)\n--&gt; 720     the_sum = _ensure_numeric(the_sum)\n    721 \n\n/usr/local/lib/python3.10/dist-packages/pandas/core/nanops.py in _ensure_numeric(x)\n   1700             # GH#44008, GH#36703 avoid casting e.g. strings to numeric\n-&gt; 1701             raise TypeError(f\"Could not convert string '{x}' to numeric\")\n   1702         try:\n\nTypeError: Could not convert string 'HargraveHillMitchellGerasimovYenMcWilliamsLombardoClarkeOsborneLavineBianchiTylerMartinOkagbueBucchoT'ienClarkHammondBrownlessGlauertPisanoPalermoBallardCavenaghReadPostleBuleyLeonardOnyeoruluOsborneFuDunbabinMauldonParsonsKoWelchChidozieCalabresiZetticciMacDonaldKaodilinakachukwuArthurLiChiaVasinForwoodTaylorMadukweBennelongAlexeevaMacleanChigolumWilkinsonTreacyTaubmanRobinsonHawkinsFuCampbellAshboltRozierOgbonnayaCocciT'aoFordTsaiOnuoraMcDonaldMillerHayLucasSmithPachecoTsaoIfesinachiHughesJessMortonRossiReppertCh'iuFieldingZetticciBoyleWallworkDavidsonO'DonnellAhmedChuangTienHartleySkinnerMcEncroeGordonTs'aiHunterHsiehKnowlesDayTsaoNwabugwuYoungKerrFreemanSeleznyovIkedinachukwuAmosSimmonsRobinsonBianchiChenIbrahimovaNolanScottMonaldoColeAngeloKoTingBlackIkemefunaMorrisonCelisChengOuthwaitePaiMitchellKoFiskChiangHeathDellucciT'angStevensonWeiPisaniMannaRicciCarrFindlayHughesChukwuemekaSwiftRossUspenskyCookNewboldHeHiltonSunEvansPisanoAnkudinovLewisKirbyMartinHsiaWesterbergKryukovaSeleznevaFreemanLoMacleodPisanoMacartneyLuWaltonBrookesShihUkaegbunamDavideBurnsHanReichardPriceRitchieMackenziePendergrassEvansBillsonTengObialoLinMcKayRickardsBegumOnyinyechukwukaMaOkwuadigboChanGrecoLombardiAlexandrovaFallaciMaiStoutDuncanCrawfordGetherLarionovaPaiCraigCh'iuRahmanMcMillanPickeringMiramsMcIntyrePagnottoFengDonaldsonChambersMarceloEjimoforSageseNapolitaniWallaceSmallBledsoeWertheimP'anAchebeRussoMaccallumWatkinsMitchelFerdinandChin...\n\nThe above exception was the direct cause of the following exception:\n\nTypeError                                 Traceback (most recent call last)\n&lt;ipython-input-4-c6a351abe19c&gt; in &lt;cell line: 26&gt;()\n     24 \n     25 # Cluster profiles\n---&gt; 26 cluster_profiles = data.groupby('Cluster').mean()\n     27 print(cluster_profiles)\n\n/usr/local/lib/python3.10/dist-packages/pandas/core/groupby/groupby.py in mean(self, numeric_only, engine, engine_kwargs)\n   2450             )\n   2451         else:\n-&gt; 2452             result = self._cython_agg_general(\n   2453                 \"mean\",\n   2454                 alt=lambda x: Series(x, copy=False).mean(numeric_only=numeric_only),\n\n/usr/local/lib/python3.10/dist-packages/pandas/core/groupby/groupby.py in _cython_agg_general(self, how, alt, numeric_only, min_count, **kwargs)\n   1996             return result\n   1997 \n-&gt; 1998         new_mgr = data.grouped_reduce(array_func)\n   1999         res = self._wrap_agged_manager(new_mgr)\n   2000         if how in [\"idxmin\", \"idxmax\"]:\n\n/usr/local/lib/python3.10/dist-packages/pandas/core/internals/managers.py in grouped_reduce(self, func)\n   1467                 #  while others do not.\n   1468                 for sb in blk._split():\n-&gt; 1469                     applied = sb.apply(func)\n   1470                     result_blocks = extend_blocks(applied, result_blocks)\n   1471             else:\n\n/usr/local/lib/python3.10/dist-packages/pandas/core/internals/blocks.py in apply(self, func, **kwargs)\n    391         one\n    392         \"\"\"\n--&gt; 393         result = func(self.values, **kwargs)\n    394 \n    395         result = maybe_coerce_values(result)\n\n/usr/local/lib/python3.10/dist-packages/pandas/core/groupby/groupby.py in array_func(values)\n   1993 \n   1994             assert alt is not None\n-&gt; 1995             result = self._agg_py_fallback(how, values, ndim=data.ndim, alt=alt)\n   1996             return result\n   1997 \n\n/usr/local/lib/python3.10/dist-packages/pandas/core/groupby/groupby.py in _agg_py_fallback(self, how, values, ndim, alt)\n   1944             msg = f\"agg function failed [how-&gt;{how},dtype-&gt;{ser.dtype}]\"\n   1945             # preserve the kind of exception that raised\n-&gt; 1946             raise type(err)(msg) from err\n   1947 \n   1948         if ser.dtype == object:\n\nTypeError: agg function failed [how-&gt;mean,dtype-&gt;object]\n\n\n\n\n# Import necessary libraries\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.cluster import KMeans\nfrom sklearn.decomposition import PCA\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Load the dataset\ndata = pd.read_csv('bank_churn.csv')  # Replace with your dataset file path\n\n# Preprocessing for clustering\n# Drop irrelevant columns and encode categorical variables\ndata['Geography'] = data['Geography'].astype('category').cat.codes\ndata['Gender'] = data['Gender'].astype('category').cat.codes\nX = data.drop(['CustomerId', 'Surname', 'Exited'], axis=1)  # Keep only numerical features\n\n# Standardize the features\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\n# K-Means Clustering\n# Define the optimal number of clusters using the Elbow Method\ninertia = []\nrange_n_clusters = range(1, 11)\nfor k in range_n_clusters:\n    kmeans = KMeans(n_clusters=k, random_state=42)\n    kmeans.fit(X_scaled)\n    inertia.append(kmeans.inertia_)\n\n# Plot the Elbow Method\nplt.figure(figsize=(8, 6))\nplt.plot(range_n_clusters, inertia, marker='o')\nplt.title('Elbow Method for Optimal Number of Clusters')\nplt.xlabel('Number of Clusters (k)')\nplt.ylabel('Inertia')\nplt.show()\n\n# Choose the optimal k (based on the elbow plot) and fit K-Means\noptimal_k = 4  # Example, adjust based on the elbow plot\nkmeans = KMeans(n_clusters=optimal_k, random_state=42)\ndata['Cluster'] = kmeans.fit_predict(X_scaled)\n\n# Visualize the clusters using PCA for dimensionality reduction\npca = PCA(n_components=2)\nX_pca = pca.fit_transform(X_scaled)\n\nplt.figure(figsize=(10, 6))\nsns.scatterplot(x=X_pca[:, 0], y=X_pca[:, 1], hue=data['Cluster'], palette='viridis', s=60)\nplt.title('Customer Segments (PCA Visualization)')\nplt.xlabel('Principal Component 1')\nplt.ylabel('Principal Component 2')\nplt.legend(title='Cluster')\nplt.show()\n\n# Ensure only numeric columns are included in the analysis\nnumeric_data = data.select_dtypes(include=[float, int])\n\n# Include the cluster column for grouping\nnumeric_data['Cluster'] = data['Cluster']\n\n# Compute cluster profiles\ncluster_profiles = numeric_data.groupby('Cluster').mean()\n\nprint(\"Cluster Profiles:\\n\", cluster_profiles)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCluster Profiles:\n            CustomerId  CreditScore        Age    Tenure        Balance  \\\nCluster                                                                  \n0        1.569082e+07   650.592581  39.685641  4.929325  103679.746658   \n1        1.569068e+07   650.840863  37.984534  5.075295    9411.432112   \n2        1.569022e+07   649.755751  39.240903  4.984944  105665.965926   \n3        1.569228e+07   650.964444  38.502716  5.098765   81422.771284   \n\n         NumOfProducts  HasCrCard  IsActiveMember  EstimatedSalary    Exited  \nCluster                                                                       \n0             1.266390   0.701311        0.494404    100726.031871  0.291653  \n1             2.121286   0.715100        0.530729     99748.752515  0.118030  \n2             1.128816   0.706399        0.501464     99839.175186  0.229611  \n3             1.694321   0.699259        0.544198     99819.231778  0.141235  \n\n\n\n# Import necessary libraries\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.metrics import classification_report, accuracy_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\n\n# Step 1: Load dataset\ndata = pd.read_csv('bank_churn.csv')  # Replace with your dataset file path\n\n# Step 2: Data Preprocessing\n# Encode categorical variables\nle_geography = LabelEncoder()\nle_gender = LabelEncoder()\ndata['Geography'] = le_geography.fit_transform(data['Geography'])\ndata['Gender'] = le_gender.fit_transform(data['Gender'])\n\n# Define features (X) and target (y)\nX = data.drop(['CustomerId', 'Surname', 'Exited'], axis=1)  # Drop irrelevant columns\ny = data['Exited']\n\n# Split dataset into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n\n# Standardize the features\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Step 3: Logistic Regression\nlog_model = LogisticRegression(random_state=42)\nlog_model.fit(X_train_scaled, y_train)\n\ny_pred_log = log_model.predict(X_test_scaled)\n\nprint(\"Logistic Regression Classification Report:\\n\", classification_report(y_test, y_pred_log))\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred_log))\n\n# Step 4: Naive Bayes\nnb_model = GaussianNB()\nnb_model.fit(X_train_scaled, y_train)\n\ny_pred_nb = nb_model.predict(X_test_scaled)\n\nprint(\"Naive Bayes Classification Report:\\n\", classification_report(y_test, y_pred_nb))\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred_nb))\n\n# Step 5: Decision Tree\ndt_model = DecisionTreeClassifier(max_depth=5, random_state=42)\ndt_model.fit(X_train, y_train)\n\ny_pred_dt = dt_model.predict(X_test)\n\nprint(\"Decision Tree Classification Report:\\n\", classification_report(y_test, y_pred_dt))\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred_dt))\n\n\nLogistic Regression Classification Report:\n               precision    recall  f1-score   support\n\n           0       0.82      0.97      0.89      1593\n           1       0.59      0.14      0.23       407\n\n    accuracy                           0.81      2000\n   macro avg       0.70      0.56      0.56      2000\nweighted avg       0.77      0.81      0.75      2000\n\nAccuracy: 0.805\nNaive Bayes Classification Report:\n               precision    recall  f1-score   support\n\n           0       0.83      0.98      0.90      1593\n           1       0.76      0.24      0.36       407\n\n    accuracy                           0.83      2000\n   macro avg       0.79      0.61      0.63      2000\nweighted avg       0.82      0.83      0.79      2000\n\nAccuracy: 0.829\nDecision Tree Classification Report:\n               precision    recall  f1-score   support\n\n           0       0.86      0.98      0.91      1593\n           1       0.80      0.37      0.51       407\n\n    accuracy                           0.85      2000\n   macro avg       0.83      0.68      0.71      2000\nweighted avg       0.85      0.85      0.83      2000\n\nAccuracy: 0.854\n\n\n\n# Ivy part\npreprocessed_data = pd.read_csv('preprocessed_data.csv')\n# Import required libraries\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nimport pandas as pd\n\n# Split the data into features (X) and target (y)\nX = preprocessed_data.drop('Exited', axis=1)\ny = preprocessed_data['Exited']\n\n# Split the dataset into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n\n# Dictionary to store model results\nmodel_results = {}\n\n# Function to train and evaluate models\ndef train_and_evaluate_model(model, model_name):\n    # Train the model\n    model.fit(X_train, y_train)\n    # Make predictions\n    y_pred = model.predict(X_test)\n    # Calculate accuracy\n    acc = accuracy_score(y_test, y_pred)\n    # Confusion Matrix\n    conf_matrix = confusion_matrix(y_test, y_pred)\n    # Classification Report\n    class_report = classification_report(y_test, y_pred)\n    # Store results\n    model_results[model_name] = {\n        \"Accuracy\": acc,\n        \"Confusion Matrix\": conf_matrix,\n        \"Classification Report\": class_report\n    }\n    return model\n\n# Train and evaluate models\n# Random Forest\nrf_model = train_and_evaluate_model(RandomForestClassifier(random_state=42), \"Random Forest\")\n\n# Logistic Regression\nlr_model = train_and_evaluate_model(LogisticRegression(max_iter=500, random_state=42), \"Logistic Regression\")\n\n# Naive Bayes\nnb_model = train_and_evaluate_model(GaussianNB(), \"Naive Bayes\")\n\n# Decision Tree\ndt_model = train_and_evaluate_model(DecisionTreeClassifier(random_state=42), \"Decision Tree\")\n\n# Display results for each model\nfor model_name, results in model_results.items():\n    print(f\"--- {model_name} ---\")\n    print(f\"Accuracy: {results['Accuracy']}\")\n    #print(f\"Confusion Matrix:\\n{results['Confusion Matrix']}\")\n    print(f\"Classification Report:\\n{results['Classification Report']}\")\n    print(\"\\n\")\n\n--- Random Forest ---\nAccuracy: 0.8645\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.88      0.97      0.92      1593\n           1       0.78      0.46      0.58       407\n\n    accuracy                           0.86      2000\n   macro avg       0.83      0.71      0.75      2000\nweighted avg       0.86      0.86      0.85      2000\n\n\n\n--- Logistic Regression ---\nAccuracy: 0.8095\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.82      0.97      0.89      1593\n           1       0.60      0.19      0.29       407\n\n    accuracy                           0.81      2000\n   macro avg       0.71      0.58      0.59      2000\nweighted avg       0.78      0.81      0.77      2000\n\n\n\n--- Naive Bayes ---\nAccuracy: 0.7865\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.80      0.97      0.88      1593\n           1       0.36      0.06      0.11       407\n\n    accuracy                           0.79      2000\n   macro avg       0.58      0.52      0.49      2000\nweighted avg       0.71      0.79      0.72      2000\n\n\n\n--- Decision Tree ---\nAccuracy: 0.783\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.87      0.85      0.86      1593\n           1       0.47      0.51      0.49       407\n\n    accuracy                           0.78      2000\n   macro avg       0.67      0.68      0.68      2000\nweighted avg       0.79      0.78      0.79      2000\n\n\n\n\n\n/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n\n\n\n# Ivy part\n# # SMOTE\n# Import required libraries\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nimport pandas as pd\n\n# Split the data into features (X) and target (y)\nX = preprocessed_data.drop('Exited', axis=1)\ny = preprocessed_data['Exited']\n\n# Apply SMOTE to balance the dataset\nsmote = SMOTE(random_state=42)\nX_resampled, y_resampled = smote.fit_resample(X, y)\n\n# Split the resampled dataset into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(\n    X_resampled, y_resampled, test_size=0.2, random_state=42, stratify=y_resampled\n)\n\n# Dictionary to store model results\nmodel_results_smote = {}\n\n# Function to train and evaluate models\ndef train_and_evaluate_model(model, model_name):\n    # Train the model\n    model.fit(X_train, y_train)\n    # Make predictions\n    y_pred = model.predict(X_test)\n    # Calculate accuracy\n    acc = accuracy_score(y_test, y_pred)\n    # Confusion Matrix\n    conf_matrix = confusion_matrix(y_test, y_pred)\n    # Classification Report\n    class_report = classification_report(y_test, y_pred)\n    # Store results\n    model_results_smote[model_name] = {\n        \"Accuracy\": acc,\n        \"Confusion Matrix\": conf_matrix,\n        \"Classification Report\": class_report\n    }\n    return model\n\n# Train and evaluate models\n# Random Forest\nrf_model_smote = train_and_evaluate_model(RandomForestClassifier(random_state=42), \"Random Forest (SMOTE)\")\n\n# Logistic Regression\nlr_model_smote = train_and_evaluate_model(LogisticRegression(max_iter=500, random_state=42), \"Logistic Regression (SMOTE)\")\n\n# Naive Bayes\nnb_model_smote = train_and_evaluate_model(GaussianNB(), \"Naive Bayes (SMOTE)\")\n\n# Decision Tree\ndt_model_smote = train_and_evaluate_model(DecisionTreeClassifier(random_state=42), \"Decision Tree (SMOTE)\")\n\n# Display results for each model\nfor model_name, results in model_results_smote.items():\n    print(f\"--- {model_name} ---\")\n    print(f\"Accuracy: {results['Accuracy']}\")\n    print(f\"Confusion Matrix:\\n{results['Confusion Matrix']}\")\n    print(f\"Classification Report:\\n{results['Classification Report']}\")\n    print(\"\\n\")\n\n/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n\n\n--- Random Forest (SMOTE) ---\nAccuracy: 0.8612680477087257\nConfusion Matrix:\n[[1393  200]\n [ 242 1351]]\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.85      0.87      0.86      1593\n           1       0.87      0.85      0.86      1593\n\n    accuracy                           0.86      3186\n   macro avg       0.86      0.86      0.86      3186\nweighted avg       0.86      0.86      0.86      3186\n\n\n\n--- Logistic Regression (SMOTE) ---\nAccuracy: 0.7727558066541117\nConfusion Matrix:\n[[1239  354]\n [ 370 1223]]\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.77      0.78      0.77      1593\n           1       0.78      0.77      0.77      1593\n\n    accuracy                           0.77      3186\n   macro avg       0.77      0.77      0.77      3186\nweighted avg       0.77      0.77      0.77      3186\n\n\n\n--- Naive Bayes (SMOTE) ---\nAccuracy: 0.7115505335844319\nConfusion Matrix:\n[[1084  509]\n [ 410 1183]]\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.73      0.68      0.70      1593\n           1       0.70      0.74      0.72      1593\n\n    accuracy                           0.71      3186\n   macro avg       0.71      0.71      0.71      3186\nweighted avg       0.71      0.71      0.71      3186\n\n\n\n--- Decision Tree (SMOTE) ---\nAccuracy: 0.7875078468298807\nConfusion Matrix:\n[[1228  365]\n [ 312 1281]]\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.80      0.77      0.78      1593\n           1       0.78      0.80      0.79      1593\n\n    accuracy                           0.79      3186\n   macro avg       0.79      0.79      0.79      3186\nweighted avg       0.79      0.79      0.79      3186\n\n\n\n\n\n\n#Jess\n# L1 regularization on logistic regression\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy.stats import ttest_ind, chi2_contingency\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report\n\npreprocessed_data = pd.read_csv('/content/preprocessed_data.csv')\n# Import required libraries\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nimport pandas as pd\n\n# Split the data into features (X) and target (y)\nX = preprocessed_data.drop('Exited', axis=1)\ny = preprocessed_data['Exited']\n\n# Split the dataset into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n\n# Dictionary to store model results\nmodel_results = {}\n\n# Function to train and evaluate models\ndef train_and_evaluate_model(model, model_name):\n    # Train the model\n    model.fit(X_train, y_train)\n    # Make predictions\n    y_pred = model.predict(X_test)\n    # Calculate accuracy\n    acc = accuracy_score(y_test, y_pred)\n    # Confusion Matrix\n    conf_matrix = confusion_matrix(y_test, y_pred)\n    # Classification Report\n    class_report = classification_report(y_test, y_pred)\n    # Store results\n    model_results[model_name] = {\n        \"Accuracy\": acc,\n        \"Confusion Matrix\": conf_matrix,\n        \"Classification Report\": class_report\n    }\n    return model\n\n# Logistic Regression with L1 Regularization\nlr_l1_model = train_and_evaluate_model(\n    LogisticRegression(\n        penalty='l1',  # Use L1 regularization\n        solver='liblinear',  # Required solver for L1 regularization\n        max_iter=500,\n        random_state=42\n    ),\n    \"Logistic Regression (L1 Regularization)\"\n)\n\n\n# Train and evaluate models\n# Random Forest\nrf_model = train_and_evaluate_model(RandomForestClassifier(random_state=42), \"Random Forest\")\n\n# Logistic Regression\nlr_l1_model = train_and_evaluate_model(\n    LogisticRegression(penalty='l1', solver='liblinear', max_iter=500, random_state=42),\n    \"Logistic Regression (L1 Regularization)\"\n)\n\n# Naive Bayes\nnb_model = train_and_evaluate_model(GaussianNB(), \"Naive Bayes\")\nfrom sklearn.model_selection import GridSearchCV\n\n# Decision Tree with Pruning\ndt_pruned_model = train_and_evaluate_model(\n    DecisionTreeClassifier(max_depth=5, min_samples_split=10, min_samples_leaf=5, random_state=42),\n    \"Decision Tree (Pruned)\"\n)\n\n\n# Display results for each model\nfor model_name, results in model_results.items():\n    print(f\"--- {model_name} ---\")\n    print(f\"Accuracy: {results['Accuracy']}\")\n    #print(f\"Confusion Matrix:\\n{results['Confusion Matrix']}\")\n    print(f\"Classification Report:\\n{results['Classification Report']}\")\n    print(\"\\n\")\n\n--- Logistic Regression (L1 Regularization) ---\nAccuracy: 0.8085\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.82      0.97      0.89      1593\n           1       0.60      0.18      0.28       407\n\n    accuracy                           0.81      2000\n   macro avg       0.71      0.58      0.59      2000\nweighted avg       0.78      0.81      0.77      2000\n\n\n\n--- Random Forest ---\nAccuracy: 0.8645\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.88      0.97      0.92      1593\n           1       0.78      0.46      0.58       407\n\n    accuracy                           0.86      2000\n   macro avg       0.83      0.71      0.75      2000\nweighted avg       0.86      0.86      0.85      2000\n\n\n\n--- Naive Bayes ---\nAccuracy: 0.7865\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.80      0.97      0.88      1593\n           1       0.36      0.06      0.11       407\n\n    accuracy                           0.79      2000\n   macro avg       0.58      0.52      0.49      2000\nweighted avg       0.71      0.79      0.72      2000\n\n\n\n--- Decision Tree (Pruned) ---\nAccuracy: 0.856\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.86      0.97      0.91      1593\n           1       0.79      0.40      0.53       407\n\n    accuracy                           0.86      2000\n   macro avg       0.83      0.69      0.72      2000\nweighted avg       0.85      0.86      0.84      2000\n\n\n\n\n\n\n#Jess\n# PCA for Random Forest\nfrom sklearn.decomposition import PCA\nfrom sklearn.pipeline import Pipeline\n\n# Number of principal components to retain (e.g., retain 95% variance or a fixed number of components)\nn_components = 10  # Adjust based on your dataset\n\n# Create a pipeline with PCA and Random Forest\npipeline = Pipeline([\n    ('pca', PCA(n_components=n_components, random_state=42)),\n    ('rf', RandomForestClassifier(random_state=42))\n])\n\n# Train the pipeline\npipeline.fit(X_train, y_train)\n\n# Make predictions\ny_pred = pipeline.predict(X_test)\n\n# Evaluate the model\nacc = accuracy_score(y_test, y_pred)\nconf_matrix = confusion_matrix(y_test, y_pred)\nclass_report = classification_report(y_test, y_pred)\n\n# Display results\nprint(\"--- Random Forest with PCA ---\")\nprint(f\"Accuracy: {acc}\")\nprint(f\"Confusion Matrix:\\n{conf_matrix}\")\nprint(f\"Classification Report:\\n{class_report}\")\n\n\n\n--- Random Forest with PCA ---\nAccuracy: 0.8545\nConfusion Matrix:\n[[1519   74]\n [ 217  190]]\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.88      0.95      0.91      1593\n           1       0.72      0.47      0.57       407\n\n    accuracy                           0.85      2000\n   macro avg       0.80      0.71      0.74      2000\nweighted avg       0.84      0.85      0.84      2000\n\n\n\n\n#Jess\n# PCA for Naive Bayes\nfrom sklearn.decomposition import PCA\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n\n# Number of principal components to retain\nn_components = 10  # Adjust based on dataset\n\n# Create a pipeline with PCA and Naive Bayes\npipeline = Pipeline([\n    ('pca', PCA(n_components=n_components, random_state=42)),\n    ('nb', GaussianNB())\n])\n\n# Train the pipeline\npipeline.fit(X_train, y_train)\n\n# Make predictions\ny_pred = pipeline.predict(X_test)\n\n# Evaluate the model\nacc = accuracy_score(y_test, y_pred)\nconf_matrix = confusion_matrix(y_test, y_pred)\nclass_report = classification_report(y_test, y_pred)\n\n# Display results\nprint(\"--- Naive Bayes with PCA ---\")\nprint(f\"Accuracy: {acc}\")\nprint(f\"Confusion Matrix:\\n{conf_matrix}\")\nprint(f\"Classification Report:\\n{class_report}\")\n\n--- Naive Bayes with PCA ---\nAccuracy: 0.783\nConfusion Matrix:\n[[1547   46]\n [ 388   19]]\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.80      0.97      0.88      1593\n           1       0.29      0.05      0.08       407\n\n    accuracy                           0.78      2000\n   macro avg       0.55      0.51      0.48      2000\nweighted avg       0.70      0.78      0.71      2000\n\n\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix\n\ndef plot_confusion_matrix(y_test, y_pred, model_name):\n    \"\"\"Plot confusion matrix as a heatmap.\"\"\"\n    cm = confusion_matrix(y_test, y_pred)\n    plt.figure(figsize=(8, 6))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['No Churn', 'Churn'], yticklabels=['No Churn', 'Churn'])\n    plt.title(f'Confusion Matrix for {model_name}')\n    plt.xlabel('Predicted')\n    plt.ylabel('Actual')\n    plt.show()\n\n\n# Confusion Matrix for Logistic Regression\nplot_confusion_matrix(y_test, y_pred_log, \"Logistic Regression\")\n\n# Logistic Regression Feature Importance (Coefficients)\ncoefficients = pd.DataFrame({\n    'Feature': X.columns,\n    'Coefficient': log_model.coef_[0]\n}).sort_values(by='Coefficient', ascending=False)\n\n# Plot coefficients\nplt.figure(figsize=(10, 6))\nsns.barplot(x='Coefficient', y='Feature', data=coefficients, palette='viridis')\nplt.title('Feature Importance (Logistic Regression Coefficients)')\nplt.xlabel('Coefficient Value')\nplt.ylabel('Feature')\nplt.show()\n\n\n\n\n\n\n\n\nFutureWarning: \n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n\n  sns.barplot(x='Coefficient', y='Feature', data=coefficients, palette='viridis')\n\n\n\n\n\n\n\n\n\n\n# Confusion Matrix for Naive Bayes\nplot_confusion_matrix(y_test, y_pred_nb, \"Naive Bayes\")\n\n# Naive Bayes does not provide direct feature importance visualization.\n# You can interpret probabilities, but this is not visualized in standard models.\n\n\n\n\n\n\n\n\n\nfrom sklearn.tree import plot_tree\n\n# Confusion Matrix for Decision Tree\nplot_confusion_matrix(y_test, y_pred_dt, \"Decision Tree\")\n\n# Visualize Decision Tree\nplt.figure(figsize=(20, 10))\nplot_tree(dt_model, feature_names=X.columns, class_names=['No Churn', 'Churn'], filled=True)\nplt.title(\"Decision Tree Visualization\")\nplt.show()\n\n# Feature Importance for Decision Tree\ndt_importance = pd.DataFrame({\n    'Feature': X.columns,\n    'Importance': dt_model.feature_importances_\n}).sort_values(by='Importance', ascending=False)\n\n# Plot feature importance\nplt.figure(figsize=(10, 6))\nsns.barplot(x='Importance', y='Feature', data=dt_importance, palette='coolwarm')\nplt.title('Feature Importance (Decision Tree)')\nplt.xlabel('Importance Score')\nplt.ylabel('Feature')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFutureWarning: \n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n\n  sns.barplot(x='Importance', y='Feature', data=dt_importance, palette='coolwarm')\n\n\n\n\n\n\n\n\n\n\n# Calculate mean and variance of 'CreditScore' for each class in the target variable 'Exited'\ncredit_score_stats = data.groupby('Exited')['CreditScore'].agg(['mean', 'var'])\n\nclass_probabilities = data['Exited'].value_counts(normalize=True).rename(\"P(Class)\").sort_index()\ncredit_score_stats['P(Class)'] = class_probabilities\n\ncredit_score_stats\n\n\n  \n    \n\n\n\n\n\n\nmean\nvar\nP(Class)\n\n\nExited\n\n\n\n\n\n\n\n0\n651.853196\n9149.656542\n0.7963\n\n\n1\n645.351497\n10064.403894\n0.2037\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n\n  \n    \n    \n\n  \n    \n  \n    \n    \n  \n\n    \n  \n\n\n\n#P(Geography|Exited)\ngeo_exited_counts = data.groupby(['Geography', 'Exited']).size()\nexited_counts = data['Exited'].value_counts()\ngeo_given_exited = geo_exited_counts / exited_counts\ngeo_given_exited_table = geo_given_exited.unstack()\n\nprint(geo_given_exited_table)\n\nExited            0         1\nGeography                    \n0          0.527942  0.397644\n1          0.212859  0.399607\n2          0.259199  0.202749\n\n\n\n#P(Balance|Exited)\nimport numpy as np\ndef gaussian_probability(x, mean, var):\n    return (1 / np.sqrt(2 * np.pi * var)) * np.exp(-((x - mean) ** 2) / (2 * var))\n\nbalance_stats = data.groupby('Exited')['Balance'].agg(['mean', 'var'])\n\n#Specify a balance value for which to calculate the probabilities\nbalance_value = 50000  # Example balance value\n\nbalance_given_exited = {\n    class_label: gaussian_probability(balance_value, row['mean'], row['var'])\n    for class_label, row in balance_stats.iterrows()\n}\n\nprint(balance_given_exited)\n\n{0: 5.945340348787947e-06, 1: 5.333952035061307e-06}\n\n\n\n#P(Age|Exited)\nimport numpy as np\ndef gaussian_probability(x, mean, var):\n    return (1 / np.sqrt(2 * np.pi * var)) * np.exp(-((x - mean) ** 2) / (2 * var))\n\nage_stats = data.groupby('Exited')['Age'].agg(['mean', 'var'])\n\n#Specify an age value for which to calculate the probabilities\nage_value = 40  # Example age value\n\nage_given_exited = {\n    class_label: gaussian_probability(age_value, row['mean'], row['var'])\n    for class_label, row in age_stats.iterrows()\n}\n\nprint(age_given_exited)\n\n{0: 0.038130613680163516, 1: 0.03614527361626094}\n\n\n\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# 1. ë°ì´í„° ë¡œë“œ\nfile_path = '/content/Bank_Churn.csv'  # ì ì ˆí•œ íŒŒì¼ ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš”\ndata = pd.read_csv(file_path)\n\n# 2. ê·¸ë˜í”„ ìŠ¤íƒ€ì¼ ì„¤ì •\nsns.set_style(\"whitegrid\")\n\n# 3. ê·¸ë˜í”„ ìƒì„±\nfig, axes = plt.subplots(2, 2, figsize=(14, 10))  # 2x2 ì„œë¸Œí”Œë¡¯\n\n# ìˆ«ì ê°’ í‘œì‹œ í•¨ìˆ˜ ì •ì˜\ndef add_counts(ax):\n    \"\"\"ë§‰ëŒ€ ìœ„ì— ìˆ«ì ê°’ ì¶”ê°€\"\"\"\n    for container in ax.containers:\n        ax.bar_label(container, fmt='%d', label_type='edge', fontsize=9, padding=3)\n\n# (a) Gender vs Exited\nax = sns.countplot(x='Gender', hue='Exited', data=data, ax=axes[0, 0], palette='coolwarm')\nadd_counts(ax)\naxes[0, 0].set_title(\"(a) Gender vs Exited\")\naxes[0, 0].set_xlabel(\"Gender\")\naxes[0, 0].set_ylabel(\"Count\")\n\n# (b) HasCrCard vs Exited\nax = sns.countplot(x='HasCrCard', hue='Exited', data=data, ax=axes[0, 1], palette='coolwarm')\nadd_counts(ax)\naxes[0, 1].set_title(\"(b) HasCrCard vs Exited\")\naxes[0, 1].set_xlabel(\"HasCrCard\")\naxes[0, 1].set_ylabel(\"Count\")\n\n# (c) IsActiveMember vs Exited\nax = sns.countplot(x='IsActiveMember', hue='Exited', data=data, ax=axes[1, 0], palette='coolwarm')\nadd_counts(ax)\naxes[1, 0].set_title(\"(c) IsActiveMember vs Exited\")\naxes[1, 0].set_xlabel(\"IsActiveMember\")\naxes[1, 0].set_ylabel(\"Count\")\n\n# (d) Geography (Countries) vs Exited\nax = sns.countplot(x='Geography', hue='Exited', data=data, ax=axes[1, 1], palette='coolwarm')\nadd_counts(ax)\naxes[1, 1].set_title(\"(d) Geography vs Exited\")\naxes[1, 1].set_xlabel(\"Countries\")\naxes[1, 1].set_ylabel(\"Count\")\n\n# 4. ë ˆì´ì•„ì›ƒ ì¡°ì • ë° ì¶œë ¥\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n# Import necessary libraries\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\n\n# Load the dataset\ndata = pd.read_csv('bank_churn.csv')  # Replace with your dataset file path\n\n# Encode categorical variables\nle_geography = LabelEncoder()\nle_gender = LabelEncoder()\ndata['Geography'] = le_geography.fit_transform(data['Geography'])\ndata['Gender'] = le_gender.fit_transform(data['Gender'])\n\n# Define features (X) and target (y)\nX = data.drop(['CustomerId', 'Surname', 'Exited'], axis=1)  # Drop irrelevant columns\ny = data['Exited']\n\n# Split dataset into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n\n# Standardize the features\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Train Logistic Regression Model\nlog_model = LogisticRegression(random_state=42, max_iter=500)\nlog_model.fit(X_train_scaled, y_train)\n\n# Predictions\ny_pred_log = log_model.predict(X_test_scaled)\n\n# Confusion Matrix\ncm_log = confusion_matrix(y_test, y_pred_log)\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm_log, annot=True, fmt='d', cmap='Blues', xticklabels=['No Churn', 'Churn'], yticklabels=['No Churn', 'Churn'])\nplt.title('Confusion Matrix - Logistic Regression')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.show()\n\n# Classification Report\nprint(\"Classification Report - Logistic Regression:\\n\", classification_report(y_test, y_pred_log))\n\n# Feature Importance (Coefficients)\ncoefficients = pd.DataFrame({\n    'Feature': X.columns,\n    'Coefficient': log_model.coef_[0]\n}).sort_values(by='Coefficient', ascending=False)\n\n# Plot Feature Importance\nplt.figure(figsize=(10, 6))\nsns.barplot(x='Coefficient', y='Feature', data=coefficients, palette='viridis')\nplt.title('Feature Importance - Logistic Regression')\nplt.xlabel('Coefficient Value')\nplt.ylabel('Feature')\nplt.show()\n\n\n\n\n\n\n\n\nClassification Report - Logistic Regression:\n               precision    recall  f1-score   support\n\n           0       0.82      0.97      0.89      1593\n           1       0.59      0.14      0.23       407\n\n    accuracy                           0.81      2000\n   macro avg       0.70      0.56      0.56      2000\nweighted avg       0.77      0.81      0.75      2000\n\n\n\nFutureWarning: \n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n\n  sns.barplot(x='Coefficient', y='Feature', data=coefficients, palette='viridis')\n\n\n\n\n\n\n\n\n\n\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Train Random Forest Model\nrf_model = RandomForestClassifier(n_estimators=100, random_state=42)\nrf_model.fit(X_train, y_train)\n\n# Predictions\ny_pred_rf = rf_model.predict(X_test)\n\n# Confusion Matrix\ncm_rf = confusion_matrix(y_test, y_pred_rf)\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm_rf, annot=True, fmt='d', cmap='Blues', xticklabels=['No Churn', 'Churn'], yticklabels=['No Churn', 'Churn'])\nplt.title('Confusion Matrix - Random Forest')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.show()\n\n# Classification Report\nprint(\"Classification Report - Random Forest:\\n\", classification_report(y_test, y_pred_rf))\n\n# Feature Importance\nrf_importances = pd.DataFrame({\n    'Feature': X.columns,\n    'Importance': rf_model.feature_importances_\n}).sort_values(by='Importance', ascending=False)\n\n# Plot Feature Importance\nplt.figure(figsize=(10, 6))\nsns.barplot(x='Importance', y='Feature', data=rf_importances, palette='coolwarm')\nplt.title('Feature Importance - Random Forest')\nplt.xlabel('Importance Score')\nplt.ylabel('Feature')\nplt.show()\n\n\n\n\n\n\n\n\nClassification Report - Random Forest:\n               precision    recall  f1-score   support\n\n           0       0.88      0.97      0.92      1593\n           1       0.78      0.46      0.58       407\n\n    accuracy                           0.86      2000\n   macro avg       0.83      0.71      0.75      2000\nweighted avg       0.86      0.86      0.85      2000\n\n\n\nFutureWarning: \n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n\n  sns.barplot(x='Importance', y='Feature', data=rf_importances, palette='coolwarm')"
  },
  {
    "objectID": "projects/Netflix Recommendation/NLP_group_8_project.html",
    "href": "projects/Netflix Recommendation/NLP_group_8_project.html",
    "title": "tfidf",
    "section": "",
    "text": "import pandas as pd\nimport re\n\n# Load dataset\ndf = pd.read_csv('/content/netflix_titles.csv', encoding='ISO-8859-1')\n\n# --------------------------------\n# Step 1: Create 'year' column based on 'rating'\n# --------------------------------\nrating_to_year = {\n    'G': 0, 'PG': 10, 'PG-13': 13, 'R': 17, 'NC-17': 18,\n    'NR': 0, 'UR': 0, 'TV-Y': 0, 'TV-Y7': 7, 'TV-Y7-FV': 7,\n    'TV-G': 0, 'TV-PG': 10, 'TV-14': 14, 'TV-MA': 17\n}\n\n# Map the 'rating' column to the new 'year' column\ndf['year'] = df['rating'].map(rating_to_year).fillna(0).astype(int)\n\n# --------------------------------\n# Step 2: Remove non-English words from 'description'\n# --------------------------------\n# Function to remove non-English words\ndef clean_description(text):\n    if pd.isna(text):  # Handle NaN values\n        return \"\"\n    # Keep only English characters (letters, numbers, punctuation)\n    return re.sub(r'[^a-zA-Z0-9.,!?\\'\" ]', '', text)\n\n# Apply cleaning function to 'description'\ndf['description'] = df['description'].apply(clean_description)\n\n# --------------------------------\n# Display cleaned data\n# --------------------------------\nprint(df[['rating', 'year', 'description']].head(10))\n\n# Optional: Save the cleaned data to a new CSV file\ndf.to_csv('/content/netflix_titles_cleaned.csv', index=False)\n\n  rating  year                                        description\n0  PG-13    13  As her father nears the end of his life, filmm...\n1  TV-MA    17  After crossing paths at a party, a Cape Town t...\n2  TV-MA    17  To protect his family from a powerful drug lor...\n3  TV-MA    17  Feuds, flirtations and toilet talk go down amo...\n4  TV-MA    17  In a city of coaching centers known to train I...\n5  TV-MA    17  The arrival of a charismatic young priest brin...\n6     PG    10  Equestria's divided. But a brighteyed hero bel...\n7  TV-MA    17  On a photo shoot in Ghana, an American model s...\n8  TV-14    14  A talented batch of amateur bakers face off in...\n9  PG-13    13  A woman adjusting to life after a loss contend...\n\n\n\nimport pandas as pd\nimport numpy as np\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom sklearn.preprocessing import MinMaxScaler\n\n\n!pip install matplotlib\nimport matplotlib.pyplot as plt\n\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\nRequirement already satisfied: contourpy&gt;=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\nRequirement already satisfied: cycler&gt;=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: fonttools&gt;=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\nRequirement already satisfied: kiwisolver&gt;=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\nRequirement already satisfied: numpy&gt;=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.0.2)\nRequirement already satisfied: packaging&gt;=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\nRequirement already satisfied: pillow&gt;=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\nRequirement already satisfied: pyparsing&gt;=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\nRequirement already satisfied: python-dateutil&gt;=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\nRequirement already satisfied: six&gt;=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil&gt;=2.7-&gt;matplotlib) (1.17.0)\n\n\n\ndf = pd.read_csv('/content/netflix_titles.csv', encoding='ISO-8859-1')\n\n\n#data = pd.read_csv('/content/netflix_titles.csv', encoding='iso-8859-1')\n\n\n# Drop columns 'Unnamed: 12' to 'Unnamed: 19'\n# df = df.drop(columns=['Unnamed: 12', 'Unnamed: 13', 'Unnamed: 14', 'Unnamed: 15', 'Unnamed: 16', 'Unnamed: 17', 'Unnamed: 18', 'Unnamed: 19','Unnamed: 20', 'Unnamed: 21','Unnamed: 22', 'Unnamed: 23', 'Unnamed: 24', 'Unnamed: 25'])\n# Display the cleaned DataFrame\ndf.head()\n\n\n  \n    \n\n\n\n\n\n\nshow_id\ntype\ntitle\ndirector\ncast\ncountry\ndate_added\nrelease_year\nrating\nduration\nlisted_in\ndescription\n\n\n\n\n0\ns1\nMovie\nDick Johnson Is Dead\nKirsten Johnson\nNaN\nUnited States\n25-Sep-21\n2020\nPG-13\n90 min\nDocumentaries\nAs her father nears the end of his life, filmm...\n\n\n1\ns2\nTV Show\nBlood & Water\nNaN\nAma Qamata, Khosi Ngema, Gail Mabalane, Thaban...\nSouth Africa\n24-Sep-21\n2021\nTV-MA\n2 Seasons\nInternational TV Shows, TV Dramas, TV Mysteries\nAfter crossing paths at a party, a Cape Town t...\n\n\n2\ns3\nTV Show\nGanglands\nJulien Leclercq\nSami Bouajila, Tracy Gotoas, Samuel Jouy, Nabi...\nNaN\n24-Sep-21\n2021\nTV-MA\n1 Season\nCrime TV Shows, International TV Shows, TV Act...\nTo protect his family from a powerful drug lor...\n\n\n3\ns4\nTV Show\nJailbirds New Orleans\nNaN\nNaN\nNaN\n24-Sep-21\n2021\nTV-MA\n1 Season\nDocuseries, Reality TV\nFeuds, flirtations and toilet talk go down amo...\n\n\n4\ns5\nTV Show\nKota Factory\nNaN\nMayur More, Jitendra Kumar, Ranjan Raj, Alam K...\nIndia\n24-Sep-21\n2021\nTV-MA\n2 Seasons\nInternational TV Shows, Romantic TV Shows, TV ...\nIn a city of coaching centers known to train I...\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n\n    \n  \n\n\n\n# Fill missing values with 'Unknown' for director, cast, and country. Flag the missing values without losing any data (we can always drop missing values if wanted)\ndf['director'] = df['director'].fillna('Unknown')\ndf['cast'] = df['cast'].fillna('Unknown')\ndf['country'] = df['country'].fillna('Unknown')\n\n# Drop duplicate rows based on the 'title' column\ndf = df.drop_duplicates(subset=['title'], keep='first')\n\n\nprint(df['rating'].unique())\n\n['PG-13' 'TV-MA' 'PG' 'TV-14' 'TV-PG' 'TV-Y' 'TV-Y7' 'R' 'TV-G' 'G'\n 'NC-17' '74 min' '84 min' '66 min' 'NR' nan 'TV-Y7-FV' 'UR' 'A']\n\n\n\n# rating= {\n#     \"G\": \"age &gt;= 0\",\n#     \"PG\": \"age &gt;= 10\",\n#     \"PG-13\": \"age &gt;= 13\",\n#     \"R\": \"age &gt;= 17\",\n#     \"NC-17\": \"age &gt;= 18\",\n#     \"NR\": \"Unknown\",\n#     \"UR\": \"Unknown\",\n#     \"TV-Y\": \"age &gt;= 0\",\n#     \"TV-Y7\": \"age &gt;= 7\",\n#     \"TV-Y7-FV\": \"age &gt;= 7\",\n#     \"TV-G\": \"age &gt;= 0\",\n#     \"TV-PG\": \"age &gt;= 10\",\n#     \"TV-14\": \"age &gt;= 14\",\n#     \"TV-MA\": \"age &gt;= 17\",\n# }\n\n\nage_ratings_numeric = {\n    \"G\": \"age &gt;= 0\",\n    \"PG\": \"age &gt;= 10\",\n    \"PG-13\": \"age &gt;= 13\",\n    \"R\": \"age &gt;= 17\",\n    \"NC-17\": \"age &gt;= 18\",\n    \"NR\": \"Unknown\",\n    \"UR\": \"Unknown\",\n    \"TV-Y\": \"age &gt;= 0\",\n    \"TV-Y7\": \"age &gt;= 7\",\n    \"TV-Y7-FV\": \"age &gt;= 7\",\n    \"TV-G\": \"age &gt;= 0\",\n    \"TV-PG\": \"age &gt;= 10\",\n    \"TV-14\": \"age &gt;= 14\",\n    \"TV-MA\": \"age &gt;= 17\",\n}\n\n\ndf = df[df['rating'].isin(age_ratings_numeric.keys())]\n\n\ndf['age_numeric'] = df['rating'].map(age_ratings_numeric)\n\n# Drop \"Unknown\" values\ndf = df[df['age_numeric'] != \"Unknown\"]\n\n# Recalculate counts\nage_counts = df['age_numeric'].value_counts()\n\n# Plot\nplt.figure(figsize=(12,6))\nplt.bar(age_counts.index, age_counts.values, color='royalblue', edgecolor='black')\nplt.xlabel(\"Age Ratings\", fontsize=14)\nplt.ylabel(\"Count\", fontsize=14)\nplt.title(\"Age Distribution of Netflix Content\", fontsize=16)\nplt.xticks(rotation=45, fontsize=12)\nplt.yticks(fontsize=12)\nplt.grid(axis='y', linestyle='--', alpha=0.7)\nplt.show()\n\n\n\n\n\n\n\n\n\n\ncontent_type_distribution = df['type'].value_counts()\n\ncontent_type_distribution.plot(kind='bar', color='royalblue')\nplt.title('Content Type Distribution')\nplt.xlabel('Type')\nplt.ylabel('Count')\nplt.show()\n\n\n\n\n\n\n\n\n\nimport nltk\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nimport string\nfrom nltk.stem import WordNetLemmatizer\nimport string\n\n\nnltk.download('punkt')\nnltk.download('punkt_tab')\nnltk.download('stopwords')\nnltk.download('wordnet')\n\nstop_words = set(stopwords.words('english'))\nlemmatizer = WordNetLemmatizer()\n\n\ndef clean_and_tokenize(text):\n    text = text.lower()\n    tokens = word_tokenize(text)\n    tokens = [word for word in tokens if word.isalnum()]\n    tokens = [word for word in tokens if word not in stop_words]\n    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n    return tokens\n\n\ndf[\"tokenized_description\"] = df[\"description\"].fillna(\"\").apply(clean_and_tokenize)\n\n\ndf[[\"title\", \"tokenized_description\"]].head()\n\n[nltk_data] Downloading package punkt to /root/nltk_data...\n[nltk_data]   Unzipping tokenizers/punkt.zip.\n[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n[nltk_data] Downloading package stopwords to /root/nltk_data...\n[nltk_data]   Unzipping corpora/stopwords.zip.\n[nltk_data] Downloading package wordnet to /root/nltk_data...\n\n\n\n  \n    \n\n\n\n\n\n\ntitle\ntokenized_description\n\n\n\n\n0\nDick Johnson Is Dead\n[father, nears, end, life, filmmaker, kirsten,...\n\n\n1\nBlood & Water\n[crossing, path, party, cape, town, teen, set,...\n\n\n2\nGanglands\n[protect, family, powerful, drug, lord, skille...\n\n\n3\nJailbirds New Orleans\n[feud, flirtation, toilet, talk, go, among, in...\n\n\n4\nKota Factory\n[city, coaching, center, known, train, finest,...\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n\n    \n  \n\n\n\nimport pandas as pd\nimport spacy\nimport re\nimport string\n\n# Load spaCy model\nnlp = spacy.load(\"en_core_web_sm\")\n\n# Prepare stopwords (combining spaCy + NLTK)\nimport nltk\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\n\nstopwords_spacy = spacy.lang.en.stop_words.STOP_WORDS\nstopwords_nltk = set(stopwords.words('english'))\ncustom_stopwords = stopwords_spacy.union(stopwords_nltk)\ncustom_stopwords = custom_stopwords.union({\"netflix\", \"series\", \"season\"})\n\n# Define preprocessing function\ndef preprocess_text_spacy(text):\n    text = re.sub(r'[^\\x00-\\x7F]+', ' ', text)  # remove non-ASCII\n    text = text.strip()\n    doc = nlp(text.lower())\n\n    clean_tokens = []\n    for token in doc:\n        if (\n            token.text not in custom_stopwords\n            and token.text not in string.punctuation\n            and re.search('[a-zA-Z0-9]', token.text)\n        ):\n            clean_tokens.append(token.lemma_)\n\n    return clean_tokens\n\n# Apply preprocessing\ndf['processed_description'] = df['description'].astype(str).apply(preprocess_text_spacy)\n\n# Preview\nprint(df[['description', 'processed_description']].head(10))\n\n[nltk_data] Downloading package stopwords to /root/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n\n\n                                         description  \\\n0  As her father nears the end of his life, filmm...   \n1  After crossing paths at a party, a Cape Town t...   \n2  To protect his family from a powerful drug lor...   \n3  Feuds, flirtations and toilet talk go down amo...   \n4  In a city of coaching centers known to train I...   \n5  The arrival of a charismatic young priest brin...   \n6  Equestria's divided. But a bright-eyed hero be...   \n7  On a photo shoot in Ghana, an American model s...   \n8  A talented batch of amateur bakers face off in...   \n9  A woman adjusting to life after a loss contend...   \n\n                               processed_description  \n0  [father, near, end, life, filmmaker, kirsten, ...  \n1  [cross, path, party, cape, town, teen, set, pr...  \n2  [protect, family, powerful, drug, lord, skille...  \n3  [feuds, flirtation, toilet, talk, incarcerated...  \n4  [city, coaching, center, know, train, india, f...  \n5  [arrival, charismatic, young, priest, bring, g...  \n6  [equestria, divided, bright, eyed, hero, belie...  \n7  [photo, shoot, ghana, american, model, slip, t...  \n8  [talented, batch, amateur, baker, face, 10, we...  \n9  [woman, adjust, life, loss, contend, feisty, b...  \n\n\n\n# Join tokens back into a single string so TF-IDF can handle them easily\ndf['processed_text_str'] = df['processed_description'].apply(lambda tokens: ' '.join(tokens))\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\n# Initialize and fit the TF-IDF vectorizer on the processed descriptions\nvectorizer = TfidfVectorizer()\nX_tfidf = vectorizer.fit_transform(df['processed_text_str'])\nprint(\"TF-IDF matrix shape:\", X_tfidf.shape)  # (number of samples, number of features)\n\n# Get some insights: average TF-IDF weight for each term across the corpus\navg_tfidf = np.mean(X_tfidf.toarray(), axis=0)\ntop_n = 20\ntop_indices = avg_tfidf.argsort()[-top_n:][::-1]\ntop_features = [vectorizer.get_feature_names_out()[i] for i in top_indices]\nprint(\"Top TF-IDF features:\", top_features)\n\nTF-IDF matrix shape: (8715, 15269)\nTop TF-IDF features: ['life', 'young', 'find', 'family', 'woman', 'new', 'man', 'friend', 'love', 'world', 'year', 'take', 'help', 'documentary', 'school', 'old', 'try', 'home', 'father', 'story']\n\n\n\nimport pandas as pd\nimport re\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.preprocessing import LabelEncoder\n\n# Load dataset\ndf = pd.read_csv('/content/netflix_titles.csv', encoding='ISO-8859-1')\n\n# Step 1: Extract Primary Genre\n# Take the first genre listed as the 'primary genre'\ndf['genre'] = df['listed_in'].astype(str).apply(lambda x: x.split(',')[0].strip())\n\n# Step 2: Clean Descriptions\ndef clean_description(text):\n    if pd.isna(text):  # Handle NaN values\n        return \"\"\n    return re.sub(r'[^a-zA-Z0-9.,!?\\'\" ]', '', text)\n\ndf['cleaned_description'] = df['description'].apply(clean_description)\n\n# Step 3: TF-IDF Vectorization\nvectorizer = TfidfVectorizer(stop_words='english', ngram_range=(1, 2), min_df=3, max_df=0.9)\nX = vectorizer.fit_transform(df['cleaned_description'])\n\n# Step 4: Encode Genre Labels\nlabel_encoder = LabelEncoder()\ny = label_encoder.fit_transform(df['genre'])\n\n# Check results\nprint(\"âœ… Sample Data:\")\nprint(df[['title', 'genre', 'cleaned_description']].head(5))\n\nâœ… Sample Data:\n                   title                   genre  \\\n0   Dick Johnson Is Dead           Documentaries   \n1          Blood & Water  International TV Shows   \n2              Ganglands          Crime TV Shows   \n3  Jailbirds New Orleans              Docuseries   \n4           Kota Factory  International TV Shows   \n\n                                 cleaned_description  \n0  As her father nears the end of his life, filmm...  \n1  After crossing paths at a party, a Cape Town t...  \n2  To protect his family from a powerful drug lor...  \n3  Feuds, flirtations and toilet talk go down amo...  \n4  In a city of coaching centers known to train I...  \n\n\n\nimport pandas as pd\n\n# 1) Load dataset\ndf = pd.read_csv('netflix_titles.csv', encoding='ISO-8859-1')\n\n# 2) Convert 'listed_in' to a list of genres\ndf['genre_list'] = df['listed_in'].astype(str).apply(lambda x: [g.strip() for g in x.split(',')])\n\n\nimport re\n\ndef clean_description(text):\n    if pd.isna(text):\n        return \"\"\n    # Remove non-alphanumeric except basic punctuation\n    return re.sub(r'[^a-zA-Z0-9.,!?\\'\" ]', '', text)\n\ndf['cleaned_description'] = df['description'].apply(clean_description)\n\n\nfrom sklearn.preprocessing import MultiLabelBinarizer\n\nmlb = MultiLabelBinarizer()\ny = mlb.fit_transform(df['genre_list'])  # shape: (num_samples, num_unique_genres)\ngenre_labels = mlb.classes_  # array of genre names\n\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nvectorizer = TfidfVectorizer(stop_words='english', ngram_range=(1,2), min_df=2, max_df=0.9)\nX = vectorizer.fit_transform(df['cleaned_description'])  # shape: (num_samples, num_features)\n\nprint(\"Feature matrix shape:\", X.shape)\nprint(\"Label matrix shape:\", y.shape)\n\nFeature matrix shape: (8809, 17008)\nLabel matrix shape: (8809, 48)\n\n\n\nmodel training part\n\nfrom sklearn.metrics import f1_score, make_scorer\n\ndef multi_label_f1_micro(y_true, y_pred):\n    return f1_score(y_true, y_pred, average='micro')\n\nf1_micro_scorer = make_scorer(multi_label_f1_micro)\n\n\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.naive_bayes import MultinomialNB\n\n\nmodels = {\n    \"LogisticRegression\": LogisticRegression(max_iter=1000),\n    \"RandomForest\": RandomForestClassifier(n_estimators=200, random_state=42),\n    \"XGBoost\": XGBClassifier(eval_metric='logloss', use_label_encoder=False, random_state=42),\n    \"NaiveBayes\": MultinomialNB()\n}\n\n\nfrom sklearn.decomposition import TruncatedSVD\n\nsvd = TruncatedSVD(n_components=300, random_state=42)\nX_reduced = svd.fit_transform(X)  # use the output of TF-IDF\n\n\nimport pandas as pd\nimport re\n\n# Load the dataset\ndf = pd.read_csv('netflix_titles.csv', encoding='ISO-8859-1')\n\n# Extract the first genre from 'listed_in'\ndf['genre'] = df['listed_in'].astype(str).apply(lambda x: x.split(',')[0].strip())\n\n# Clean the 'description' column\ndef clean_description(text):\n    if pd.isna(text):\n        return \"\"\n    return re.sub(r'[^a-zA-Z0-9.,!?\\'\" ]', '', text)\n\ndf['cleaned_description'] = df['description'].apply(clean_description)\n\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nvectorizer = TfidfVectorizer(\n    stop_words='english',\n    ngram_range=(1, 2),\n    min_df=2,\n    max_df=0.9\n)\nX = vectorizer.fit_transform(df['cleaned_description'])\n\n\nfrom sklearn.preprocessing import LabelEncoder\n\nlabel_encoder = LabelEncoder()\ny = label_encoder.fit_transform(df['genre'])\n\n\nfrom sklearn.decomposition import TruncatedSVD, NMF\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.naive_bayes import MultinomialNB\n\n\nfrom sklearn.pipeline import Pipeline\n\n# 1) Logistic Regression + SVD\npipe_lr = Pipeline([\n    ('svd', TruncatedSVD(n_components=300, random_state=42)),\n    ('clf', LogisticRegression(max_iter=1000, solver='saga', n_jobs=-1))\n])\n\n# 2) MultinomialNB + NMF (ensures non-negative features)\npipe_nb = Pipeline([\n    ('nmf', NMF(n_components=50, init='random', random_state=42)),\n    ('clf', MultinomialNB())\n])\n\n# 3) RandomForest + SVD\npipe_rf = Pipeline([\n    ('svd', TruncatedSVD(n_components=300, random_state=42)),\n    ('clf', RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1))\n])\n\n# 4) XGBoost + SVD\npipe_xgb = Pipeline([\n    ('svd', TruncatedSVD(n_components=300, random_state=42)),\n    ('clf', XGBClassifier(eval_metric='logloss', use_label_encoder=False, random_state=42, n_jobs=-1))\n])\n\n\nimport numpy as np\nfrom sklearn.model_selection import KFold, cross_val_score\nfrom sklearn.metrics import f1_score, make_scorer\n\ndef f1_micro(y_true, y_pred):\n    return f1_score(y_true, y_pred, average='micro')\n\nf1_micro_scorer = make_scorer(f1_micro)\n\nkf = KFold(n_splits=3, shuffle=True, random_state=42)\n\nmodels = {\n    \"LogisticRegression+SVD\": pipe_lr,\n    \"MultinomialNB+NMF\": pipe_nb,\n    \"RandomForest+SVD\": pipe_rf,\n    \"XGBoost+SVD\": pipe_xgb\n}\n\nfor name, model_pipeline in models.items():\n    scores = cross_val_score(\n        model_pipeline,\n        X,\n        y,\n        cv=kf,\n        scoring=f1_micro_scorer,\n        n_jobs=-1\n    )\n    print(f\"Model: {name}\")\n    print(f\"F1-micro (3-fold avg): {np.mean(scores):.4f} Â± {np.std(scores):.4f}\")\n    print(\"-\" * 50)\n\nModel: LogisticRegression+SVD\nF1-micro (3-fold avg): 0.3544 Â± 0.0153\n--------------------------------------------------\nModel: MultinomialNB+NMF\nF1-micro (3-fold avg): 0.1816 Â± 0.0116\n--------------------------------------------------\nModel: RandomForest+SVD\nF1-micro (3-fold avg): 0.3382 Â± 0.0128\n--------------------------------------------------\nModel: XGBoost+SVD\nF1-micro (3-fold avg): nan Â± nan\n--------------------------------------------------\n\n\n/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n2 fits failed out of a total of 3.\nThe score on these train-test partitions for these parameters will be set to nan.\nIf these failures are not expected, you can try to debug them by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\", line 662, in fit\n    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n  File \"/usr/local/lib/python3.11/dist-packages/xgboost/core.py\", line 726, in inner_f\n    return func(**kwargs)\n           ^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py\", line 1559, in fit\n    raise ValueError(\nValueError: Invalid classes inferred from unique values of `y`.  Expected: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n 24 25 26 27 28 29 30 31 32 33], got [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 20 21 22 23 24\n 25 27 29 30 31 32 33 34 36 37]\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\", line 662, in fit\n    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n  File \"/usr/local/lib/python3.11/dist-packages/xgboost/core.py\", line 726, in inner_f\n    return func(**kwargs)\n           ^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py\", line 1559, in fit\n    raise ValueError(\nValueError: Invalid classes inferred from unique values of `y`.  Expected: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n 24 25 26 27 28 29 30 31 32 33 34 35 36], got [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14 15 16 17 18 19 20 21 22 23 24\n 25 26 27 28 29 30 31 32 33 34 35 36 37]\n\n  warnings.warn(some_fits_failed_message, FitFailedWarning)\n\n\n\n\nclustering\n\n# Join tokens back into a single string so TF-IDF can handle them easily\ndf['processed_text_str'] = df['processed_description'].apply(lambda tokens: ' '.join(tokens))\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\n# Initialize and fit the TF-IDF vectorizer on the processed descriptions\nvectorizer = TfidfVectorizer()\nX_tfidf = vectorizer.fit_transform(df['processed_text_str'])\nprint(\"TF-IDF matrix shape:\", X_tfidf.shape)  # (number of samples, number of features)\n\n# Get some insights: average TF-IDF weight for each term across the corpus\navg_tfidf = np.mean(X_tfidf.toarray(), axis=0)\ntop_n = 20\ntop_indices = avg_tfidf.argsort()[-top_n:][::-1]\ntop_features = [vectorizer.get_feature_names_out()[i] for i in top_indices]\nprint(\"Top TF-IDF features:\", top_features)\n\nTF-IDF matrix shape: (8809, 15318)\nTop TF-IDF features: ['life', 'young', 'find', 'family', 'woman', 'new', 'man', 'friend', 'love', 'world', 'year', 'take', 'help', 'documentary', 'school', 'old', 'try', 'home', 'father', 'story']\n\n\n\nfrom sklearn.cluster import KMeans\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\n# Vectorize the processed descriptions\nvectorizer = TfidfVectorizer(stop_words='english', ngram_range=(1, 2), min_df=2, max_df=0.9)\nX_tfidf_desc = vectorizer.fit_transform(df['processed_text_str'])  # Use processed description\n\n# Perform KMeans clustering\nnum_clusters = 6\nkmeans = KMeans(n_clusters=num_clusters, random_state=42)\nclusters = kmeans.fit_predict(X_tfidf_desc)\n\n# Assign cluster labels\ndf['cluster'] = clusters\n\n# Display results\nprint(\"Cluster assignments (first 10):\")\nprint(df[['title', 'processed_text_str', 'cluster']].head(10))\n\nCluster assignments (first 10):\n                              title  \\\n0              Dick Johnson Is Dead   \n1                     Blood & Water   \n2                         Ganglands   \n3             Jailbirds New Orleans   \n4                      Kota Factory   \n5                     Midnight Mass   \n6  My Little Pony: A New Generation   \n7                           Sankofa   \n8     The Great British Baking Show   \n9                      The Starling   \n\n                                  processed_text_str  cluster  \n0  father near end life filmmaker kirsten johnson...        4  \n1  cross path party cape town teen set prove priv...        4  \n2  protect family powerful drug lord skilled thie...        2  \n3  feud flirtation toilet talk incarcerated woman...        1  \n4  city coach center know train india fine colleg...        5  \n5  arrival charismatic young priest bring gloriou...        1  \n6  equestria divided bright eyed hero believe ear...        4  \n7  photo shoot ghana american model slip time ens...        4  \n8  talented batch amateur baker face 10 week comp...        3  \n9  woman adjust life loss contend feisty bird tak...        1  \n\n\n\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\n\n# Finding the optimal number of clusters using the Elbow Method\ninertia = []\nsilhouette_scores = []\n\nfor k in range(2, 11):  # Test multiple cluster sizes\n    kmeans = KMeans(n_clusters=k, random_state=42)\n    kmeans.fit(X_tfidf_desc)\n    inertia.append(kmeans.inertia_)  # Elbow Method\n    silhouette_scores.append(silhouette_score(X_tfidf_desc, kmeans.labels_))  # Silhouette Score\n\n# Plot Elbow Method\nplt.figure(figsize=(10, 5))\nplt.plot(range(2, 11), inertia, marker='o')\nplt.title('Elbow Method - Optimal K')\nplt.xlabel('Number of Clusters')\nplt.ylabel('Inertia')\nplt.show()\n\n# Plot Silhouette Scores\nplt.figure(figsize=(10, 5))\nplt.plot(range(2, 11), silhouette_scores, marker='o', color='green')\nplt.title('Silhouette Score - Optimal K')\nplt.xlabel('Number of Clusters')\nplt.ylabel('Silhouette Score')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfrom sklearn.cluster import KMeans\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\n# Vectorize the processed descriptions\nvectorizer = TfidfVectorizer(stop_words='english', ngram_range=(1, 2), min_df=2, max_df=0.9)\nX_tfidf_desc = vectorizer.fit_transform(df['processed_text_str'])  # Use processed description\n\n# Perform KMeans clustering\nnum_clusters = 6\nkmeans = KMeans(n_clusters=num_clusters, random_state=42)\nclusters = kmeans.fit_predict(X_tfidf_desc)\n\n# Assign cluster labels\ndf['cluster'] = clusters\n\n# Display results\nprint(\"Cluster assignments (first 10):\")\nprint(df[['title', 'processed_text_str', 'cluster']].head(10))\n\nCluster assignments (first 10):\n                              title  \\\n0              Dick Johnson Is Dead   \n1                     Blood & Water   \n2                         Ganglands   \n3             Jailbirds New Orleans   \n4                      Kota Factory   \n5                     Midnight Mass   \n6  My Little Pony: A New Generation   \n7                           Sankofa   \n8     The Great British Baking Show   \n9                      The Starling   \n\n                                  processed_text_str  cluster  \n0  father near end life filmmaker kirsten johnson...        4  \n1  cross path party cape town teen set prove priv...        4  \n2  protect family powerful drug lord skilled thie...        2  \n3  feud flirtation toilet talk incarcerated woman...        1  \n4  city coach center know train india fine colleg...        5  \n5  arrival charismatic young priest bring gloriou...        1  \n6  equestria divided bright eyed hero believe ear...        4  \n7  photo shoot ghana american model slip time ens...        4  \n8  talented batch amateur baker face 10 week comp...        3  \n9  woman adjust life loss contend feisty bird tak...        1  \n\n\n\n# Display Sample Titles from Each Cluster\nfor cluster_id in sorted(df['cluster'].unique()):\n    print(f\"\\nCluster {cluster_id} Titles:\")\n    print(df[df['cluster'] == cluster_id][['title', 'processed_text_str']].head(5))\n\n# Show Top Words in Each Cluster\nfrom collections import Counter\nimport numpy as np\n\ndef get_top_words(cluster_num, top_n=10):\n    cluster_text = \" \".join(df[df['cluster'] == cluster_num]['processed_text_str'])\n    word_counts = Counter(cluster_text.split())\n    return dict(word_counts.most_common(top_n))\n\n# Display the top words in each cluster\nfor cluster_id in sorted(df['cluster'].unique()):\n    print(f\"\\nCluster {cluster_id} Top Words:\")\n    print(get_top_words(cluster_id, top_n=10))\n\n\nCluster 0 Titles:\n                          title  \\\n48                 Training Day   \n82                      Lucifer   \n84         Omo Ghetto: the Saga   \n91   The Women and the Murderer   \n122                  In the Cut   \n\n                                    processed_text_str  \n48   rookie cop day prove veteran lapd narcotic off...  \n82   bore lord hell devil relocate los angeles open...  \n84   twin reunite good hearted female gangster upti...  \n91   documentary trace capture serial killer guy ge...  \n122  embark affair cop probe murder young woman ins...  \n\nCluster 1 Titles:\n                    title                                 processed_text_str\n3   Jailbirds New Orleans  feud flirtation toilet talk incarcerated woman...\n5           Midnight Mass  arrival charismatic young priest bring gloriou...\n9            The Starling  woman adjust life loss contend feisty bird tak...\n12           Je Suis Karl  family murder terrorist bombing young woman un...\n24                  Jeans  father man love insist twin son marry twin sis...\n\nCluster 2 Titles:\n                     title                                 processed_text_str\n2                Ganglands  protect family powerful drug lord skilled thie...\n26          Minsara Kanavu  tangle love triangle ensue man fall woman stud...\n28              Dark Skies  family idyllic suburban life shatter alien for...\n47   The Smart Money Woman  glamorous millennial strive success juggle car...\n103         Shadow Parties  family face destruction long run conflict comm...\n\nCluster 3 Titles:\n                               title  \\\n8      The Great British Baking Show   \n13  Confessions of an Invisible Girl   \n18                         Intrusion   \n21            Resurrection: Ertugrul   \n34           Tayo and Little Wizards   \n\n                                   processed_text_str  \n8   talented batch amateur baker face 10 week comp...  \n13  clever socially awkward tet join new school fi...  \n18  deadly home invasion couple new dream house tr...  \n21  good deed unwittingly endanger clan 13th centu...  \n34  tayo speed adventure friend kidnap evil magici...  \n\nCluster 4 Titles:\n                                  title  \\\n0                  Dick Johnson Is Dead   \n1                         Blood & Water   \n6      My Little Pony: A New Generation   \n7                               Sankofa   \n10  Vendetta: Truth, Lies and The Mafia   \n\n                                   processed_text_str  \n0   father near end life filmmaker kirsten johnson...  \n1   cross path party cape town teen set prove priv...  \n6   equestria divided bright eyed hero believe ear...  \n7   photo shoot ghana american model slip time ens...  \n10  sicily boast bold anti mafia coalition happen ...  \n\nCluster 5 Titles:\n                     title                                 processed_text_str\n4             Kota Factory  city coach center know train india fine colleg...\n11        Bangkok Breaking  struggle earn living bangkok man join emergenc...\n30         Ankahi Kahaniya  big city life buzz lonely soul discover surpri...\n36          The Stronghold  tired small time grind marseille cop chance bu...\n45  My Heroes Were Cowboys  robin wiltshire painful childhood rescue weste...\n\nCluster 0 Top Words:\n{'murder': 264, 'cop': 118, 'detective': 90, 'crime': 73, 'case': 65, 'killer': 56, 'police': 48, 'find': 46, 'suspect': 36, 'investigate': 36}\n\nCluster 1 Top Words:\n{'young': 612, 'woman': 549, 'man': 248, 'life': 154, 'find': 109, 'love': 104, 'father': 72, 'year': 58, 'new': 55, 'mother': 52}\n\nCluster 2 Top Words:\n{'family': 611, 'love': 432, 'life': 163, 'fall': 111, 'find': 87, 'year': 76, 'man': 63, 'young': 59, 'home': 55, 'girl': 54}\n\nCluster 3 Top Words:\n{'friend': 541, 'new': 441, 'good': 154, 'life': 109, 'find': 105, 'school': 80, 'help': 74, 'world': 62, 'old': 61, 'high': 60}\n\nCluster 4 Top Words:\n{'life': 565, 'world': 383, 'find': 340, 'documentary': 279, 'year': 247, 'man': 240, 'take': 231, 'story': 220, 'school': 201, 'high': 190}\n\nCluster 5 Top Words:\n{'struggle': 197, 'city': 194, 'big': 146, 'new': 135, 'york': 92, 'life': 69, 'world': 50, 'find': 46, 'family': 29, 'young': 29}\n\n\n\n# Plot the distribution of clustersimport seaborn as sns\nimport seaborn as sns\n\nplt.figure(figsize=(8, 5))\nsns.countplot(x='cluster', data=df, palette='viridis')\nplt.title(\"Distribution of Clusters\")\nplt.xlabel(\"Cluster\")\nplt.ylabel(\"Count\")\nplt.show()\n\nFutureWarning: \n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n\n  sns.countplot(x='cluster', data=df, palette='viridis')\n\n\n\n\n\n\n\n\n\n\n\ntopic modeling\n\n### Topic Modeling\n# Use Latent Dirichlet Allocation (LDA) on the TF-IDF matrix to discover topics.\nfrom sklearn.decomposition import LatentDirichletAllocation\n\nnum_topics = 5\nlda = LatentDirichletAllocation(n_components=num_topics, random_state=42)\nlda.fit(X_tfidf)\nfeature_names = vectorizer.get_feature_names_out()\n\nprint(\"\\nTopics discovered:\")\nfor topic_idx, topic in enumerate(lda.components_):\n    top_words = [feature_names[i] for i in topic.argsort()[-10:]]\n    print(f\"Topic {topic_idx+1}: {', '.join(top_words)}\")\n\n\nTopics discovered:\nTopic 1: mischievous, growth, turn upside, haddish, retaliate, turf war, fair, undo, laga, flawed\nTopic 2: flawed, mischievous, uncover dark, laga, fair, life star, turf war, undo, fast, leave family\nTopic 3: consultant, undo, fair, mischievous, turn upside, turf war, flawed, leave family, fast, laga\nTopic 4: flawed, turf war, leave family, familiar face, fast, fair, life star, undo, mischievous, laga\nTopic 5: turn obsessive, leave family, undo, fair, mischievous, turn upside, turf war, life star, fast, laga\n\n\n\nimport pandas as pd\nimport re\n\n# Load the dataset\ndf = pd.read_csv('netflix_titles.csv', encoding='ISO-8859-1')\n\n# Extract the first genre from 'listed_in' and store in a new column 'genre'\ndf['genre'] = df['listed_in'].astype(str).apply(lambda x: x.split(',')[0].strip())\n\n# Clean the 'description' column: remove unwanted characters\ndef clean_description(text):\n    if pd.isna(text):\n        return \"\"\n    return re.sub(r'[^a-zA-Z0-9.,!?\\'\" ]', '', text).strip()\n\ndf['cleaned_description'] = df['description'].apply(clean_description)\n\n# (Optional) Inspect the cleaned data\nprint(df[['title', 'genre', 'cleaned_description']].head(5))\n\n                   title                   genre  \\\n0   Dick Johnson Is Dead           Documentaries   \n1          Blood & Water  International TV Shows   \n2              Ganglands          Crime TV Shows   \n3  Jailbirds New Orleans              Docuseries   \n4           Kota Factory  International TV Shows   \n\n                                 cleaned_description  \n0  As her father nears the end of his life, filmm...  \n1  After crossing paths at a party, a Cape Town t...  \n2  To protect his family from a powerful drug lor...  \n3  Feuds, flirtations and toilet talk go down amo...  \n4  In a city of coaching centers known to train I...  \n\n\n\n\nprediction for type ( optional )\n\nimport pandas as pd\nimport re\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\n# 1) Load dataset\ndf = pd.read_csv('netflix_titles.csv', encoding='ISO-8859-1')\n\n# 2) Clean the description\ndef clean_description(text):\n    if pd.isna(text):\n        return \"\"\n    return re.sub(r'[^a-zA-Z0-9.,!?\\'\" ]', '', text).strip()\n\ndf['cleaned_description'] = df['description'].apply(clean_description)\n\n# 3) Define target: \"Movie\" vs. \"TV Show\"\ny = df['type']  # 'Movie' or 'TV Show'\n\n# 4) TF-IDF vectorization of the cleaned descriptions\nvectorizer = TfidfVectorizer(stop_words='english', ngram_range=(1,2), min_df=2, max_df=0.9)\nX_tfidf = vectorizer.fit_transform(df['cleaned_description'])\n\n# 5) Split data\nX_train, X_test, y_train, y_test = train_test_split(\n    X_tfidf,\n    y,\n    test_size=0.2,\n    random_state=42\n)\n\nprint(\"Shapes:\", X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n\nShapes: (7047, 17008) (1762, 17008) (7047,) (1762,)\n\n\n\nimport numpy as np\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom collections import Counter\n\ndef classify_by_similarity(new_text, vectorizer, X_train, y_train, k=5):\n    \"\"\"\n    Classify a new text as 'Movie' or 'TV Show' using similarity to training data.\n\n    Parameters:\n    - new_text: string (description to classify)\n    - vectorizer: the fitted TfidfVectorizer\n    - X_train: TF-IDF matrix for training descriptions\n    - y_train: Series or array of labels ('Movie'/'TV Show') for training\n    - k: number of neighbors to consider\n\n    Returns:\n    - predicted_type: the predicted label ('Movie' or 'TV Show')\n    \"\"\"\n    # 1) Transform new text into TF-IDF vector\n    new_vec = vectorizer.transform([new_text])\n\n    # 2) Compute cosine similarity with each training sample\n    sims = cosine_similarity(new_vec, X_train).flatten()\n\n    # 3) Get indices of top-k neighbors (largest similarity)\n    top_k_idx = np.argsort(sims)[::-1][:k]\n\n    # 4) Majority vote among those k neighbors\n    #    If y_train is a pandas Series, we can use .iloc;\n    #    If y_train is a NumPy array, index it directly.\n    if isinstance(y_train, pd.Series):\n        top_k_labels = y_train.iloc[top_k_idx]\n    else:\n        top_k_labels = y_train[top_k_idx]\n\n    # 5) Determine the most common label\n    predicted_type = Counter(top_k_labels).most_common(1)[0][0]\n\n    return predicted_type\n\n\n\nresult\n\n# Example: A new description\nnew_description = \"A gripping story of a detective unraveling mysteries in a futuristic world.\"\n\npredicted_label = classify_by_similarity(\n    new_text=new_description,\n    vectorizer=vectorizer,\n    X_train=X_train,\n    y_train=y_train,\n    k=5  # top-5 neighbors\n)\n\nprint(\"Predicted label by similarity-based method:\", predicted_label)\n\nPredicted label by similarity-based method: Movie\n\n\n\nimport pandas as pd\nimport re\nimport string\n\n# Load the dataset\ndf = pd.read_csv('netflix_titles.csv', encoding='ISO-8859-1')\n\n# Fill missing values for columns we'll use\nfor col in ['listed_in', 'type', 'cast', 'description']:\n    df[col] = df[col].fillna('')\n\n# Combine features into a single text field\ndef combine_features(row):\n    return f\"{row['listed_in']} {row['type']} {row['cast']} {row['description']}\"\n\ndf['combined_features'] = df.apply(combine_features, axis=1)\n\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\nimport numpy as np\n\n# Vectorize the combined text\nvectorizer = TfidfVectorizer(stop_words='english')\ntfidf_matrix = vectorizer.fit_transform(df['combined_features'])\nprint(\"TF-IDF matrix shape:\", tfidf_matrix.shape)\n\n# Example: Compute similarity for a query\nquery = \"Comedy Movie Adam Sandler funny heartwarming family\"\nquery_vec = vectorizer.transform([query])\nsimilarities = cosine_similarity(query_vec, tfidf_matrix).flatten()\ntop_indices = np.argsort(similarities)[::-1][:5]\nprint(\"Top recommendations using TF-IDF:\")\nprint(df.iloc[top_indices][['title', 'listed_in', 'type']])\n\nTF-IDF matrix shape: (8809, 47360)\nTop recommendations using TF-IDF:\n                        title                           listed_in     type\n4482  ADAM SANDLER 100% FRESH                     Stand-Up Comedy    Movie\n1879          Hubie Halloween             Comedies, Horror Movies    Movie\n6089    Adam Ruins Everything                         TV Comedies  TV Show\n5639      Jim Gaffigan: Cinco                     Stand-Up Comedy    Movie\n6271          Bedtime Stories  Children & Family Movies, Comedies    Movie\n\n\n\nimport spacy\n\n!python -m spacy download en_core_web_md\n\nnlp = spacy.load(\"en_core_web_md\")  # Using a medium model with pretrained vectors\n\ndef get_doc_vector(text):\n    doc = nlp(text)\n    # Average the token vectors (excluding stop words and punctuation)\n    vectors = [token.vector for token in doc if token.has_vector and not token.is_stop and not token.is_punct]\n    if vectors:\n        return np.mean(vectors, axis=0)\n    else:\n        return np.zeros(nlp.vocab.vectors_length)\n\n# Compute document vectors for each title\ndf['doc_vector'] = df['combined_features'].apply(get_doc_vector)\n\n# Create a matrix of document vectors\ndoc_vectors = np.stack(df['doc_vector'].values)\n\n# Similarity example using word embeddings\nquery_vector = get_doc_vector(query)\nfrom sklearn.metrics.pairwise import cosine_similarity\nembedding_similarities = cosine_similarity([query_vector], doc_vectors).flatten()\ntop_indices_embed = np.argsort(embedding_similarities)[::-1][:5]\nprint(\"Top recommendations using Word Embeddings:\")\nprint(df.iloc[top_indices_embed][['title', 'listed_in', 'type']])\n\nCollecting en-core-web-md==3.7.1\n  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.7.1/en_core_web_md-3.7.1-py3-none-any.whl (42.8 MB)\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 42.8/42.8 MB 12.3 MB/s eta 0:00:00\nRequirement already satisfied: spacy&lt;3.8.0,&gt;=3.7.2 in /usr/local/lib/python3.11/dist-packages (from en-core-web-md==3.7.1) (3.7.5)\nRequirement already satisfied: spacy-legacy&lt;3.1.0,&gt;=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy&lt;3.8.0,&gt;=3.7.2-&gt;en-core-web-md==3.7.1) (3.0.12)\nRequirement already satisfied: spacy-loggers&lt;2.0.0,&gt;=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy&lt;3.8.0,&gt;=3.7.2-&gt;en-core-web-md==3.7.1) (1.0.5)\nRequirement already satisfied: murmurhash&lt;1.1.0,&gt;=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy&lt;3.8.0,&gt;=3.7.2-&gt;en-core-web-md==3.7.1) (1.0.12)\nRequirement already satisfied: cymem&lt;2.1.0,&gt;=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy&lt;3.8.0,&gt;=3.7.2-&gt;en-core-web-md==3.7.1) (2.0.11)\nRequirement already satisfied: preshed&lt;3.1.0,&gt;=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy&lt;3.8.0,&gt;=3.7.2-&gt;en-core-web-md==3.7.1) (3.0.9)\nRequirement already satisfied: thinc&lt;8.3.0,&gt;=8.2.2 in /usr/local/lib/python3.11/dist-packages (from spacy&lt;3.8.0,&gt;=3.7.2-&gt;en-core-web-md==3.7.1) (8.2.5)\nRequirement already satisfied: wasabi&lt;1.2.0,&gt;=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy&lt;3.8.0,&gt;=3.7.2-&gt;en-core-web-md==3.7.1) (1.1.3)\nRequirement already satisfied: srsly&lt;3.0.0,&gt;=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy&lt;3.8.0,&gt;=3.7.2-&gt;en-core-web-md==3.7.1) (2.5.1)\nRequirement already satisfied: catalogue&lt;2.1.0,&gt;=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy&lt;3.8.0,&gt;=3.7.2-&gt;en-core-web-md==3.7.1) (2.0.10)\nRequirement already satisfied: weasel&lt;0.5.0,&gt;=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy&lt;3.8.0,&gt;=3.7.2-&gt;en-core-web-md==3.7.1) (0.4.1)\nRequirement already satisfied: typer&lt;1.0.0,&gt;=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy&lt;3.8.0,&gt;=3.7.2-&gt;en-core-web-md==3.7.1) (0.15.2)\nRequirement already satisfied: tqdm&lt;5.0.0,&gt;=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy&lt;3.8.0,&gt;=3.7.2-&gt;en-core-web-md==3.7.1) (4.67.1)\nRequirement already satisfied: requests&lt;3.0.0,&gt;=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy&lt;3.8.0,&gt;=3.7.2-&gt;en-core-web-md==3.7.1) (2.32.3)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,&lt;3.0.0,&gt;=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy&lt;3.8.0,&gt;=3.7.2-&gt;en-core-web-md==3.7.1) (2.10.6)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy&lt;3.8.0,&gt;=3.7.2-&gt;en-core-web-md==3.7.1) (3.1.6)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy&lt;3.8.0,&gt;=3.7.2-&gt;en-core-web-md==3.7.1) (75.1.0)\nRequirement already satisfied: packaging&gt;=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy&lt;3.8.0,&gt;=3.7.2-&gt;en-core-web-md==3.7.1) (24.2)\nRequirement already satisfied: langcodes&lt;4.0.0,&gt;=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy&lt;3.8.0,&gt;=3.7.2-&gt;en-core-web-md==3.7.1) (3.5.0)\nRequirement already satisfied: numpy&gt;=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy&lt;3.8.0,&gt;=3.7.2-&gt;en-core-web-md==3.7.1) (1.26.4)\nRequirement already satisfied: language-data&gt;=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes&lt;4.0.0,&gt;=3.2.0-&gt;spacy&lt;3.8.0,&gt;=3.7.2-&gt;en-core-web-md==3.7.1) (1.3.0)\nRequirement already satisfied: annotated-types&gt;=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,&lt;3.0.0,&gt;=1.7.4-&gt;spacy&lt;3.8.0,&gt;=3.7.2-&gt;en-core-web-md==3.7.1) (0.7.0)\nRequirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,&lt;3.0.0,&gt;=1.7.4-&gt;spacy&lt;3.8.0,&gt;=3.7.2-&gt;en-core-web-md==3.7.1) (2.27.2)\nRequirement already satisfied: typing-extensions&gt;=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,&lt;3.0.0,&gt;=1.7.4-&gt;spacy&lt;3.8.0,&gt;=3.7.2-&gt;en-core-web-md==3.7.1) (4.12.2)\nRequirement already satisfied: charset-normalizer&lt;4,&gt;=2 in /usr/local/lib/python3.11/dist-packages (from requests&lt;3.0.0,&gt;=2.13.0-&gt;spacy&lt;3.8.0,&gt;=3.7.2-&gt;en-core-web-md==3.7.1) (3.4.1)\nRequirement already satisfied: idna&lt;4,&gt;=2.5 in /usr/local/lib/python3.11/dist-packages (from requests&lt;3.0.0,&gt;=2.13.0-&gt;spacy&lt;3.8.0,&gt;=3.7.2-&gt;en-core-web-md==3.7.1) (3.10)\nRequirement already satisfied: urllib3&lt;3,&gt;=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests&lt;3.0.0,&gt;=2.13.0-&gt;spacy&lt;3.8.0,&gt;=3.7.2-&gt;en-core-web-md==3.7.1) (2.3.0)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests&lt;3.0.0,&gt;=2.13.0-&gt;spacy&lt;3.8.0,&gt;=3.7.2-&gt;en-core-web-md==3.7.1) (2025.1.31)\nRequirement already satisfied: blis&lt;0.8.0,&gt;=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc&lt;8.3.0,&gt;=8.2.2-&gt;spacy&lt;3.8.0,&gt;=3.7.2-&gt;en-core-web-md==3.7.1) (0.7.11)\nRequirement already satisfied: confection&lt;1.0.0,&gt;=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc&lt;8.3.0,&gt;=8.2.2-&gt;spacy&lt;3.8.0,&gt;=3.7.2-&gt;en-core-web-md==3.7.1) (0.1.5)\nRequirement already satisfied: click&gt;=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer&lt;1.0.0,&gt;=0.3.0-&gt;spacy&lt;3.8.0,&gt;=3.7.2-&gt;en-core-web-md==3.7.1) (8.1.8)\nRequirement already satisfied: shellingham&gt;=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer&lt;1.0.0,&gt;=0.3.0-&gt;spacy&lt;3.8.0,&gt;=3.7.2-&gt;en-core-web-md==3.7.1) (1.5.4)\nRequirement already satisfied: rich&gt;=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer&lt;1.0.0,&gt;=0.3.0-&gt;spacy&lt;3.8.0,&gt;=3.7.2-&gt;en-core-web-md==3.7.1) (13.9.4)\nRequirement already satisfied: cloudpathlib&lt;1.0.0,&gt;=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel&lt;0.5.0,&gt;=0.1.0-&gt;spacy&lt;3.8.0,&gt;=3.7.2-&gt;en-core-web-md==3.7.1) (0.21.0)\nRequirement already satisfied: smart-open&lt;8.0.0,&gt;=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel&lt;0.5.0,&gt;=0.1.0-&gt;spacy&lt;3.8.0,&gt;=3.7.2-&gt;en-core-web-md==3.7.1) (7.1.0)\nRequirement already satisfied: MarkupSafe&gt;=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2-&gt;spacy&lt;3.8.0,&gt;=3.7.2-&gt;en-core-web-md==3.7.1) (3.0.2)\nRequirement already satisfied: marisa-trie&gt;=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data&gt;=1.2-&gt;langcodes&lt;4.0.0,&gt;=3.2.0-&gt;spacy&lt;3.8.0,&gt;=3.7.2-&gt;en-core-web-md==3.7.1) (1.2.1)\nRequirement already satisfied: markdown-it-py&gt;=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich&gt;=10.11.0-&gt;typer&lt;1.0.0,&gt;=0.3.0-&gt;spacy&lt;3.8.0,&gt;=3.7.2-&gt;en-core-web-md==3.7.1) (3.0.0)\nRequirement already satisfied: pygments&lt;3.0.0,&gt;=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich&gt;=10.11.0-&gt;typer&lt;1.0.0,&gt;=0.3.0-&gt;spacy&lt;3.8.0,&gt;=3.7.2-&gt;en-core-web-md==3.7.1) (2.18.0)\nRequirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open&lt;8.0.0,&gt;=5.2.1-&gt;weasel&lt;0.5.0,&gt;=0.1.0-&gt;spacy&lt;3.8.0,&gt;=3.7.2-&gt;en-core-web-md==3.7.1) (1.17.2)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py&gt;=2.2.0-&gt;rich&gt;=10.11.0-&gt;typer&lt;1.0.0,&gt;=0.3.0-&gt;spacy&lt;3.8.0,&gt;=3.7.2-&gt;en-core-web-md==3.7.1) (0.1.2)\nInstalling collected packages: en-core-web-md\nSuccessfully installed en-core-web-md-3.7.1\nâœ” Download and installation successful\nYou can now load the package via spacy.load('en_core_web_md')\nâš  Restart to reload dependencies\nIf you are in a Jupyter or Colab notebook, you may need to restart Python in\norder to load all the package's dependencies. You can do this by selecting the\n'Restart kernel' or 'Restart runtime' option.\nTop recommendations using Word Embeddings:\n                                             title  \\\n6039                               A Haunted House   \n4010  Jeff Dunham's Very Special Christmas Special   \n4009             Jeff Dunham: Minding the Monsters   \n3733           Adam Devine: Best Time of Our Lives   \n4474                                 Santo CachÃƒÂ³n   \n\n                                            listed_in   type  \n6039                          Comedies, Horror Movies  Movie  \n4010                                  Stand-Up Comedy  Movie  \n4009                                  Stand-Up Comedy  Movie  \n3733                                  Stand-Up Comedy  Movie  \n4474  Comedies, International Movies, Romantic Movies  Movie  \n\n\n\ndef recommend_titles(user_genre, user_type, user_actor, user_sentiment, user_description, top_n=5, method=\"tfidf\"):\n    \"\"\"\n    Recommend titles based on user inputs and similarity measure.\n\n    Parameters:\n      user_genre (str): Desired genre(s)\n      user_type (str): 'Movie' or 'TV Show'\n      user_actor (str): Actor/actress names\n      user_sentiment (str): Sentiment descriptors (e.g., 'funny', 'heartwarming')\n      user_description (str): Additional keywords\n      top_n (int): Number of recommendations to return\n      method (str): 'tfidf' or 'embedding' for similarity calculation\n\n    Returns:\n      DataFrame: Top recommended titles.\n    \"\"\"\n    # Combine user inputs into a query string\n    user_query = f\"{user_genre} {user_type} {user_actor} {user_sentiment} {user_description}\"\n\n    if method == \"tfidf\":\n        query_vec = vectorizer.transform([user_query])\n        sims = cosine_similarity(query_vec, tfidf_matrix).flatten()\n    elif method == \"embedding\":\n        query_vec = get_doc_vector(user_query)\n        sims = cosine_similarity([query_vec], doc_vectors).flatten()\n    else:\n        raise ValueError(\"Method must be either 'tfidf' or 'embedding'\")\n\n    top_indices = np.argsort(sims)[::-1][:top_n]\n    return df.iloc[top_indices][['title', 'listed_in', 'type']], sims[top_indices]\n\n# Test the recommendation function\nuser_genre = \"Comedy\"\nuser_type = \"Movie\"\nuser_actor = \"Adam Sandler\"\nuser_sentiment = \"funny heartwarming\"\nuser_description = \"family vacation\"\nrecommended_titles, sim_scores = recommend_titles(\n    user_genre, user_type, user_actor, user_sentiment, user_description, top_n=5, method=\"tfidf\"\n)\n\nprint(\"Recommended Titles (TF-IDF):\")\nprint(recommended_titles)\nprint(\"Similarity Scores:\", sim_scores)\n\nRecommended Titles (TF-IDF):\n                        title                           listed_in     type\n4482  ADAM SANDLER 100% FRESH                     Stand-Up Comedy    Movie\n1879          Hubie Halloween             Comedies, Horror Movies    Movie\n6089    Adam Ruins Everything                         TV Comedies  TV Show\n5639      Jim Gaffigan: Cinco                     Stand-Up Comedy    Movie\n6271          Bedtime Stories  Children & Family Movies, Comedies    Movie\nSimilarity Scores: [0.3720682  0.22767894 0.1952869  0.17793935 0.16485729]\n\n\n\n\nrecommendation system\n\n# Example: user-based inputs to get recommendations\n\ndef recommend_titles(user_genre, user_type, user_actor, user_sentiment, user_description, top_n=5, method=\"tfidf\"):\n    \"\"\"\n    Return recommended titles based on user inputs and similarity measure.\n\n    Parameters:\n      user_genre (str): Desired genre(s)\n      user_type (str): 'Movie' or 'TV Show'\n      user_actor (str): Actor/actress name(s)\n      user_sentiment (str): Sentiment descriptors (e.g., 'funny', 'heartwarming')\n      user_description (str): Additional keywords\n      top_n (int): Number of recommendations to return\n      method (str): 'tfidf' or 'embedding' for similarity calculation\n\n    Returns:f\n    \"\"\"\n    # Combine the user inputs into a single query string\n    user_query = f\"{user_genre} {user_type} {user_actor} {user_sentiment} {user_description}\"\n\n    if method == \"tfidf\":\n        # Vectorize the user query using the same TF-IDF vectorizer used for your dataset\n        query_vec = vectorizer.transform([user_query])\n        # Compute cosine similarity with the dataset's TF-IDF matrix\n        sims = cosine_similarity(query_vec, X_tfidf).flatten()\n    elif method == \"embedding\":\n        # If you have an embedding-based approach, implement it here\n        query_vec = get_doc_vector(user_query)  # e.g., spaCy or other embedding\n        sims = cosine_similarity([query_vec], doc_vectors).flatten()\n    else:\n        raise ValueError(\"Method must be either 'tfidf' or 'embedding'\")\n\n    # Retrieve the indices of the most similar titles\n    top_indices = np.argsort(sims)[::-1][:top_n]\n\n    # Return the top_n recommendations and their similarity scores\n    recommendations = df.iloc[top_indices][['title', 'listed_in', 'type']]\n    return recommendations, sims[top_indices]\n\n\n# ---------------------------\n# Main code that prompts user input\n# ---------------------------\n\nif __name__ == \"__main__\":\n    # Prompt user for inputs\n    user_genre = input(\"Enter your preferred genre (e.g., 'Comedy'): \")\n    user_type = input(\"Enter your preferred type (e.g., 'Movie' or 'TV Show'): \")\n    user_actor = input(\"Enter an actor/actress name (optional): \")\n    user_sentiment = input(\"Enter sentiment words (e.g., 'funny', 'heartwarming'): \")\n    user_description = input(\"Enter additional description keywords: \")\n\n    # Call the recommendation function\n    recommended_titles, sim_scores = recommend_titles(\n        user_genre=user_genre,\n        user_type=user_type,\n        user_actor=user_actor,\n        user_sentiment=user_sentiment,\n        user_description=user_description,\n        top_n=5,             # Number of recommendations\n        method=\"tfidf\"       # or \"embedding\" if you have an embedding approach\n    )\n\n    # Display results\n    print(\"\\nRecommended Titles (TF-IDF):\")\n    print(recommended_titles)\n    print(\"\\nSimilarity Scores:\")\n    print(sim_scores)\n\nEnter your preferred genre (e.g., 'Comedy'): comedy\nEnter your preferred type (e.g., 'Movie' or 'TV Show'): movie\nEnter an actor/actress name (optional): Adam Sandler\nEnter sentiment words (e.g., 'funny', 'heartwarming'): funny heartwarming\nEnter additional description keywords: family vacation\n\n\n\n---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\n&lt;ipython-input-58-42b89ff5dd84&gt; in &lt;cell line: 0&gt;()\n     52 \n     53     # Call the recommendation function\n---&gt; 54     recommended_titles, sim_scores = recommend_titles(\n     55         user_genre=user_genre,\n     56         user_type=user_type,\n\n&lt;ipython-input-58-42b89ff5dd84&gt; in recommend_titles(user_genre, user_type, user_actor, user_sentiment, user_description, top_n, method)\n     23         query_vec = vectorizer.transform([user_query])\n     24         # Compute cosine similarity with the dataset's TF-IDF matrix\n---&gt; 25         sims = cosine_similarity(query_vec, X_tfidf).flatten()\n     26     elif method == \"embedding\":\n     27         # If you have an embedding-based approach, implement it here\n\n/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py in wrapper(*args, **kwargs)\n    214                     )\n    215                 ):\n--&gt; 216                     return func(*args, **kwargs)\n    217             except InvalidParameterError as e:\n    218                 # When the function is just a wrapper around an estimator, we allow\n\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/pairwise.py in cosine_similarity(X, Y, dense_output)\n   1739     # to avoid recursive import\n   1740 \n-&gt; 1741     X, Y = check_pairwise_arrays(X, Y)\n   1742 \n   1743     X_normalized = normalize(X, copy=True)\n\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/pairwise.py in check_pairwise_arrays(X, Y, precomputed, dtype, accept_sparse, force_all_finite, ensure_all_finite, ensure_2d, copy)\n    227         # Only check the number of features if 2d arrays are enforced. Otherwise,\n    228         # validation is left to the user for custom metrics.\n--&gt; 229         raise ValueError(\n    230             \"Incompatible dimension for X and Y matrices: \"\n    231             \"X.shape[1] == %d while Y.shape[1] == %d\" % (X.shape[1], Y.shape[1])\n\nValueError: Incompatible dimension for X and Y matrices: X.shape[1] == 47360 while Y.shape[1] == 17008\n\n\n\n\nimport numpy as np\nimport pandas as pd\nimport re\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\n\n# Assume you have these pre-defined:\n# 1) df: Your Netflix dataset (DataFrame)\n# 2) tfidf_matrix: TF-IDF matrix for df['combined_features'] or df['description']\n# 3) vectorizer: The fitted TfidfVectorizer\n# 4) doc_vectors: (Optional) for embedding approach\n# 5) get_doc_vector: A function for embedding approach\n\ndef recommend_titles(user_genre, user_type, user_actor, user_sentiment, user_description, top_n=5, method=\"tfidf\"):\n    \"\"\"\n    Recommend titles based on user inputs and similarity measure.\n\n    Parameters:\n      user_genre (str): Desired genre(s)\n      user_type (str): 'Movie' or 'TV Show'\n      user_actor (str): Actor/actress names\n      user_sentiment (str): Sentiment descriptors (e.g., 'funny', 'heartwarming')\n      user_description (str): Additional keywords\n      top_n (int): Number of recommendations to return\n      method (str): 'tfidf' or 'embedding' for similarity calculation\n\n    Returns:\n      (DataFrame, np.ndarray): A tuple containing the top recommended titles\n                               and their similarity scores.\n    \"\"\"\n    # Combine user inputs into a query string\n    user_query = f\"{user_genre} {user_type} {user_actor} {user_sentiment} {user_description}\"\n\n    if method == \"tfidf\":\n        # Vectorize the user query with the same TF-IDF vectorizer\n        query_vec = vectorizer.transform([user_query])\n        # Compute cosine similarity with the TF-IDF matrix of your dataset\n        sims = cosine_similarity(query_vec, tfidf_matrix).flatten()\n    elif method == \"embedding\":\n        # If you have an embedding-based approach, convert user_query to embeddings\n        query_vec = get_doc_vector(user_query)\n        sims = cosine_similarity([query_vec], doc_vectors).flatten()\n    else:\n        raise ValueError(\"Method must be either 'tfidf' or 'embedding'\")\n\n    # Get indices of the top_n most similar titles\n    top_indices = np.argsort(sims)[::-1][:top_n]\n\n    # Return the recommended titles and their similarity scores\n    return df.iloc[top_indices][['title', 'listed_in', 'type']], sims[top_indices]\n\n# -------------------------------\n# Main code prompting user input\n# -------------------------------\nif __name__ == \"__main__\":\n    # Prompt user for inputs\n    user_genre = input(\"Enter your preferred genre (e.g., 'Comedy'): \")\n    user_type = input(\"Enter your preferred type (e.g., 'Movie' or 'TV Show'): \")\n    user_actor = input(\"Enter an actor/actress name (optional): \")\n    user_sentiment = input(\"Enter sentiment words (e.g., 'funny', 'heartwarming'): \")\n    user_description = input(\"Enter additional keywords (optional): \")\n\n    # Call the recommendation function\n    recommended_titles, sim_scores = recommend_titles(\n        user_genre=user_genre,\n        user_type=user_type,\n        user_actor=user_actor,\n        user_sentiment=user_sentiment,\n        user_description=user_description,\n        top_n=5,             # Number of recommendations\n        method=\"tfidf\"       # or \"embedding\" if you have an embedding approach\n    )\n\n    # Display results\n    print(\"\\nRecommended Titles (TF-IDF):\")\n    print(recommended_titles)\n    print(\"\\nSimilarity Scores:\")\n    print(sim_scores)\n\nEnter your preferred genre (e.g., 'Comedy'): comedy\nEnter your preferred type (e.g., 'Movie' or 'TV Show'): movie\nEnter an actor/actress name (optional): tom\nEnter sentiment words (e.g., 'funny', 'heartwarming'): funny\nEnter additional keywords (optional): vacation\n\nRecommended Titles (TF-IDF):\n                                 title  \\\n5639               Jim Gaffigan: Cinco   \n5379     Tom Segura: Completely Normal   \n3388         Jenny Slate: Stage Fright   \n4184  Trigger Warning with Killer Mike   \n2782              Tom Segura: Ball Hog   \n\n                                     listed_in     type  \n5639                           Stand-Up Comedy    Movie  \n5379                           Stand-Up Comedy    Movie  \n3388            Documentaries, Stand-Up Comedy    Movie  \n4184  Docuseries, Stand-Up Comedy & Talk Shows  TV Show  \n2782                           Stand-Up Comedy    Movie  \n\nSimilarity Scores:\n[0.25348861 0.19996897 0.1802892  0.17971545 0.17850016]"
  },
  {
    "objectID": "projects/Amazon Product Analysis/Team_Obagi_10B_CSA_Project.html",
    "href": "projects/Amazon Product Analysis/Team_Obagi_10B_CSA_Project.html",
    "title": "My Portfolio",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport re\nimport nltk\nfrom nltk.sentiment import SentimentIntensityAnalyzer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom google.colab import files\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom wordcloud import WordCloud\n\n\n# Load dataset\ndf = pd.read_csv('/content/amazon.csv')\n\n\n# Display basic info\ndf.info()\ndf.head()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 1465 entries, 0 to 1464\nData columns (total 16 columns):\n #   Column               Non-Null Count  Dtype \n---  ------               --------------  ----- \n 0   product_id           1465 non-null   object\n 1   product_name         1465 non-null   object\n 2   category             1465 non-null   object\n 3   discounted_price     1465 non-null   object\n 4   actual_price         1465 non-null   object\n 5   discount_percentage  1465 non-null   object\n 6   rating               1465 non-null   object\n 7   rating_count         1463 non-null   object\n 8   about_product        1465 non-null   object\n 9   user_id              1465 non-null   object\n 10  user_name            1465 non-null   object\n 11  review_id            1465 non-null   object\n 12  review_title         1465 non-null   object\n 13  review_content       1465 non-null   object\n 14  img_link             1465 non-null   object\n 15  product_link         1465 non-null   object\ndtypes: object(16)\nmemory usage: 183.3+ KB\n\n\n\n  \n    \n\n\n\n\n\n\nproduct_id\nproduct_name\ncategory\ndiscounted_price\nactual_price\ndiscount_percentage\nrating\nrating_count\nabout_product\nuser_id\nuser_name\nreview_id\nreview_title\nreview_content\nimg_link\nproduct_link\n\n\n\n\n0\nB07JW9H4J1\nWayona Nylon Braided USB to Lightning Fast Cha...\nComputers&Accessories|Accessories&Peripherals|...\nâ‚¹399\nâ‚¹1,099\n64%\n4.2\n24,269\nHigh Compatibility : Compatible With iPhone 12...\nAG3D6O4STAQKAY2UVGEUV46KN35Q,AHMY5CWJMMK5BJRBB...\nManav,Adarsh gupta,Sundeep,S.Sayeed Ahmed,jasp...\nR3HXWT0LRP0NMF,R2AJM3LFTLZHFO,R6AQJGUP6P86,R1K...\nSatisfied,Charging is really fast,Value for mo...\nLooks durable Charging is fine tooNo complains...\nhttps://m.media-amazon.com/images/W/WEBP_40237...\nhttps://www.amazon.in/Wayona-Braided-WN3LG1-Sy...\n\n\n1\nB098NS6PVG\nAmbrane Unbreakable 60W / 3A Fast Charging 1.5...\nComputers&Accessories|Accessories&Peripherals|...\nâ‚¹199\nâ‚¹349\n43%\n4.0\n43,994\nCompatible with all Type C enabled devices, be...\nAECPFYFQVRUWC3KGNLJIOREFP5LQ,AGYYVPDD7YG7FYNBX...\nArdKn,Nirbhay kumar,Sagar Viswanathan,Asp,Plac...\nRGIQEG07R9HS2,R1SMWZQ86XIN8U,R2J3Y1WL29GWDE,RY...\nA Good Braided Cable for Your Type C Device,Go...\nI ordered this cable to connect my phone to An...\nhttps://m.media-amazon.com/images/W/WEBP_40237...\nhttps://www.amazon.in/Ambrane-Unbreakable-Char...\n\n\n2\nB096MSW6CT\nSounce Fast Phone Charging Cable & Data Sync U...\nComputers&Accessories|Accessories&Peripherals|...\nâ‚¹199\nâ‚¹1,899\n90%\n3.9\n7,928\nã€ Fast Charger& Data Syncã€‘-With built-in safet...\nAGU3BBQ2V2DDAMOAKGFAWDDQ6QHA,AESFLDV2PT363T2AQ...\nKunal,Himanshu,viswanath,sai niharka,saqib mal...\nR3J3EQQ9TZI5ZJ,R3E7WBGK7ID0KV,RWU79XKQ6I1QF,R2...\nGood speed for earlier versions,Good Product,W...\nNot quite durable and sturdy,https://m.media-a...\nhttps://m.media-amazon.com/images/W/WEBP_40237...\nhttps://www.amazon.in/Sounce-iPhone-Charging-C...\n\n\n3\nB08HDJ86NZ\nboAt Deuce USB 300 2 in 1 Type-C & Micro USB S...\nComputers&Accessories|Accessories&Peripherals|...\nâ‚¹329\nâ‚¹699\n53%\n4.2\n94,363\nThe boAt Deuce USB 300 2 in 1 cable is compati...\nAEWAZDZZJLQUYVOVGBEUKSLXHQ5A,AG5HTSFRRE6NL3M5S...\nOmkar dhale,JD,HEMALATHA,Ajwadh a.,amar singh ...\nR3EEUZKKK9J36I,R3HJVYCLYOY554,REDECAZ7AMPQC,R1...\nGood product,Good one,Nice,Really nice product...\nGood product,long wire,Charges good,Nice,I bou...\nhttps://m.media-amazon.com/images/I/41V5FtEWPk...\nhttps://www.amazon.in/Deuce-300-Resistant-Tang...\n\n\n4\nB08CF3B7N1\nPortronics Konnect L 1.2M Fast Charging 3A 8 P...\nComputers&Accessories|Accessories&Peripherals|...\nâ‚¹154\nâ‚¹399\n61%\n4.2\n16,905\n[CHARGE & SYNC FUNCTION]- This cable comes wit...\nAE3Q6KSUK5P75D5HFYHCRAOLODSA,AFUGIFH5ZAFXRDSZH...\nrahuls6099,Swasat Borah,Ajay Wadke,Pranali,RVK...\nR1BP4L2HH9TFUP,R16PVJEXKV6QZS,R2UPDB81N66T4P,R...\nAs good as original,Decent,Good one for second...\nBought this instead of original apple, does th...\nhttps://m.media-amazon.com/images/W/WEBP_40237...\nhttps://www.amazon.in/Portronics-Konnect-POR-1...\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n\n    \n  \n\n\n\n# Drop unnecessary columns based on project plan\ncolumns_to_keep = ['product_id', 'product_name', 'category','discounted_price','actual_price', 'rating', 'rating_count', 'about_product',\n                   'user_id', 'review_id', 'review_title', 'review_content']\ndf = df[columns_to_keep]\n\n\n# Handle missing values\ndf.dropna(subset=['review_content', 'rating'], inplace=True)\n\n\n# Add review length column\ndf['review_length'] = df['review_content'].apply(lambda x: len(str(x).split()))\n\n\nimport nltk\nnltk.download('stopwords')\nfrom sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n\n[nltk_data] Downloading package stopwords to /root/nltk_data...\n[nltk_data]   Unzipping corpora/stopwords.zip.\n\n\n\nimport nltk\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords # Import stopwords from nltk.corpus\nfrom sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n\n# Define stopwords\nstop_words = set(stopwords.words('english'))\n\n# Add custom stopwords\ncustom_stopwords = [\"product\", \"like\",\"good\",\"easy\",\"use\"]  # Add your specific words\nstop_words.update(custom_stopwords)  # Update stopwords set\n\n# Function to preprocess text\ndef preprocess_text(text):\n    text = text.lower()  # Lowercase\n    text = re.sub(r'\\d+', '', text)  # Remove numbers\n    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n    tokens = text.split()  # Tokenization\n    tokens = [word for word in tokens if word not in stop_words]  # Remove stopwords\n    return ' '.join(tokens)\n\n[nltk_data] Downloading package stopwords to /root/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n\n\n\n# Apply preprocessing\ndf['cleaned_review'] = df['review_content'].astype(str).apply(preprocess_text)\n\n\nreviews = df['cleaned_review']\n\nvectorizer = TfidfVectorizer(min_df=5, max_df=0.8, max_features=5000, stop_words='english')\nX = vectorizer.fit_transform(reviews)\n\n# Get the terms (words) and their corresponding term frequencies (TF)\nterms = vectorizer.get_feature_names_out()\nterm_frequencies = X.sum(axis=0).A1  # Sum across all documents\n\nfrequency_df = pd.DataFrame(list(zip(terms, term_frequencies)), columns=['Word', 'Frequency'])\nfrequency_df = frequency_df.sort_values(by='Frequency', ascending=False)\n\n# Display the top 10 most frequent words\nprint(frequency_df.head(10))\n\n          Word  Frequency\n2519   quality  70.256776\n397      cable  67.148906\n486   charging  51.103816\n2387     price  46.262668\n3589   working  37.917501\n2267     phone  37.902488\n3433     using  36.223175\n242    battery  34.270183\n3346        tv  32.496618\n384        buy  32.475281\n\n\n\n# Initialize Sentiment Analyzer\nnltk.download('vader_lexicon')\nsia = SentimentIntensityAnalyzer()\n\n[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n\n\n\ndef get_sentiment(text):\n    \"\"\"Classifies sentiment as Positive, Neutral, or Negative.\"\"\"\n    score = sia.polarity_scores(text)['compound']\n    if score &gt; 0.05:\n        return 1\n    elif score &lt; -0.05:\n        return -1\n    else:\n        return 0\n\n\n# Apply sentiment analysis\ndf['sentiment'] = df['cleaned_review'].apply(get_sentiment)\n\n\ndf['cleaned_review'].head(5)\n\n\n\n\n\n\n\n\ncleaned_review\n\n\n\n\n0\nlooks durable charging fine toono complainscha...\n\n\n1\nordered cable connect phone android auto car c...\n\n\n2\nquite durable sturdyhttpsmmediaamazoncomimages...\n\n\n3\nproductlong wirecharges goodnicei bought cable...\n\n\n4\nbought instead original apple work rs fast app...\n\n\n\n\ndtype: object\n\n\n\n# Define a mapping dictionary\nsentiment_mapping = {1: \"Positive\", 0: \"Neutral\", -1: \"Negative\"}\n\n# Create a new column with mapped sentiment labels\ndf[\"sentiment_label_text\"] = df[\"sentiment\"].map(sentiment_mapping)\n\n# Display the first few rows\nprint(df[[\"sentiment\", \"sentiment_label_text\"]].head())\n\n   sentiment sentiment_label_text\n0          1             Positive\n1          1             Positive\n2          1             Positive\n3          1             Positive\n4          1             Positive\n\n\n\n# Sentiment distribution\nplt.figure(figsize=(6,4))\nsns.countplot(x='sentiment_label_text', data=df, palette='coolwarm')\nplt.title('Sentiment Distribution')\nplt.show()\n\nFutureWarning: \n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n\n  sns.countplot(x='sentiment_label_text', data=df, palette='coolwarm')\n\n\n\n\n\n\n\n\n\n\n# Review Length vs. Sentiment\nplt.figure(figsize=(8,5))\nsns.boxplot(x='sentiment_label_text', y='review_length', data=df, palette='coolwarm')\nplt.title('Review Length vs. Sentiment')\nplt.show()\n\nFutureWarning: \n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n\n  sns.boxplot(x='sentiment_label_text', y='review_length', data=df, palette='coolwarm')\n\n\n\n\n\n\n\n\n\n\n# Regression Analysis: Review Length vs. Rating\nX = df[['review_length']]\n# Convert 'rating' to numeric, handling errors, and then drop NaNs\ny = pd.to_numeric(df['rating'], errors='coerce').dropna()\n# Filter the DataFrame based on the valid ratings in 'y'\ndf = df[df.index.isin(y.index)]\nX = df[['review_length']]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n\ny_pred = model.predict(X_test)\n\n\n# Regression Metrics\nprint(\"Mean Squared Error:\", mean_squared_error(y_test, y_pred))\nprint(\"R-squared Score:\", r2_score(y_test, y_pred))\n\nMean Squared Error: 0.07705379430653071\nR-squared Score: 0.00699365804788743\n\n\n\n# Plot Regression\nplt.figure(figsize=(8,5))\n# Ensure 'rating' is numeric before plotting\ndf['rating'] = pd.to_numeric(df['rating'], errors='coerce')\ndf = df.dropna(subset=['rating'])  # Drop rows with invalid ratings\nsns.regplot(x=df['review_length'], y=df['rating'], scatter_kws={'alpha':0.3}, line_kws={'color':'red'})\nplt.title('Review Length vs. Rating')\nplt.xlabel('Review Length')\nplt.ylabel('Rating')\nplt.show()\n\n\n\n\n\n\n\n\n\n# Sentiment vs. Product Rating\nplt.figure(figsize=(8,5))\nsns.boxplot(x='sentiment_label_text', y='rating', data=df, palette='coolwarm')\nplt.title('Sentiment vs. Product Rating')\nplt.show()\n\nFutureWarning: \n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n\n  sns.boxplot(x='sentiment_label_text', y='rating', data=df, palette='coolwarm')\n\n\n\n\n\n\n\n\n\n\n# Distribution of Review Lengths by Sentiment\nplt.figure(figsize=(8,5))\nsns.histplot(data=df, x='review_length', hue='sentiment_label_text', bins=30, kde=True, palette='coolwarm')\nplt.title('Distribution of Review Lengths by Sentiment')\nplt.show()\n\n\n\n\n\n\n\n\n\ncorrelation = df[\"review_length\"].corr(df[\"rating\"])\nprint(f\"Correlation between review length and rating: {correlation:.4f}\")\n\nCorrelation between review length and rating: 0.0787\n\n\n\ncorrelation = df[\"review_length\"].corr(df[\"sentiment\"])\nprint(f\"Correlation between review length and sentiment: {correlation:.4f}\")\n\nCorrelation between review length and sentiment: 0.0835\n\n\n\n#Top 5 categories that has the most review\ntop_categories = df['category'].value_counts().head(5)\n\n# Display the top 5 categories with the most reviews\nprint(top_categories)\n\ncategory\nComputers&Accessories|Accessories&Peripherals|Cables&Accessories|Cables|USBCables    233\nElectronics|WearableTechnology|SmartWatches                                           76\nElectronics|Mobiles&Accessories|Smartphones&BasicMobiles|Smartphones                  68\nElectronics|HomeTheater,TV&Video|Televisions|SmartTelevisions                         63\nElectronics|Headphones,Earbuds&Accessories|Headphones|In-Ear                          52\nName: count, dtype: int64\n\n\n\n# Plot the bar chart\nplt.figure(figsize=(10, 6))\nsns.barplot(x=top_categories.values, y=top_categories.index, palette=\"viridis\")\n\n# Add labels and title\nplt.xlabel(\"Number of Reviews\")\nplt.ylabel(\"Category\")\nplt.title(\"Top 5 Categories with Most Reviews\")\nplt.xticks(rotation=45)\nplt.show()\n\nFutureWarning: \n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n\n  sns.barplot(x=top_categories.values, y=top_categories.index, palette=\"viridis\")\n\n\n\n\n\n\n\n\n\n\nprint(df[\"cleaned_review\"].isnull().sum())\nprint(df[\"cleaned_review\"].str.len().sum())\n\nprint(df[\"sentiment\"].value_counts())\n\n0\n1301289\nsentiment\n 1    1344\n-1     101\n 0      19\nName: count, dtype: int64\n\n\n\n# Filter positive reviews\npositive_reviews = df[\"cleaned_review\"].dropna().astype(str)\n\n# Initialize TfidfVectorizer\nvectorizer = TfidfVectorizer(min_df=5, max_df=0.8, max_features=5000,ngram_range=(2,3))\n\n# Fit and transform the positive reviews\ntfidf_matrix = vectorizer.fit_transform(positive_reviews)\n\n# Get feature names (words) and their corresponding TF-IDF scores\nfeature_names = vectorizer.get_feature_names_out()\ntfidf_scores = tfidf_matrix.sum(axis=0).A1  # Sum TF-IDF scores for each word\n\n# Create dictionary of words and their TF-IDF scores\nword_scores = dict(zip(feature_names, tfidf_scores))\n\n# Generate WordCloud\nwordcloud = WordCloud(width=800, height=400, background_color=\"white\", colormap=\"viridis\").generate_from_frequencies(word_scores)\n\n# Plot the WordCloud\nplt.figure(figsize=(10, 5))\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis(\"off\")\nplt.title(\"Positive Reviews WordCloud (TF-IDF)\", fontsize=14)\nplt.show()\n\n\n\n\n\n\n\n\n\n# Filter negative reviews\nnegative_reviews = df[df['sentiment'] == -1]['cleaned_review']\n\n# Vectorize the negative reviews using TfidfVectorizer\nvectorizer = TfidfVectorizer(max_features=5000, ngram_range=(2, 3))\nX = vectorizer.fit_transform(negative_reviews)\n\n# Get the feature names (words/phrases)\nfeature_names = vectorizer.get_feature_names_out()\n\n# Get the tf-idf scores for each feature (word/phrase)\ntfidf_scores = X.sum(axis=0).A1  # Summing scores across all reviews for each feature\n\n# Create a dictionary of words and their corresponding scores\nword_scores = dict(zip(feature_names, tfidf_scores))\n\n# Generate the word cloud\nwordcloud = WordCloud(width=800, height=400, background_color='white', colormap=\"Reds\").generate_from_frequencies(word_scores)\n\n# Plot the word cloud\nplt.figure(figsize=(10, 5))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis('off')\nplt.show()\n\n\n\n\n\n\n\n\n\nfrom sklearn.linear_model import LogisticRegression\n\n# Convert text into numerical vectors using TF-IDF\nvectorizer = TfidfVectorizer(max_features=5000)\nX = vectorizer.fit_transform(df['cleaned_review'])\ny = df['sentiment']\n\n# Split data into training & test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\n# Train a Logistic Regression model\nmodel = LogisticRegression(class_weight='balanced', random_state=42)\nmodel.fit(X_train, y_train)  # Model now gives equal importance to all classes\n\n# Predict sentiment\ny_pred = model.predict(X_test)\n\nprint(pd.Series(y_train).value_counts())\nprint(pd.Series(y_test).value_counts())\n\n# Evaluate model performance\naccuracy = accuracy_score(y_test, y_pred)\nprint(f\"Model Accuracy: {accuracy:.2f}\")\nprint(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n\nsentiment\n 1    944\n-1     69\n 0     11\nName: count, dtype: int64\nsentiment\n 1    400\n-1     32\n 0      8\nName: count, dtype: int64\nModel Accuracy: 0.92\nClassification Report:\n               precision    recall  f1-score   support\n\n          -1       0.83      0.16      0.26        32\n           0       0.00      0.00      0.00         8\n           1       0.92      1.00      0.96       400\n\n    accuracy                           0.92       440\n   macro avg       0.58      0.39      0.41       440\nweighted avg       0.90      0.92      0.89       440\n\n\n\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n\n\n\n# Convert text to numerical features using TF-IDF\nvectorizer = TfidfVectorizer(min_df=5, max_df=0.8, max_features=5000, ngram_range=(3,4))\n\nX = vectorizer.fit_transform(df['cleaned_review'])\n\n# Get feature names\nfeature_names = vectorizer.get_feature_names_out()\nprint(\"Top 10 Features:\", feature_names[:10])\n\nTop 10 Features: ['accessory travelling without' 'accessory travelling without risking'\n 'accuracy feel little' 'accuracy feel little bit' 'accurate near trust'\n 'accurate near trust emergency' 'accurate sensors efficiently'\n 'accurate sensors efficiently worked' 'accurate sensorsbad ui'\n 'accurate sensorsbad ui fonts']\n\n\n\n# Plot the top 10 frequent words\ntop_10_words = frequency_df.head(10)\n\nplt.figure(figsize=(10, 6))\nplt.barh(top_10_words['Word'], top_10_words['Frequency'], color='skyblue')\nplt.xlabel('Frequency')\nplt.title('Top 10 Most Frequent Words')\nplt.gca().invert_yaxis()\nplt.show()\n\n\n\n\n\n\n\n\n\n# Use SMOTE to handle the class imbalance\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.model_selection import train_test_split\n\n# Convert text data into numerical features (e.g., TF-IDF)\nvectorizer = TfidfVectorizer(min_df=5, max_df=0.8, max_features=5000)\nX = vectorizer.fit_transform(df['cleaned_review'])\ny = df['sentiment']\n\n# Split data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\n# Adjust SMOTE to handle small classes\nsmote = SMOTE(sampling_strategy='auto', random_state=42, k_neighbors=min(3, len(y_train.unique()) - 1))\n\nX_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n\n# Check class balance\nprint(pd.Series(y_train_resampled).value_counts())\nprint(pd.Series(y_train).value_counts())\n\nsentiment\n 1    944\n-1    944\n 0    944\nName: count, dtype: int64\nsentiment\n 1    944\n-1     69\n 0     11\nName: count, dtype: int64\n\n\n\n# Machine learning models accuracy after fixing the class imbalance on the train test\n# Train Logistic Regression model\nmodel = LogisticRegression(class_weight='balanced', random_state=42)\nmodel.fit(X_train_resampled, y_train_resampled)\n\n# Predict sentiment\ny_pred = model.predict(X_test)\n\n# Evaluate model performance\naccuracy = accuracy_score(y_test, y_pred)\nprint(f\"Model Accuracy: {accuracy:.2f}\")\nprint(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n\nModel Accuracy: 0.92\nClassification Report:\n               precision    recall  f1-score   support\n\n          -1       1.00      0.16      0.27        32\n           0       0.00      0.00      0.00         8\n           1       0.92      1.00      0.96       400\n\n    accuracy                           0.92       440\n   macro avg       0.64      0.39      0.41       440\nweighted avg       0.91      0.92      0.89       440\n\n\n\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n\n\n\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Train Random Forest\nrf_model = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')\nrf_model.fit(X_train, y_train)\n\n# Predict sentiment\ny_pred_rf_1 = rf_model.predict(X_test)\n\n# Evaluate model performance\naccuracy = accuracy_score(y_test, y_pred_rf_1)\nprint(f\"Model Accuracy: {accuracy:.2f}\")\nprint(\"Classification Report:\\n\", classification_report(y_test, y_pred_rf_1))\n\nModel Accuracy: 0.91\nClassification Report:\n               precision    recall  f1-score   support\n\n          -1       1.00      0.06      0.12        32\n           0       0.00      0.00      0.00         8\n           1       0.91      1.00      0.95       400\n\n    accuracy                           0.91       440\n   macro avg       0.64      0.35      0.36       440\nweighted avg       0.90      0.91      0.88       440\n\n\n\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n\n\n\nfrom sklearn.svm import SVC\n\n# Train SVM\nsvm_model = SVC(kernel='linear', class_weight='balanced', random_state=42)\nsvm_model.fit(X_train_resampled, y_train_resampled)\n\n# Predictions\ny_pred_svm = svm_model.predict(X_test)\n\n# Evaluate model performance\naccuracy = accuracy_score(y_test, y_pred_svm)\nprint(f\"Model Accuracy: {accuracy:.2f}\")\nprint(\"Classification Report:\\n\", classification_report(y_test, y_pred_svm))\n\nModel Accuracy: 0.92\nClassification Report:\n               precision    recall  f1-score   support\n\n          -1       1.00      0.16      0.27        32\n           0       0.00      0.00      0.00         8\n           1       0.92      1.00      0.96       400\n\n    accuracy                           0.92       440\n   macro avg       0.64      0.39      0.41       440\nweighted avg       0.91      0.92      0.89       440\n\n\n\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n\n\n\n#Topic Modeling on Negative Reviews\n#LDA to find topics in negative reviews\nfrom sklearn.decomposition import LatentDirichletAllocation\nfrom sklearn.feature_extraction.text import CountVectorizer\n\nvectorizer = CountVectorizer(max_features=5000, stop_words='english', ngram_range=(2,3))\nX = vectorizer.fit_transform(df[df['sentiment'] == -1]['cleaned_review'])\n\nlda_model = LatentDirichletAllocation(n_components=5, random_state=42)\nlda_model.fit(X)\n\n# Print topics\nfor index, topic in enumerate(lda_model.components_):\n    words = [vectorizer.get_feature_names_out()[i] for i in topic.argsort()[-10:]]\n    print(f\"Topic {index+1}: {', '.join(words)}\")\n\nTopic 1: stopped working, value money, till date, dont buy, charging cable, buy cheap, vacuum mop, worth money, suction power, battery life\nTopic 2: wall hanging hook, addresswhy bad badthey, floor mount, badthey come support, ok smart, buy floor mount, quality poor, bad service, google tv, installation guy\nTopic 3: goodgreat really durablegood, headphone jack, problem earphone jack, able hear, customer care, got delivered, need frequently, quality bad, using months, cord length\nTopic 4: poor quality, smudge proof, switch socket, click time, gas stove, change temperature, picture quality, set minutes, fast charging, charging cable\nTopic 5: worth price, local cable, iam using, worth money, year warranty, remote control, sound quality, quality price, tv mains, picture quality"
  },
  {
    "objectID": "projects/Yelp Restaurant Rating /yelp-restaurant-ratings-analysis.html",
    "href": "projects/Yelp Restaurant Rating /yelp-restaurant-ratings-analysis.html",
    "title": "ğŸ½ï¸ Yelp Restaurant Ratings Analysis",
    "section": "",
    "text": "This project analyzes Yelp restaurant data across California to identify key drivers behind customer ratings and provide actionable insights for small restaurant owners. Using machine learning models and data visualizations, the study reveals how cuisine type, location, and customer feedback influence restaurant success."
  },
  {
    "objectID": "projects/Yelp Restaurant Rating /yelp-restaurant-ratings-analysis.html#project-overview",
    "href": "projects/Yelp Restaurant Rating /yelp-restaurant-ratings-analysis.html#project-overview",
    "title": "ğŸ½ï¸ Yelp Restaurant Ratings Analysis",
    "section": "",
    "text": "This project analyzes Yelp restaurant data across California to identify key drivers behind customer ratings and provide actionable insights for small restaurant owners. Using machine learning models and data visualizations, the study reveals how cuisine type, location, and customer feedback influence restaurant success."
  },
  {
    "objectID": "projects/Yelp Restaurant Rating /yelp-restaurant-ratings-analysis.html#objectives",
    "href": "projects/Yelp Restaurant Rating /yelp-restaurant-ratings-analysis.html#objectives",
    "title": "ğŸ½ï¸ Yelp Restaurant Ratings Analysis",
    "section": "ğŸ¯ Objectives",
    "text": "ğŸ¯ Objectives\n\nIdentify popular cuisines and their rating patterns\nUnderstand the impact of location and number of reviews on ratings\nPredict restaurant success using classification models\nSupport small restaurant owners with data-driven strategies"
  },
  {
    "objectID": "projects/Yelp Restaurant Rating /yelp-restaurant-ratings-analysis.html#data-methods",
    "href": "projects/Yelp Restaurant Rating /yelp-restaurant-ratings-analysis.html#data-methods",
    "title": "ğŸ½ï¸ Yelp Restaurant Ratings Analysis",
    "section": "ğŸ—‚ï¸ Data & Methods",
    "text": "ğŸ—‚ï¸ Data & Methods\n\nData Source: Yelp data scraped via Python (2,177 restaurant entries)\nFeatures: Cuisine type, review count, price range, location (lat/lon), rating\nTools: Python, Pandas, Scikit-learn, Matplotlib\nModels Used: Decision Tree, K-Nearest Neighbor, Random Forest"
  },
  {
    "objectID": "projects/Yelp Restaurant Rating /yelp-restaurant-ratings-analysis.html#key-insights",
    "href": "projects/Yelp Restaurant Rating /yelp-restaurant-ratings-analysis.html#key-insights",
    "title": "ğŸ½ï¸ Yelp Restaurant Ratings Analysis",
    "section": "ğŸ“Š Key Insights",
    "text": "ğŸ“Š Key Insights\n\nTop Cuisines: Mexican, New American, and Italian are the most popular in California\nMexican Cuisine: Shows wide variability in ratings, indicating inconsistent experiences\nLocation & Review Count Matter: These were the most important predictors in rating performance"
  },
  {
    "objectID": "projects/Yelp Restaurant Rating /yelp-restaurant-ratings-analysis.html#model-performance",
    "href": "projects/Yelp Restaurant Rating /yelp-restaurant-ratings-analysis.html#model-performance",
    "title": "ğŸ½ï¸ Yelp Restaurant Ratings Analysis",
    "section": "ğŸ¤– Model Performance",
    "text": "ğŸ¤– Model Performance\n\n\n\nModel\nAccuracy\nF1 Score\nPrecision\nRecall\n\n\n\n\nDecision Tree\n61.7%\n0.72\n0.76\n0.69\n\n\nKNN (Tuned)\n64.1%\n0.77\n0.66\n0.93\n\n\nRandom Forest\n71.8%\n0.81\n0.74\n0.89\n\n\n\n\nRandom Forest performed best overall, identifying high-rated restaurants effectively.\nKNN excelled in recall, while Decision Tree had the fewest false positives."
  },
  {
    "objectID": "projects/Yelp Restaurant Rating /yelp-restaurant-ratings-analysis.html#business-recommendations",
    "href": "projects/Yelp Restaurant Rating /yelp-restaurant-ratings-analysis.html#business-recommendations",
    "title": "ğŸ½ï¸ Yelp Restaurant Ratings Analysis",
    "section": "ğŸ’¼ Business Recommendations",
    "text": "ğŸ’¼ Business Recommendations\n\nLocation Strategy: Choose areas with high traffic or market through social platforms to boost visibility in suburban areas.\nReview Management: Actively solicit and respond to reviews to enhance credibility and ratings.\nQuality Consistency: Standardize food and service quality, especially in cuisines with rating volatility like Mexican."
  },
  {
    "objectID": "projects/Yelp Restaurant Rating /yelp-restaurant-ratings-analysis.html#conclusion",
    "href": "projects/Yelp Restaurant Rating /yelp-restaurant-ratings-analysis.html#conclusion",
    "title": "ğŸ½ï¸ Yelp Restaurant Ratings Analysis",
    "section": "ğŸ§¾ Conclusion",
    "text": "ğŸ§¾ Conclusion\nThis project highlights how Yelp data can help small restaurants better understand customer behavior and optimize operations. By applying machine learning and analysis techniques, restaurant owners can gain strategic insights into location, cuisine impact, and review managementâ€”ultimately leading to better customer satisfaction and improved performance."
  },
  {
    "objectID": "projects/Yelp Restaurant Rating /yelp-restaurant-ratings-analysis.html#github-repository",
    "href": "projects/Yelp Restaurant Rating /yelp-restaurant-ratings-analysis.html#github-repository",
    "title": "ğŸ½ï¸ Yelp Restaurant Ratings Analysis",
    "section": "ğŸ“ GitHub Repository",
    "text": "ğŸ“ GitHub Repository\nğŸ‘‰ View Code on GitHub"
  },
  {
    "objectID": "projects/Customer Segmentation/Clustering Project.html",
    "href": "projects/Customer Segmentation/Clustering Project.html",
    "title": "My Portfolio",
    "section": "",
    "text": "# Mount Google Drive in Colab\nfrom google.colab import drive\ndrive.mount('/content/drive')\n\nMounted at /content/drive\n\n\n\nimport pandas as pd\n\n#read the Clustering Data csv file\ndata = pd.read_csv('/content/drive/MyDrive/Clustering Data.csv')\n\n\nfrom google.colab.data_table import DataTable\nDataTable.max_columns = 100\n\n\ndata.head()\n\n\n  \n    \n\n\n\n\n\n\nuid\nPNRLocatorID\navg_amt\nround_trip\ngroup_size\ngroup\ndays_pre_booked\nBookingChannel_Other\nBookingChannel_Outside_Booking\nBookingChannel_Reservations_Booking\n...\ntrue_destination_dest_SXM\ntrue_destination_dest_TPA\ntrue_destination_dest_ZIH\nUflyMemberStatus_Elite\nUflyMemberStatus_non-ufly\nUflyMemberStatus_Standard\nseasonality_Q1\nseasonality_Q2\nseasonality_Q3\nseasonality_Q4\n\n\n\n\n0\n504554455244696420493F7C2067657420746869732072...\nAADMLF\n0.019524\n0\n0.000\n0\n0.029703\n0\n1\n0\n...\n0\n0\n0\n0\n0\n1\n0\n0\n0\n1\n\n\n1\n46495853454E44696420493F7C20676574207468697320...\nAAFBOM\n0.081774\n1\n0.000\n0\n0.039604\n0\n0\n0\n...\n0\n0\n0\n0\n0\n1\n0\n0\n1\n0\n\n\n2\n534355545444696420493F7C2067657420746869732072...\nAAFILI\n0.026650\n0\n0.125\n1\n0.069307\n0\n0\n0\n...\n0\n0\n0\n0\n1\n0\n1\n0\n0\n0\n\n\n3\n534355545444696420493F7C2067657420746869732072...\nAAFILI\n0.026650\n0\n0.125\n1\n0.069307\n0\n0\n0\n...\n0\n0\n0\n0\n1\n0\n1\n0\n0\n0\n\n\n4\n44554D4D414E4E44696420493F7C206765742074686973...\nAAFRQI\n0.000000\n1\n0.000\n0\n0.035361\n0\n1\n0\n...\n0\n0\n0\n0\n1\n0\n0\n0\n0\n1\n\n\n\n\n5 rows Ã— 90 columns\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n\n    \n  \n\n\n\nclustering_data = data.copy()\nclustering_data = clustering_data.drop(['uid','PNRLocatorID'],axis =1)\n\n\n#find the optimum number of cluster\nfrom sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\n\ninertia = []\ncluster_range = range(1,21)\n\nfor cluster_num in cluster_range:\n  kmeans = KMeans(n_clusters=cluster_num,n_init = 10, random_state = 24)\n  kmeans.fit(clustering_data)\n  inertia.append(kmeans.inertia_)\n\nplt.figure(figsize=(10,6))\nplt.plot(cluster_range,inertia,marker='o', linestyle ='--')\nplt.xlabel('Number of Clusters')\nplt.ylabel('Inertia')\nplt.grid(True)\n\n\n\n\n\n\n\n\n\n#Applying KMeans\nkmeans = KMeans(n_clusters = 5,n_init=30)\nkmeans.fit(clustering_data)\n\ndata['Cluster'] = kmeans.labels_\ndata.head(10000)\n\n\n  \n    \n\n\n\n\n\n\nuid\nPNRLocatorID\navg_amt\nround_trip\ngroup_size\ngroup\ndays_pre_booked\nBookingChannel_Other\nBookingChannel_Outside_Booking\nBookingChannel_Reservations_Booking\n...\ntrue_destination_dest_TPA\ntrue_destination_dest_ZIH\nUflyMemberStatus_Elite\nUflyMemberStatus_non-ufly\nUflyMemberStatus_Standard\nseasonality_Q1\nseasonality_Q2\nseasonality_Q3\nseasonality_Q4\nCluster\n\n\n\n\n0\n504554455244696420493F7C2067657420746869732072...\nAADMLF\n0.019524\n0\n0.000\n0\n0.029703\n0\n1\n0\n...\n0\n0\n0\n0\n1\n0\n0\n0\n1\n3\n\n\n1\n46495853454E44696420493F7C20676574207468697320...\nAAFBOM\n0.081774\n1\n0.000\n0\n0.039604\n0\n0\n0\n...\n0\n0\n0\n0\n1\n0\n0\n1\n0\n3\n\n\n2\n534355545444696420493F7C2067657420746869732072...\nAAFILI\n0.026650\n0\n0.125\n1\n0.069307\n0\n0\n0\n...\n0\n0\n0\n1\n0\n1\n0\n0\n0\n1\n\n\n3\n534355545444696420493F7C2067657420746869732072...\nAAFILI\n0.026650\n0\n0.125\n1\n0.069307\n0\n0\n0\n...\n0\n0\n0\n1\n0\n1\n0\n0\n0\n1\n\n\n4\n44554D4D414E4E44696420493F7C206765742074686973...\nAAFRQI\n0.000000\n1\n0.000\n0\n0.035361\n0\n1\n0\n...\n0\n0\n0\n1\n0\n0\n0\n0\n1\n0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n9995\n465241484D44696420493F7C2067657420746869732072...\nOVDEVE\n0.042032\n0\n0.125\n1\n0.036775\n0\n0\n0\n...\n0\n0\n0\n0\n1\n0\n0\n1\n0\n3\n\n\n9996\n5649434B45525944696420493F7C206765742074686973...\nOVDVCT\n0.049705\n0\n0.000\n0\n0.028289\n0\n1\n0\n...\n0\n0\n0\n1\n0\n0\n0\n1\n0\n0\n\n\n9997\n535445504B4144696420493F7C20676574207468697320...\nOVGARJ\n0.012305\n1\n0.000\n0\n0.019802\n0\n1\n0\n...\n0\n0\n0\n1\n0\n0\n0\n1\n0\n4\n\n\n9998\n4B4F53544B4F44696420493F7C20676574207468697320...\nOVGBHE\n0.067609\n1\n0.125\n1\n0.125884\n0\n1\n0\n...\n0\n0\n0\n1\n0\n0\n0\n1\n0\n4\n\n\n9999\n59414244696420493F7C20676574207468697320726967...\nOVGBHE\n0.067609\n1\n0.125\n1\n0.125884\n0\n1\n0\n...\n0\n0\n0\n1\n0\n0\n0\n1\n0\n4\n\n\n\n\n10000 rows Ã— 91 columns\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n\n    \n  \n\n\n\n#sort and count for each number of cluster\ncluster_size = data['Cluster'].value_counts().sort_index()\ncluster_size\n\n\n\n\n\n\n\n\ncount\n\n\nCluster\n\n\n\n\n\n0\n2441\n\n\n1\n2351\n\n\n2\n4127\n\n\n3\n2387\n\n\n4\n3838\n\n\n\n\ndtype: int64\n\n\n\nreservation_data = pd.read_csv('/content/drive/MyDrive/sample_data_transformed.csv')\n\nDtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.\n  reservation_data = pd.read_csv('/content/drive/MyDrive/sample_data_transformed.csv')\n\n\n\n#Merge sample_data_transformed and cluster data\nfinal_dataframe = reservation_data.merge(data[['uid', 'Cluster']], on='uid', how='left')\n\n\nfinal_dataframe.head()\n\n\n  \n    \n\n\n\n\n\n\nUnnamed: 0\nPNRLocatorID\nPaxName\nTicketNum\nCouponSeqNbr\nServiceStartCity\nServiceEndCity\nPNRCreateDate\nServiceStartDate\nEncryptedName\n...\nage_group\ntrue_origins\nfinal_destination\nround_trip\ngroup_size\ngroup\nseasonality\ndays_pre_booked\ntrue_destination\nCluster\n\n\n\n\n0\n1\nAADMLF\nPETEJO\n3.377490e+12\n1\nMSP\nDFW\n9/15/14\n10/6/14\n504554455244696420493F7C2067657420746869732072...\n...\n55+\nMSP\nDFW\n0\n1\n0\nQ4\n21\nDFW\n3\n\n\n1\n2\nAAFBOM\nFIXSMO\n3.372110e+12\n2\nJFK\nMSP\n7/22/14\n8/19/14\n46495853454E44696420493F7C20676574207468697320...\n...\n35-54\nMSP\nMSP\n1\n1\n0\nQ3\n28\nJFK\n3\n\n\n2\n3\nAAFBOM\nFIXSMO\n3.372110e+12\n1\nMSP\nJFK\n7/22/14\n8/14/14\n46495853454E44696420493F7C20676574207468697320...\n...\n35-54\nMSP\nMSP\n1\n1\n0\nQ3\n23\nJFK\n3\n\n\n3\n4\nAAFILI\nSCUTKA\n3.372110e+12\n2\nMSP\nSEA\n2/6/14\n3/27/14\n534355545444696420493F7C2067657420746869732072...\n...\n25-34\nLAN\nSEA\n0\n2\n1\nQ1\n49\nMSP\n1\n\n\n4\n5\nAAFILI\nSCUTKA\n3.372110e+12\n1\nLAN\nMSP\n2/6/14\n3/27/14\n534355545444696420493F7C2067657420746869732072...\n...\n25-34\nLAN\nSEA\n0\n2\n1\nQ1\n49\nMSP\n1\n\n\n\n\n5 rows Ã— 38 columns\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n\n    \n  \n\n\n\n#Template Code for Visualization\ncluster_color = {\n    0: 'red',\n    1: 'blue',\n    2: 'yellow',\n    3: 'green',\n    4: 'purple'\n}\ncluster_season = final_dataframe.groupby('Cluster')['group'].sum()\n\nplt.figure(figsize=(10,6))\nfor cluster in range(len(cluster_season)):\n  plt.bar(cluster,cluster_season[cluster],color = cluster_color[cluster])\n\nplt.title('Number of people traveling in a group')\nplt.xlabel('Cluster')\nplt.ylabel('Number of Travel made in the Season')\nplt.xticks(ticks = range(len(cluster_season)))\nplt.grid(axis='y')\nplt.show()\n\n\n\n\n\n\n\n\n\ncluster_seasonality_counts = final_dataframe.groupby('Cluster')['seasonality'].value_counts().unstack().fillna(0)\n\n# Pie charts for seasonality\nfor cluster in cluster_seasonality_counts.index:\n    season_counts = cluster_seasonality_counts.loc[cluster]\n    plt.figure()\n    plt.pie(season_counts, labels=season_counts.index, autopct='%1.1f%%', startangle=140)\n    plt.axis('equal')\n    plt.title(f'Seasonality Distribution for Cluster {cluster}')\n    plt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Count the number of people traveling in a group by cluster\n\n#group_travelers = final_dataframe[final_dataframe['group_size'] &gt; 1]\n#cluster_group_size = group_travelers.groupby('Cluster')['group_size'].count().reset_index()\n\n#plt.figure(figsize=(10,6))\n\n#for cluster in range(len(cluster_group_size)):\n#  plt.bar(cluster,cluster_season[cluster],color = cluster_color[cluster])\n\n#plt.title('Number of People Traveling in a Group by Cluster')\n#plt.xlabel('Cluster')\n#plt.ylabel('Number of People Traveling in a Group')\n#plt.grid(axis='y')\n#plt.show()\n\ncluster_group_size = final_dataframe.groupby('Cluster')['group_size'].value_counts()\n\npivot_data = cluster_group_size.unstack().fillna(0)\n\npivot_data.plot(kind='bar', stacked=True, figsize=(10, 7))\nplt.title('Number of Group Size by Cluster')\nplt.xlabel('Cluster')\nplt.ylabel('Number of Data')\nplt.xticks(rotation=0)\nplt.legend(title='Group Size', bbox_to_anchor=(1.05, 1), loc='upper left')\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nmost_group_size = final_dataframe.groupby('Cluster')['group_size'].mean()\n\nprint(most_group_size)\n\nCluster\n0    1.906293\n1    1.549622\n2    2.393798\n3    2.229292\n4    1.826769\nName: group_size, dtype: float64\n\n\n\n#Days_pre_book by mean\ncluster_days_pre_book = final_dataframe.groupby('Cluster')['days_pre_booked'].mean()\n\nplt.figure(figsize=(10,6))\n\nfor cluster in cluster_days_pre_book.index:\n  plt.bar(cluster,cluster_days_pre_book[cluster],color = cluster_color[cluster])\n\nplt.title('Number of days pre book ')\nplt.xlabel('Cluster')\nplt.ylabel('Number of days')\nplt.grid(axis='y')\nplt.show()\n\n\n\n\n\n\n\n\n\n# Group the dataframe by 'Cluster' and calculate the mean of 'days_pre_booked' for each cluster\nmean_days_pre_book = final_dataframe.groupby('Cluster')['days_pre_booked'].mean()\n\n# Print the mean number of days pre-booked for each cluster\nprint(mean_days_pre_book)\n\nCluster\n0    67.770326\n1    36.250914\n2    60.062692\n3    61.768605\n4    51.006279\nName: days_pre_booked, dtype: float64\n\n\n\ncluster_BaseFareAmt = final_dataframe.groupby('Cluster')['BaseFareAmt'].value_counts()\n\npivot_data = cluster_BaseFareAmt.unstack().fillna(0)\n\npivot_data.plot(kind='bar', stacked=True, figsize=(10, 7))\nplt.title('Amount of Base Fare by Cluster')\nplt.xlabel('Cluster')\nplt.ylabel('Number of Data')\nplt.xticks(rotation=0)\nplt.legend(title='Base Fare Amount', bbox_to_anchor=(1.05, 1), loc='upper left')\nplt.tight_layout()\nplt.show()\n\nUserWarning: Tight layout not applied. The bottom and top margins cannot be made large enough to accommodate all axes decorations.\n  plt.tight_layout()\n\n\n\n\n\n\n\n\n\n\n#BaseFareAmt by mean\ncluster_BaseFareAmt_counts = final_dataframe.groupby('Cluster')['BaseFareAmt'].mean()\n\nplt.figure(figsize=(10,6))\n\nfor cluster in range(len(cluster_BaseFareAmt_counts)):\n  plt.bar(cluster,cluster_BaseFareAmt_counts[cluster],color = cluster_color[cluster])\n\nplt.title('Amount of BareFare')\nplt.xlabel('Cluster')\nplt.ylabel('Amount')\nplt.grid(axis='y')\nplt.show()\n\n\n\n\n\n\n\n\n\ncluster_BookedProduct = final_dataframe.groupby('Cluster')['BookedProduct'].value_counts()\n\npivot_data = cluster_BookedProduct.unstack().fillna(0)\n\npivot_data.plot(kind='bar', stacked=True, figsize=(10, 7))\nplt.title('Number of BookedProduct by Cluster')\nplt.xlabel('Cluster')\nplt.ylabel('Number of Data')\nplt.xticks(rotation=0)\nplt.legend(title='Group Size', bbox_to_anchor=(1.05, 1), loc='upper left')\nplt.tight_layout()\nplt.show()\n\nUserWarning: Tight layout not applied. The bottom and top margins cannot be made large enough to accommodate all axes decorations.\n  plt.tight_layout()\n\n\n\n\n\n\n\n\n\n\n# Main Booked Product in Each Segment\nmainproduct = final_dataframe.groupby(['Cluster', 'BookedProduct']).size().unstack(fill_value=0)\nmainproduct = mainproduct.idxmax(axis=1)\n\nprint(mainproduct)\n\nCluster\n0    SSWMIR\n1       EXP\n2    SSWMIR\n3       EXP\n4    SSWMIR\ndtype: object\n\n\n\nfiltered_status = final_dataframe[final_dataframe['UflyMemberStatus'].isin(['Elite', 'Standard'])]\n\nufly_status_by_cluster = filtered_status.groupby(['Cluster', 'UflyMemberStatus']).size().unstack(fill_value=0)\n\nplt.figure(figsize=(10, 6))\n\nufly_status_by_cluster.plot(kind='bar', stacked=True, ax=plt.gca(), color=['lightblue', 'orange'])\n\nplt.title('Ufly Member Status Distribution by Cluster (Elite and Standard)')\nplt.xlabel('Cluster')\nplt.ylabel('Number of Customers')\nplt.xticks(rotation=0)\nplt.legend(title='Ufly Member Status', bbox_to_anchor=(1.05, 1), loc='upper left')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\ndestination_by_cluster = final_dataframe.groupby(['Cluster', 'final_destination']).size().unstack(fill_value=0)\n\nplt.figure(figsize=(10, 6))\n\ndestination_by_cluster.plot(kind='bar', stacked=True, ax=plt.gca())\n\nplt.title('Final Destination Distribution by Cluster')\nplt.xlabel('Cluster')\nplt.ylabel('Number of Customers')\nplt.xticks(rotation=0)\nplt.legend(title='Final Destination', bbox_to_anchor=(1.05, 1), loc='upper left')\nplt.show()\n\n\n\n\n\n\n\n\n\n# Main Final Destination in Each Segment\nmaindestination = final_dataframe.groupby(['Cluster', 'final_destination']).size().unstack(fill_value=0)\nmaindestination = maindestination.idxmax(axis=1)\n\nprint(maindestination)\n\nCluster\n0    MSP\n1    MSP\n2    MSP\n3    MSP\n4    MSP\ndtype: object\n\n\n\n# Segment's Information by Age Group Distribution\nimport matplotlib.pyplot as plt\n\nage_group_distribution = final_dataframe.groupby(['Cluster', 'age_group']).size().unstack(fill_value=0)\n\nplt.figure(figsize=(6, 4))\n\nage_group_distribution.plot(kind='bar', stacked=True, ax=plt.gca())\n\nplt.title('Age Group Distribution by Cluster')\nplt.xlabel('Cluster')\nplt.ylabel('Number of Customers')\nplt.xticks(rotation=0)\nplt.legend(title='Age Group', bbox_to_anchor=(1.05, 1), loc='upper left')\nplt.grid(axis='y', linestyle='--')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n# Largest Age Group in Each Segment\ndefining_age_group = final_dataframe.groupby(['Cluster', 'age_group']).size().unstack(fill_value=0)\ndefining_age_group = defining_age_group.idxmax(axis=1)\n\nprint(defining_age_group)\n\nCluster\n0      55+\n1    25-34\n2    35-54\n3    35-54\n4      55+\ndtype: object\n\n\n\n# Visualization of What class of service (coach, first class, etc) the passenger booked\nimport matplotlib.pyplot as plt\n\nage_group_distribution = final_dataframe.groupby(['Cluster', 'BkdClassOfService']).size().unstack(fill_value=0)\n\nplt.figure(figsize=(6, 4))\n\nage_group_distribution.plot(kind='bar', stacked=True, ax=plt.gca())\n\nplt.title('Ticket Group Distribution by Cluster')\nplt.xlabel('Cluster')\nplt.ylabel('Number of Customers')\nplt.xticks(rotation=0)\nplt.legend(title='Fare Group', bbox_to_anchor=(1.05, 1), loc='upper left')\nplt.grid(axis='y', linestyle='--')\n\nplt.tight_layout()\nplt.show()\n\n# Mostly all the segments are just Coach!\n\n\n\n\n\n\n\n\n\n# Visualization of seasonality within each segment\nimport matplotlib.pyplot as plt\n\nage_group_distribution = final_dataframe.groupby(['Cluster', 'seasonality']).size().unstack(fill_value=0)\n\nplt.figure(figsize=(6, 4))\n\nage_group_distribution.plot(kind='bar', stacked=True, ax=plt.gca())\n\nplt.title('Ticket Group Distribution by Cluster')\nplt.xlabel('Cluster')\nplt.ylabel('Number of Customers')\nplt.xticks(rotation=0)\nplt.legend(title='Quarter Group', bbox_to_anchor=(1.05, 1), loc='upper left')\nplt.grid(axis='y', linestyle='--')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n# Most Popular Quarter in Each Segment\npopularquarter = final_dataframe.groupby(['Cluster', 'seasonality']).size().unstack(fill_value=0)\npopularquarter = popularquarter.idxmax(axis=1)\n\n\nprint(popularquarter)\n\nCluster\n0    Q4\n1    Q3\n2    Q1\n3    Q1\n4    Q3\ndtype: object\n\n\n\n# Segment 3 Information\n\ncluster_origin_counts = final_dataframe.groupby('Cluster')['true_origins'].value_counts().unstack().fillna(0)\n\n# Pie charts for strating airport\n\norigin_counts = cluster_origin_counts.loc[3]\nplt.figure()\nplt.pie(origin_counts, labels=origin_counts.index, autopct='%1.1f%%', startangle=140)\nplt.axis('equal')\nplt.title(f'Origin Destination for Cluster 3')\nplt.show()\n\n\n\n\n\n\n\n\n\n# Visualization of seasonality within Cluster 3\nimport matplotlib.pyplot as plt\n\nclusterspecific = final_dataframe[final_dataframe['Cluster'] == 3]\n\nage_group_distribution = clusterspecific.groupby(['Cluster', 'seasonality']).size().unstack(fill_value=0)\n\nplt.figure(figsize=(6, 4))\n\nage_group_distribution.plot(kind='bar', stacked=True, ax=plt.gca())\n\nplt.title('Ticket Group Distribution by Cluster')\nplt.xlabel('Cluster')\nplt.ylabel('Number of Customers')\nplt.xticks(rotation=0)\nplt.legend(title='Quarter Group', bbox_to_anchor=(1.05, 1), loc='upper left')\nplt.grid(axis='y', linestyle='--')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n# Segment 3's Information by Age Group Distribution\nimport matplotlib.pyplot as plt\n\nclusterspecificage = final_dataframe[final_dataframe['Cluster'] == 3]\n\n\nage_group_distribution = clusterspecificage.groupby(['Cluster', 'age_group']).size().unstack(fill_value=0)\n\nplt.figure(figsize=(6, 4))\n\nage_group_distribution.plot(kind='bar', stacked=True, ax=plt.gca())\n\nplt.title('Age Group Distribution for Cluster 3')\nplt.xlabel('Cluster')\nplt.ylabel('Number of Customers')\nplt.xticks(rotation=0)\nplt.legend(title='Age Group', bbox_to_anchor=(1.05, 1), loc='upper left')\nplt.grid(axis='y', linestyle='--')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n# Cluster 3 Membership Status\n\nnew_var = final_dataframe[final_dataframe['Cluster'] == 3]\n\nclusterspecificstatus = new_var\n\nfiltered_status = clusterspecificstatus[final_dataframe['UflyMemberStatus'].isin(['Elite', 'Standard'])]\n\nufly_status_by_cluster = filtered_status.groupby(['Cluster', 'UflyMemberStatus']).size().unstack(fill_value=0)\n\nplt.figure(figsize=(10, 6))\n\nufly_status_by_cluster.plot(kind='bar', stacked=True, ax=plt.gca(), color=['lightblue', 'orange'])\n\nplt.title('Ufly Member Status Distribution for Cluster 3 (Elite and Standard)')\nplt.xlabel('Cluster')\nplt.ylabel('Number of Customers')\nplt.xticks(rotation=0)\nplt.legend(title='Ufly Member Status', bbox_to_anchor=(1.05, 1), loc='upper left')\n\nplt.tight_layout()\nplt.show()\n\nUserWarning: Boolean Series key will be reindexed to match DataFrame index.\n  filtered_status = clusterspecificstatus[final_dataframe['UflyMemberStatus'].isin(['Elite', 'Standard'])]"
  },
  {
    "objectID": "projects/Customer-Segmentation/suncounty-customer-segmentation.html",
    "href": "projects/Customer-Segmentation/suncounty-customer-segmentation.html",
    "title": "âœˆï¸ Customer Segmentation for Sun Country Airlines",
    "section": "",
    "text": "Sun County Airlines, a small U.S.-based carrier, faces pressure from larger competitors. To compete effectively, the company needs a deep understanding of its customersâ€™ behavior, demographics, and travel preferences. This project uses unsupervised machine learning to segment customers into distinct groups for targeted marketing and product development."
  },
  {
    "objectID": "projects/Customer-Segmentation/suncounty-customer-segmentation.html#project-overview",
    "href": "projects/Customer-Segmentation/suncounty-customer-segmentation.html#project-overview",
    "title": "âœˆï¸ Customer Segmentation for Sun Country Airlines",
    "section": "",
    "text": "Sun County Airlines, a small U.S.-based carrier, faces pressure from larger competitors. To compete effectively, the company needs a deep understanding of its customersâ€™ behavior, demographics, and travel preferences. This project uses unsupervised machine learning to segment customers into distinct groups for targeted marketing and product development."
  },
  {
    "objectID": "projects/Customer-Segmentation/suncounty-customer-segmentation.html#objectives",
    "href": "projects/Customer-Segmentation/suncounty-customer-segmentation.html#objectives",
    "title": "âœˆï¸ Customer Segmentation for Sun Country Airlines",
    "section": "ğŸ¯ Objectives",
    "text": "ğŸ¯ Objectives\n\nCombine and clean customer datasets from Excel\nIdentify key features relevant to customer behavior\nApply KMeans Clustering to uncover unique customer groups\nProvide insights for strategic marketing decisions"
  },
  {
    "objectID": "projects/Customer-Segmentation/suncounty-customer-segmentation.html#data-features",
    "href": "projects/Customer-Segmentation/suncounty-customer-segmentation.html#data-features",
    "title": "âœˆï¸ Customer Segmentation for Sun Country Airlines",
    "section": "ğŸ—‚ï¸ Data & Features",
    "text": "ğŸ—‚ï¸ Data & Features\nWe used two spreadsheets from Sun County Airlines containing customer booking and demographic data. After merging the data using Pandas in Google Colab, we selected the following variables:\n\nBirthdate (Age)\nBooking Class & Channel\nBase Fare Paid\nMembership Status\nProduct Type\nRoute Details\nGroup Size\nBooking Lead Time (days_pre_booked)\nSeasonality Habits"
  },
  {
    "objectID": "projects/Customer-Segmentation/suncounty-customer-segmentation.html#methodology",
    "href": "projects/Customer-Segmentation/suncounty-customer-segmentation.html#methodology",
    "title": "âœˆï¸ Customer Segmentation for Sun Country Airlines",
    "section": "ğŸ” Methodology",
    "text": "ğŸ” Methodology\nWe used K-means clustering after standardizing numerical features and encoding categorical ones. The Elbow method suggested that k = 5 was optimal.\n\n\n\n\nğŸ§® Tools Used\n\nPython (Pandas, Scikit-learn)\nGoogle Colab\nMatplotlib & Seaborn\nExcel (raw input files)"
  },
  {
    "objectID": "projects/Customer-Segmentation/suncounty-customer-segmentation.html#key-segments-marketing-strategies",
    "href": "projects/Customer-Segmentation/suncounty-customer-segmentation.html#key-segments-marketing-strategies",
    "title": "âœˆï¸ Customer Segmentation for Sun Country Airlines",
    "section": "ğŸ“Š Key Segments & Marketing Strategies",
    "text": "ğŸ“Š Key Segments & Marketing Strategies\n\nCluster 0 â€“ Middle-Aged Standard Travelers\nMost frequently fly solo or in pairs, book standard class, and fly year-round.\n\n\n\n\nğŸ’¸ Marketing Strategies:\nâ€¢ Boost Visibility on Travel Platforms: Partner with OTAs and meta-search engines (e.g., Expedia, Skyscanner) to secure premium listings and improve flight discoverability.\nâ€¢ Manage Reviews Proactively: Encourage satisfied customers to leave reviews and respond to feedback to build trust and reputation.\nâ€¢ Offer Destination Bundles: Create travel packages for popular routes (e.g., BOS, DFW, LAX) by bundling flights with hotels or car rentals to attract deal-seeking travelers.\n\n\n\nCluster 1 â€“ Spring Squad Adventurers\nGroup travelers, often younger, travel mainly during spring with discounted fares.\n\n\n\n\nğŸ’¸ Marketing Strategies:\nâ€¢ Promote Spring Travel Deals: Offer group discounts, family packages, and senior travel incentives to appeal to larger group travelers.\nâ€¢ Bundle Group Packages: Partner with tour providers for all-inclusive deals that combine flights, hotels, and activities, optimized for multi-passenger bookings.\nâ€¢ Highlight Senior-Friendly Services: Emphasize amenities like priority boarding, wheelchair assistance, and personalized service.\nâ€¢ Drive Ufly Program Adoption: Incentivize loyalty signups with group booking bonuses, Q1 travel discounts, and senior-exclusive perks.\n\n\n\nCluster 2 â€“ Adventurous Young Budget Travelers\nYoungest cluster, budget-conscious, often use mobile booking channels.\n\n\n\n\nğŸ’¸ Marketing Strategies:\nâ€¢ Emphasize Comfort & Loyalty Benefits: Promote premium features like extra legroom, priority boarding, and UFly bonus points to appeal to their comfort-seeking preferences.\nâ€¢ Encourage Early Bookings: Launch Q4 campaigns like â€œFly Home for the Holidaysâ€ with early-bird discounts and flexible booking options to match their organized travel habits.\n\n\n\nCluster 3 â€“ Early Minneapolis Travelers\nFrequent early months flights, loyal customers from Minneapolis hub.\n\n\n\n\nğŸ’¸ Marketing Strategies:\nâ€¢ Time Campaigns Around Booking Habits: Launch promotions in early October and late December to align with their 61-day pre-booking window and holiday shopping season.\nâ€¢ Seasonal Messaging: Use timely slogans like â€œFly into the new year with this great offer!â€ to boost early-year travel bookings.\nâ€¢ Reward MSP Loyalty: Offer exclusive perks such as lounge access, Wi-Fi, or local discounts to retain Minneapolis-based flyers.\n\n\n\nCluster 4 â€“ Age-Blend Bargain Birds\nWide age range, price-driven, high sensitivity to sales and promotions.\n\n\n\n\nğŸ’¸ Marketing Strategies:\nâ€¢ Highlight Affordability: Emphasize budget-friendly travel, value-for-money bundles, and exclusive online deals to attract this cost-conscious, age-diverse group.\nâ€¢ Inclusive Messaging: Use language that resonates with all age groups, focusing on the benefits of early planning and direct booking.\nâ€¢ Offer Age-Based & Bundle Discounts: Promote senior savings, youth specials, and flight + accommodation/car rental bundles to increase appeal and direct engagement on the SCA website."
  },
  {
    "objectID": "projects/Customer-Segmentation/suncounty-customer-segmentation.html#conclusion",
    "href": "projects/Customer-Segmentation/suncounty-customer-segmentation.html#conclusion",
    "title": "âœˆï¸ Customer Segmentation for Sun Country Airlines",
    "section": "ğŸ§¾ Conclusion",
    "text": "ğŸ§¾ Conclusion\nThrough the application of K-means clustering, we successfully identified five distinct customer segments for Sun Country Airlines. These clusters revealed meaningful patterns in booking behavior, travel timing, group sizes, and fare preferences. By segmenting customers in this way, the airline can personalize its marketing efforts, develop more tailored promotions, and optimize resource allocation for customer engagement.\nThis segmentation lays the groundwork for targeted marketing strategies, such as offering mobile booking incentives for younger travelers or loyalty perks for high-value solo fliers.\nThe process also demonstrated the power of combining raw Excel data with Python-based clustering and visualization tools to drive business insight. With scalable implementation, this approach could become part of a broader customer intelligence system at Sun Country."
  },
  {
    "objectID": "projects/Customer-Segmentation/suncounty-customer-segmentation.html#future-enhancements",
    "href": "projects/Customer-Segmentation/suncounty-customer-segmentation.html#future-enhancements",
    "title": "âœˆï¸ Customer Segmentation for Sun Country Airlines",
    "section": "ğŸ”„ Future Enhancements",
    "text": "ğŸ”„ Future Enhancements\n\nIncorporate additional behavioral data such as frequency of bookings and flight satisfaction\nExplore supervised models for predicting customer loyalty or churn\nBuild a dashboard (Tableau or Streamlit) for real-time cluster monitoring"
  },
  {
    "objectID": "projects/Customer-Segmentation/suncounty-customer-segmentation.html#github-repository",
    "href": "projects/Customer-Segmentation/suncounty-customer-segmentation.html#github-repository",
    "title": "âœˆï¸ Customer Segmentation for Sun Country Airlines",
    "section": "ğŸ“ GitHub Repository",
    "text": "ğŸ“ GitHub Repository\nğŸ‘‰ View Code on GitHub"
  },
  {
    "objectID": "projects/Customer-Segmentation/Clustering Project.html",
    "href": "projects/Customer-Segmentation/Clustering Project.html",
    "title": "My Portfolio",
    "section": "",
    "text": "# Mount Google Drive in Colab\nfrom google.colab import drive\ndrive.mount('/content/drive')\n\nMounted at /content/drive\n\n\n\nimport pandas as pd\n\n#read the Clustering Data csv file\ndata = pd.read_csv('/content/drive/MyDrive/Clustering Data.csv')\n\n\nfrom google.colab.data_table import DataTable\nDataTable.max_columns = 100\n\n\ndata.head()\n\n\n  \n    \n\n\n\n\n\n\nuid\nPNRLocatorID\navg_amt\nround_trip\ngroup_size\ngroup\ndays_pre_booked\nBookingChannel_Other\nBookingChannel_Outside_Booking\nBookingChannel_Reservations_Booking\n...\ntrue_destination_dest_SXM\ntrue_destination_dest_TPA\ntrue_destination_dest_ZIH\nUflyMemberStatus_Elite\nUflyMemberStatus_non-ufly\nUflyMemberStatus_Standard\nseasonality_Q1\nseasonality_Q2\nseasonality_Q3\nseasonality_Q4\n\n\n\n\n0\n504554455244696420493F7C2067657420746869732072...\nAADMLF\n0.019524\n0\n0.000\n0\n0.029703\n0\n1\n0\n...\n0\n0\n0\n0\n0\n1\n0\n0\n0\n1\n\n\n1\n46495853454E44696420493F7C20676574207468697320...\nAAFBOM\n0.081774\n1\n0.000\n0\n0.039604\n0\n0\n0\n...\n0\n0\n0\n0\n0\n1\n0\n0\n1\n0\n\n\n2\n534355545444696420493F7C2067657420746869732072...\nAAFILI\n0.026650\n0\n0.125\n1\n0.069307\n0\n0\n0\n...\n0\n0\n0\n0\n1\n0\n1\n0\n0\n0\n\n\n3\n534355545444696420493F7C2067657420746869732072...\nAAFILI\n0.026650\n0\n0.125\n1\n0.069307\n0\n0\n0\n...\n0\n0\n0\n0\n1\n0\n1\n0\n0\n0\n\n\n4\n44554D4D414E4E44696420493F7C206765742074686973...\nAAFRQI\n0.000000\n1\n0.000\n0\n0.035361\n0\n1\n0\n...\n0\n0\n0\n0\n1\n0\n0\n0\n0\n1\n\n\n\n\n5 rows Ã— 90 columns\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n\n    \n  \n\n\n\nclustering_data = data.copy()\nclustering_data = clustering_data.drop(['uid','PNRLocatorID'],axis =1)\n\n\n#find the optimum number of cluster\nfrom sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\n\ninertia = []\ncluster_range = range(1,21)\n\nfor cluster_num in cluster_range:\n  kmeans = KMeans(n_clusters=cluster_num,n_init = 10, random_state = 24)\n  kmeans.fit(clustering_data)\n  inertia.append(kmeans.inertia_)\n\nplt.figure(figsize=(10,6))\nplt.plot(cluster_range,inertia,marker='o', linestyle ='--')\nplt.xlabel('Number of Clusters')\nplt.ylabel('Inertia')\nplt.grid(True)\n\n\n\n\n\n\n\n\n\n#Applying KMeans\nkmeans = KMeans(n_clusters = 5,n_init=30)\nkmeans.fit(clustering_data)\n\ndata['Cluster'] = kmeans.labels_\ndata.head(10000)\n\n\n  \n    \n\n\n\n\n\n\nuid\nPNRLocatorID\navg_amt\nround_trip\ngroup_size\ngroup\ndays_pre_booked\nBookingChannel_Other\nBookingChannel_Outside_Booking\nBookingChannel_Reservations_Booking\n...\ntrue_destination_dest_TPA\ntrue_destination_dest_ZIH\nUflyMemberStatus_Elite\nUflyMemberStatus_non-ufly\nUflyMemberStatus_Standard\nseasonality_Q1\nseasonality_Q2\nseasonality_Q3\nseasonality_Q4\nCluster\n\n\n\n\n0\n504554455244696420493F7C2067657420746869732072...\nAADMLF\n0.019524\n0\n0.000\n0\n0.029703\n0\n1\n0\n...\n0\n0\n0\n0\n1\n0\n0\n0\n1\n3\n\n\n1\n46495853454E44696420493F7C20676574207468697320...\nAAFBOM\n0.081774\n1\n0.000\n0\n0.039604\n0\n0\n0\n...\n0\n0\n0\n0\n1\n0\n0\n1\n0\n3\n\n\n2\n534355545444696420493F7C2067657420746869732072...\nAAFILI\n0.026650\n0\n0.125\n1\n0.069307\n0\n0\n0\n...\n0\n0\n0\n1\n0\n1\n0\n0\n0\n1\n\n\n3\n534355545444696420493F7C2067657420746869732072...\nAAFILI\n0.026650\n0\n0.125\n1\n0.069307\n0\n0\n0\n...\n0\n0\n0\n1\n0\n1\n0\n0\n0\n1\n\n\n4\n44554D4D414E4E44696420493F7C206765742074686973...\nAAFRQI\n0.000000\n1\n0.000\n0\n0.035361\n0\n1\n0\n...\n0\n0\n0\n1\n0\n0\n0\n0\n1\n0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n9995\n465241484D44696420493F7C2067657420746869732072...\nOVDEVE\n0.042032\n0\n0.125\n1\n0.036775\n0\n0\n0\n...\n0\n0\n0\n0\n1\n0\n0\n1\n0\n3\n\n\n9996\n5649434B45525944696420493F7C206765742074686973...\nOVDVCT\n0.049705\n0\n0.000\n0\n0.028289\n0\n1\n0\n...\n0\n0\n0\n1\n0\n0\n0\n1\n0\n0\n\n\n9997\n535445504B4144696420493F7C20676574207468697320...\nOVGARJ\n0.012305\n1\n0.000\n0\n0.019802\n0\n1\n0\n...\n0\n0\n0\n1\n0\n0\n0\n1\n0\n4\n\n\n9998\n4B4F53544B4F44696420493F7C20676574207468697320...\nOVGBHE\n0.067609\n1\n0.125\n1\n0.125884\n0\n1\n0\n...\n0\n0\n0\n1\n0\n0\n0\n1\n0\n4\n\n\n9999\n59414244696420493F7C20676574207468697320726967...\nOVGBHE\n0.067609\n1\n0.125\n1\n0.125884\n0\n1\n0\n...\n0\n0\n0\n1\n0\n0\n0\n1\n0\n4\n\n\n\n\n10000 rows Ã— 91 columns\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n\n    \n  \n\n\n\n#sort and count for each number of cluster\ncluster_size = data['Cluster'].value_counts().sort_index()\ncluster_size\n\n\n\n\n\n\n\n\ncount\n\n\nCluster\n\n\n\n\n\n0\n2441\n\n\n1\n2351\n\n\n2\n4127\n\n\n3\n2387\n\n\n4\n3838\n\n\n\n\ndtype: int64\n\n\n\nreservation_data = pd.read_csv('/content/drive/MyDrive/sample_data_transformed.csv')\n\nDtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.\n  reservation_data = pd.read_csv('/content/drive/MyDrive/sample_data_transformed.csv')\n\n\n\n#Merge sample_data_transformed and cluster data\nfinal_dataframe = reservation_data.merge(data[['uid', 'Cluster']], on='uid', how='left')\n\n\nfinal_dataframe.head()\n\n\n  \n    \n\n\n\n\n\n\nUnnamed: 0\nPNRLocatorID\nPaxName\nTicketNum\nCouponSeqNbr\nServiceStartCity\nServiceEndCity\nPNRCreateDate\nServiceStartDate\nEncryptedName\n...\nage_group\ntrue_origins\nfinal_destination\nround_trip\ngroup_size\ngroup\nseasonality\ndays_pre_booked\ntrue_destination\nCluster\n\n\n\n\n0\n1\nAADMLF\nPETEJO\n3.377490e+12\n1\nMSP\nDFW\n9/15/14\n10/6/14\n504554455244696420493F7C2067657420746869732072...\n...\n55+\nMSP\nDFW\n0\n1\n0\nQ4\n21\nDFW\n3\n\n\n1\n2\nAAFBOM\nFIXSMO\n3.372110e+12\n2\nJFK\nMSP\n7/22/14\n8/19/14\n46495853454E44696420493F7C20676574207468697320...\n...\n35-54\nMSP\nMSP\n1\n1\n0\nQ3\n28\nJFK\n3\n\n\n2\n3\nAAFBOM\nFIXSMO\n3.372110e+12\n1\nMSP\nJFK\n7/22/14\n8/14/14\n46495853454E44696420493F7C20676574207468697320...\n...\n35-54\nMSP\nMSP\n1\n1\n0\nQ3\n23\nJFK\n3\n\n\n3\n4\nAAFILI\nSCUTKA\n3.372110e+12\n2\nMSP\nSEA\n2/6/14\n3/27/14\n534355545444696420493F7C2067657420746869732072...\n...\n25-34\nLAN\nSEA\n0\n2\n1\nQ1\n49\nMSP\n1\n\n\n4\n5\nAAFILI\nSCUTKA\n3.372110e+12\n1\nLAN\nMSP\n2/6/14\n3/27/14\n534355545444696420493F7C2067657420746869732072...\n...\n25-34\nLAN\nSEA\n0\n2\n1\nQ1\n49\nMSP\n1\n\n\n\n\n5 rows Ã— 38 columns\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n\n    \n  \n\n\n\n#Template Code for Visualization\ncluster_color = {\n    0: 'red',\n    1: 'blue',\n    2: 'yellow',\n    3: 'green',\n    4: 'purple'\n}\ncluster_season = final_dataframe.groupby('Cluster')['group'].sum()\n\nplt.figure(figsize=(10,6))\nfor cluster in range(len(cluster_season)):\n  plt.bar(cluster,cluster_season[cluster],color = cluster_color[cluster])\n\nplt.title('Number of people traveling in a group')\nplt.xlabel('Cluster')\nplt.ylabel('Number of Travel made in the Season')\nplt.xticks(ticks = range(len(cluster_season)))\nplt.grid(axis='y')\nplt.show()\n\n\n\n\n\n\n\n\n\ncluster_seasonality_counts = final_dataframe.groupby('Cluster')['seasonality'].value_counts().unstack().fillna(0)\n\n# Pie charts for seasonality\nfor cluster in cluster_seasonality_counts.index:\n    season_counts = cluster_seasonality_counts.loc[cluster]\n    plt.figure()\n    plt.pie(season_counts, labels=season_counts.index, autopct='%1.1f%%', startangle=140)\n    plt.axis('equal')\n    plt.title(f'Seasonality Distribution for Cluster {cluster}')\n    plt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Count the number of people traveling in a group by cluster\n\n#group_travelers = final_dataframe[final_dataframe['group_size'] &gt; 1]\n#cluster_group_size = group_travelers.groupby('Cluster')['group_size'].count().reset_index()\n\n#plt.figure(figsize=(10,6))\n\n#for cluster in range(len(cluster_group_size)):\n#  plt.bar(cluster,cluster_season[cluster],color = cluster_color[cluster])\n\n#plt.title('Number of People Traveling in a Group by Cluster')\n#plt.xlabel('Cluster')\n#plt.ylabel('Number of People Traveling in a Group')\n#plt.grid(axis='y')\n#plt.show()\n\ncluster_group_size = final_dataframe.groupby('Cluster')['group_size'].value_counts()\n\npivot_data = cluster_group_size.unstack().fillna(0)\n\npivot_data.plot(kind='bar', stacked=True, figsize=(10, 7))\nplt.title('Number of Group Size by Cluster')\nplt.xlabel('Cluster')\nplt.ylabel('Number of Data')\nplt.xticks(rotation=0)\nplt.legend(title='Group Size', bbox_to_anchor=(1.05, 1), loc='upper left')\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nmost_group_size = final_dataframe.groupby('Cluster')['group_size'].mean()\n\nprint(most_group_size)\n\nCluster\n0    1.906293\n1    1.549622\n2    2.393798\n3    2.229292\n4    1.826769\nName: group_size, dtype: float64\n\n\n\n#Days_pre_book by mean\ncluster_days_pre_book = final_dataframe.groupby('Cluster')['days_pre_booked'].mean()\n\nplt.figure(figsize=(10,6))\n\nfor cluster in cluster_days_pre_book.index:\n  plt.bar(cluster,cluster_days_pre_book[cluster],color = cluster_color[cluster])\n\nplt.title('Number of days pre book ')\nplt.xlabel('Cluster')\nplt.ylabel('Number of days')\nplt.grid(axis='y')\nplt.show()\n\n\n\n\n\n\n\n\n\n# Group the dataframe by 'Cluster' and calculate the mean of 'days_pre_booked' for each cluster\nmean_days_pre_book = final_dataframe.groupby('Cluster')['days_pre_booked'].mean()\n\n# Print the mean number of days pre-booked for each cluster\nprint(mean_days_pre_book)\n\nCluster\n0    67.770326\n1    36.250914\n2    60.062692\n3    61.768605\n4    51.006279\nName: days_pre_booked, dtype: float64\n\n\n\ncluster_BaseFareAmt = final_dataframe.groupby('Cluster')['BaseFareAmt'].value_counts()\n\npivot_data = cluster_BaseFareAmt.unstack().fillna(0)\n\npivot_data.plot(kind='bar', stacked=True, figsize=(10, 7))\nplt.title('Amount of Base Fare by Cluster')\nplt.xlabel('Cluster')\nplt.ylabel('Number of Data')\nplt.xticks(rotation=0)\nplt.legend(title='Base Fare Amount', bbox_to_anchor=(1.05, 1), loc='upper left')\nplt.tight_layout()\nplt.show()\n\nUserWarning: Tight layout not applied. The bottom and top margins cannot be made large enough to accommodate all axes decorations.\n  plt.tight_layout()\n\n\n\n\n\n\n\n\n\n\n#BaseFareAmt by mean\ncluster_BaseFareAmt_counts = final_dataframe.groupby('Cluster')['BaseFareAmt'].mean()\n\nplt.figure(figsize=(10,6))\n\nfor cluster in range(len(cluster_BaseFareAmt_counts)):\n  plt.bar(cluster,cluster_BaseFareAmt_counts[cluster],color = cluster_color[cluster])\n\nplt.title('Amount of BareFare')\nplt.xlabel('Cluster')\nplt.ylabel('Amount')\nplt.grid(axis='y')\nplt.show()\n\n\n\n\n\n\n\n\n\ncluster_BookedProduct = final_dataframe.groupby('Cluster')['BookedProduct'].value_counts()\n\npivot_data = cluster_BookedProduct.unstack().fillna(0)\n\npivot_data.plot(kind='bar', stacked=True, figsize=(10, 7))\nplt.title('Number of BookedProduct by Cluster')\nplt.xlabel('Cluster')\nplt.ylabel('Number of Data')\nplt.xticks(rotation=0)\nplt.legend(title='Group Size', bbox_to_anchor=(1.05, 1), loc='upper left')\nplt.tight_layout()\nplt.show()\n\nUserWarning: Tight layout not applied. The bottom and top margins cannot be made large enough to accommodate all axes decorations.\n  plt.tight_layout()\n\n\n\n\n\n\n\n\n\n\n# Main Booked Product in Each Segment\nmainproduct = final_dataframe.groupby(['Cluster', 'BookedProduct']).size().unstack(fill_value=0)\nmainproduct = mainproduct.idxmax(axis=1)\n\nprint(mainproduct)\n\nCluster\n0    SSWMIR\n1       EXP\n2    SSWMIR\n3       EXP\n4    SSWMIR\ndtype: object\n\n\n\nfiltered_status = final_dataframe[final_dataframe['UflyMemberStatus'].isin(['Elite', 'Standard'])]\n\nufly_status_by_cluster = filtered_status.groupby(['Cluster', 'UflyMemberStatus']).size().unstack(fill_value=0)\n\nplt.figure(figsize=(10, 6))\n\nufly_status_by_cluster.plot(kind='bar', stacked=True, ax=plt.gca(), color=['lightblue', 'orange'])\n\nplt.title('Ufly Member Status Distribution by Cluster (Elite and Standard)')\nplt.xlabel('Cluster')\nplt.ylabel('Number of Customers')\nplt.xticks(rotation=0)\nplt.legend(title='Ufly Member Status', bbox_to_anchor=(1.05, 1), loc='upper left')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\ndestination_by_cluster = final_dataframe.groupby(['Cluster', 'final_destination']).size().unstack(fill_value=0)\n\nplt.figure(figsize=(10, 6))\n\ndestination_by_cluster.plot(kind='bar', stacked=True, ax=plt.gca())\n\nplt.title('Final Destination Distribution by Cluster')\nplt.xlabel('Cluster')\nplt.ylabel('Number of Customers')\nplt.xticks(rotation=0)\nplt.legend(title='Final Destination', bbox_to_anchor=(1.05, 1), loc='upper left')\nplt.show()\n\n\n\n\n\n\n\n\n\n# Main Final Destination in Each Segment\nmaindestination = final_dataframe.groupby(['Cluster', 'final_destination']).size().unstack(fill_value=0)\nmaindestination = maindestination.idxmax(axis=1)\n\nprint(maindestination)\n\nCluster\n0    MSP\n1    MSP\n2    MSP\n3    MSP\n4    MSP\ndtype: object\n\n\n\n# Segment's Information by Age Group Distribution\nimport matplotlib.pyplot as plt\n\nage_group_distribution = final_dataframe.groupby(['Cluster', 'age_group']).size().unstack(fill_value=0)\n\nplt.figure(figsize=(6, 4))\n\nage_group_distribution.plot(kind='bar', stacked=True, ax=plt.gca())\n\nplt.title('Age Group Distribution by Cluster')\nplt.xlabel('Cluster')\nplt.ylabel('Number of Customers')\nplt.xticks(rotation=0)\nplt.legend(title='Age Group', bbox_to_anchor=(1.05, 1), loc='upper left')\nplt.grid(axis='y', linestyle='--')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n# Largest Age Group in Each Segment\ndefining_age_group = final_dataframe.groupby(['Cluster', 'age_group']).size().unstack(fill_value=0)\ndefining_age_group = defining_age_group.idxmax(axis=1)\n\nprint(defining_age_group)\n\nCluster\n0      55+\n1    25-34\n2    35-54\n3    35-54\n4      55+\ndtype: object\n\n\n\n# Visualization of What class of service (coach, first class, etc) the passenger booked\nimport matplotlib.pyplot as plt\n\nage_group_distribution = final_dataframe.groupby(['Cluster', 'BkdClassOfService']).size().unstack(fill_value=0)\n\nplt.figure(figsize=(6, 4))\n\nage_group_distribution.plot(kind='bar', stacked=True, ax=plt.gca())\n\nplt.title('Ticket Group Distribution by Cluster')\nplt.xlabel('Cluster')\nplt.ylabel('Number of Customers')\nplt.xticks(rotation=0)\nplt.legend(title='Fare Group', bbox_to_anchor=(1.05, 1), loc='upper left')\nplt.grid(axis='y', linestyle='--')\n\nplt.tight_layout()\nplt.show()\n\n# Mostly all the segments are just Coach!\n\n\n\n\n\n\n\n\n\n# Visualization of seasonality within each segment\nimport matplotlib.pyplot as plt\n\nage_group_distribution = final_dataframe.groupby(['Cluster', 'seasonality']).size().unstack(fill_value=0)\n\nplt.figure(figsize=(6, 4))\n\nage_group_distribution.plot(kind='bar', stacked=True, ax=plt.gca())\n\nplt.title('Ticket Group Distribution by Cluster')\nplt.xlabel('Cluster')\nplt.ylabel('Number of Customers')\nplt.xticks(rotation=0)\nplt.legend(title='Quarter Group', bbox_to_anchor=(1.05, 1), loc='upper left')\nplt.grid(axis='y', linestyle='--')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n# Most Popular Quarter in Each Segment\npopularquarter = final_dataframe.groupby(['Cluster', 'seasonality']).size().unstack(fill_value=0)\npopularquarter = popularquarter.idxmax(axis=1)\n\n\nprint(popularquarter)\n\nCluster\n0    Q4\n1    Q3\n2    Q1\n3    Q1\n4    Q3\ndtype: object\n\n\n\n# Segment 3 Information\n\ncluster_origin_counts = final_dataframe.groupby('Cluster')['true_origins'].value_counts().unstack().fillna(0)\n\n# Pie charts for strating airport\n\norigin_counts = cluster_origin_counts.loc[3]\nplt.figure()\nplt.pie(origin_counts, labels=origin_counts.index, autopct='%1.1f%%', startangle=140)\nplt.axis('equal')\nplt.title(f'Origin Destination for Cluster 3')\nplt.show()\n\n\n\n\n\n\n\n\n\n# Visualization of seasonality within Cluster 3\nimport matplotlib.pyplot as plt\n\nclusterspecific = final_dataframe[final_dataframe['Cluster'] == 3]\n\nage_group_distribution = clusterspecific.groupby(['Cluster', 'seasonality']).size().unstack(fill_value=0)\n\nplt.figure(figsize=(6, 4))\n\nage_group_distribution.plot(kind='bar', stacked=True, ax=plt.gca())\n\nplt.title('Ticket Group Distribution by Cluster')\nplt.xlabel('Cluster')\nplt.ylabel('Number of Customers')\nplt.xticks(rotation=0)\nplt.legend(title='Quarter Group', bbox_to_anchor=(1.05, 1), loc='upper left')\nplt.grid(axis='y', linestyle='--')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n# Segment 3's Information by Age Group Distribution\nimport matplotlib.pyplot as plt\n\nclusterspecificage = final_dataframe[final_dataframe['Cluster'] == 3]\n\n\nage_group_distribution = clusterspecificage.groupby(['Cluster', 'age_group']).size().unstack(fill_value=0)\n\nplt.figure(figsize=(6, 4))\n\nage_group_distribution.plot(kind='bar', stacked=True, ax=plt.gca())\n\nplt.title('Age Group Distribution for Cluster 3')\nplt.xlabel('Cluster')\nplt.ylabel('Number of Customers')\nplt.xticks(rotation=0)\nplt.legend(title='Age Group', bbox_to_anchor=(1.05, 1), loc='upper left')\nplt.grid(axis='y', linestyle='--')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n# Cluster 3 Membership Status\n\nnew_var = final_dataframe[final_dataframe['Cluster'] == 3]\n\nclusterspecificstatus = new_var\n\nfiltered_status = clusterspecificstatus[final_dataframe['UflyMemberStatus'].isin(['Elite', 'Standard'])]\n\nufly_status_by_cluster = filtered_status.groupby(['Cluster', 'UflyMemberStatus']).size().unstack(fill_value=0)\n\nplt.figure(figsize=(10, 6))\n\nufly_status_by_cluster.plot(kind='bar', stacked=True, ax=plt.gca(), color=['lightblue', 'orange'])\n\nplt.title('Ufly Member Status Distribution for Cluster 3 (Elite and Standard)')\nplt.xlabel('Cluster')\nplt.ylabel('Number of Customers')\nplt.xticks(rotation=0)\nplt.legend(title='Ufly Member Status', bbox_to_anchor=(1.05, 1), loc='upper left')\n\nplt.tight_layout()\nplt.show()\n\nUserWarning: Boolean Series key will be reindexed to match DataFrame index.\n  filtered_status = clusterspecificstatus[final_dataframe['UflyMemberStatus'].isin(['Elite', 'Standard'])]"
  },
  {
    "objectID": "projects/Netflix-Recommendation/netflix-recommendation.html",
    "href": "projects/Netflix-Recommendation/netflix-recommendation.html",
    "title": "ğŸ¬ Netflix Recommendation System & Chatbot",
    "section": "",
    "text": "This project combines Natural Language Processing (NLP), content clustering, and chatbot integration to create a personalized movie and TV show recommendation system using a dataset of Netflix titles. The goal was to improve content discoverability by grouping shows based on themes and responding to user preferences through an interactive chatbot interface."
  },
  {
    "objectID": "projects/Netflix-Recommendation/netflix-recommendation.html#project-overview",
    "href": "projects/Netflix-Recommendation/netflix-recommendation.html#project-overview",
    "title": "ğŸ¬ Netflix Recommendation System & Chatbot",
    "section": "",
    "text": "This project combines Natural Language Processing (NLP), content clustering, and chatbot integration to create a personalized movie and TV show recommendation system using a dataset of Netflix titles. The goal was to improve content discoverability by grouping shows based on themes and responding to user preferences through an interactive chatbot interface."
  },
  {
    "objectID": "projects/Netflix-Recommendation/netflix-recommendation.html#objectives",
    "href": "projects/Netflix-Recommendation/netflix-recommendation.html#objectives",
    "title": "ğŸ¬ Netflix Recommendation System & Chatbot",
    "section": "ğŸ¯ Objectives",
    "text": "ğŸ¯ Objectives\n\nBuild a content-based recommendation system using NLP techniques.\nExtract core themes and patterns from Netflix descriptions using tokenization and TF-IDF.\nImplement unsupervised clustering to group similar content.\nDeploy a chatbot that responds to user inputs and delivers tailored suggestions.\nEvaluate genre prediction and chatbot relevance using both quantitative and qualitative feedback."
  },
  {
    "objectID": "projects/Netflix-Recommendation/netflix-recommendation.html#data-preprocessing-nlp-techniques",
    "href": "projects/Netflix-Recommendation/netflix-recommendation.html#data-preprocessing-nlp-techniques",
    "title": "ğŸ¬ Netflix Recommendation System & Chatbot",
    "section": "ğŸ§¹ Data Preprocessing & NLP Techniques",
    "text": "ğŸ§¹ Data Preprocessing & NLP Techniques\n\nMissing Values: Dataset was complete with no missing fields.\nAge Classification: Converted age ratings into numeric values for content filtering.\nTokenization & Lemmatization: Applied NLTK to clean and standardize text descriptions.\nTF-IDF Vectorization: Extracted key terms and themes from descriptions for clustering and recommendations."
  },
  {
    "objectID": "projects/Netflix-Recommendation/netflix-recommendation.html#clustering-insights",
    "href": "projects/Netflix-Recommendation/netflix-recommendation.html#clustering-insights",
    "title": "ğŸ¬ Netflix Recommendation System & Chatbot",
    "section": "ğŸ§  Clustering Insights",
    "text": "ğŸ§  Clustering Insights\nUsed K-means clustering to group titles into 6 thematic categories:\n\n\n\n\n\n\n\n\nCluster\nTheme\nExamples\n\n\n\n\n1\nBig City Life & Personal Discovery\nBlood & Water, Ganglands\n\n\n2\nLove & Life Journeys\nMidnight Mass, Je Suis Karl\n\n\n3\nComing-of-Age\nKota Factory, Dhanak\n\n\n4\nMusic & Art\nNailed It!, Rhyme & Reason\n\n\n5\nConnection & Discovery\nSankofa, Great British Baking Show\n\n\n6\nDocumentaries & Real-Life Stories\nDick Johnson Is Dead, Intrusion"
  },
  {
    "objectID": "projects/Netflix-Recommendation/netflix-recommendation.html#recommendation-system",
    "href": "projects/Netflix-Recommendation/netflix-recommendation.html#recommendation-system",
    "title": "ğŸ¬ Netflix Recommendation System & Chatbot",
    "section": "ğŸ¤– Recommendation System",
    "text": "ğŸ¤– Recommendation System\nThe system processes user inputs like genre, actor, type, sentiment, and keywords to generate TF-IDF-based vectors. It then calculates cosine similarity scores and ranks top 5 content matches.\nExample Input:\nGenre: Comedy | Actor: Tom | Sentiment: funny | Keyword: vacation\nTop Match: Jim Gaffigan: Cinco (similarity score: 0.253)"
  },
  {
    "objectID": "projects/Netflix-Recommendation/netflix-recommendation.html#chatbot-integration",
    "href": "projects/Netflix-Recommendation/netflix-recommendation.html#chatbot-integration",
    "title": "ğŸ¬ Netflix Recommendation System & Chatbot",
    "section": "ğŸ’¬ Chatbot Integration",
    "text": "ğŸ’¬ Chatbot Integration\nA chatbot interface was developed to make recommendations conversational and intuitive. It:\n\nAccepts free-text user inputs\nParses for preferences (e.g., actor, genre, tone)\nReturns top-matching Netflix titles with similarity scores\n\n\nExample: The chatbot asks for your favorite actor (Ama Qamata) and genre (Comedy), then returns matching stand-up specials and light-hearted shows."
  },
  {
    "objectID": "projects/Netflix-Recommendation/netflix-recommendation.html#conclusion",
    "href": "projects/Netflix-Recommendation/netflix-recommendation.html#conclusion",
    "title": "ğŸ¬ Netflix Recommendation System & Chatbot",
    "section": "ğŸ§¾ Conclusion",
    "text": "ğŸ§¾ Conclusion\nThis project demonstrates how NLP and conversational AI can enhance media recommendations. Through clustering, tokenization, and cosine similarity, we created a dynamic, personalized content discovery experience. The chatbot allows users to interact naturally, making movie and TV recommendations feel more human and tailored."
  },
  {
    "objectID": "projects/Netflix-Recommendation/netflix-recommendation.html#limitations",
    "href": "projects/Netflix-Recommendation/netflix-recommendation.html#limitations",
    "title": "ğŸ¬ Netflix Recommendation System & Chatbot",
    "section": "âš ï¸ Limitations",
    "text": "âš ï¸ Limitations\nWhile the system provides personalized recommendations and interactive chatbot responses, there are a few limitations:\n\nMulti-label Genre Complexity: Many titles belong to multiple genres, making it difficult for models to predict accurately from tokenized descriptions alone.\nText Ambiguity: Descriptions often contain vague or overlapping themes, reducing classification precision.\nModel Performance: Genre classification models (e.g., Logistic Regression, Naive Bayes) yielded relatively low F1 scores, indicating room for improvement in multi-label learning.\nUser Input Limitations: The chatbot depends on structured inputs (e.g., genre, sentiment), and may struggle with ambiguous or unrelated queries.\nCold Start Problem: The system does not incorporate real-time user behavior or preferences, limiting adaptability for new users.\n\nFuture enhancements could include deep learning models, multi-label classification improvements, and feedback-based recommendation tuning."
  },
  {
    "objectID": "projects/Netflix-Recommendation/netflix-recommendation.html#github-repository",
    "href": "projects/Netflix-Recommendation/netflix-recommendation.html#github-repository",
    "title": "ğŸ¬ Netflix Recommendation System & Chatbot",
    "section": "ğŸ“ GitHub Repository",
    "text": "ğŸ“ GitHub Repository\nğŸ‘‰ View Code on GitHub"
  },
  {
    "objectID": "projects/Amazon-Product-Analysis/amazon-product-analysis.html",
    "href": "projects/Amazon-Product-Analysis/amazon-product-analysis.html",
    "title": "ğŸ›ï¸ Amazon Product Reviews Sentiment Analysis",
    "section": "",
    "text": "This project analyzes customer sentiment from Amazon product reviews using natural language processing and machine learning techniques. The goal was to understand common customer opinions, how review length correlates with sentiment and rating, and to evaluate which models best classify review sentiment."
  },
  {
    "objectID": "projects/Amazon-Product-Analysis/amazon-product-analysis.html#project-overview",
    "href": "projects/Amazon-Product-Analysis/amazon-product-analysis.html#project-overview",
    "title": "ğŸ›ï¸ Amazon Product Reviews Sentiment Analysis",
    "section": "",
    "text": "This project analyzes customer sentiment from Amazon product reviews using natural language processing and machine learning techniques. The goal was to understand common customer opinions, how review length correlates with sentiment and rating, and to evaluate which models best classify review sentiment."
  },
  {
    "objectID": "projects/Amazon-Product-Analysis/amazon-product-analysis.html#objectives",
    "href": "projects/Amazon-Product-Analysis/amazon-product-analysis.html#objectives",
    "title": "ğŸ›ï¸ Amazon Product Reviews Sentiment Analysis",
    "section": "ğŸ¯ Objectives",
    "text": "ğŸ¯ Objectives\n\nIdentify common themes in positive vs.Â negative reviews\nExamine the relationship between review length, sentiment, and product rating\nEvaluate classification models for sentiment prediction"
  },
  {
    "objectID": "projects/Amazon-Product-Analysis/amazon-product-analysis.html#data-methods",
    "href": "projects/Amazon-Product-Analysis/amazon-product-analysis.html#data-methods",
    "title": "ğŸ›ï¸ Amazon Product Reviews Sentiment Analysis",
    "section": "ğŸ—‚ï¸ Data & Methods",
    "text": "ğŸ—‚ï¸ Data & Methods\n\nData: Amazon review dataset (1,465 reviews, 16 variables) from Kaggle\n\nText Preprocessing: Lowercasing, punctuation removal, stopword removal, tokenization\n\nFeature Engineering: TF-IDF with n-grams\n\nSentiment Labeling: VADER lexicon to classify sentiment as Positive, Neutral, or Negative\n\nModels Used: Logistic Regression, Random Forest, Support Vector Machine (SVM)"
  },
  {
    "objectID": "projects/Amazon-Product-Analysis/amazon-product-analysis.html#key-insights",
    "href": "projects/Amazon-Product-Analysis/amazon-product-analysis.html#key-insights",
    "title": "ğŸ›ï¸ Amazon Product Reviews Sentiment Analysis",
    "section": "ğŸ” Key Insights",
    "text": "ğŸ” Key Insights\n\nStrong Positive Bias: Majority of reviews were classified as positive; neutral and negative reviews were underrepresented.\nReview Length Matters: Longer reviews were slightly more likely to be positive, but the correlation was weak.\nThemes:\n\nPositive: â€œvalue for money,â€ â€œsound quality,â€ â€œlightweightâ€\nNegative: â€œpoor quality,â€ â€œcharging cable,â€ â€œdonâ€™t buyâ€"
  },
  {
    "objectID": "projects/Amazon-Product-Analysis/amazon-product-analysis.html#model-performance",
    "href": "projects/Amazon-Product-Analysis/amazon-product-analysis.html#model-performance",
    "title": "ğŸ›ï¸ Amazon Product Reviews Sentiment Analysis",
    "section": "ğŸ¤– Model Performance",
    "text": "ğŸ¤– Model Performance\n\n\n\n\n\n\n\n\n\nModel\nAccuracy\nStrengths\nWeaknesses\n\n\n\n\nLogistic Regression\n92%\nHigh recall for positive reviews\nPoor detection of neutral/negative\n\n\nRandom Forest\n91%\nRobust with positive sentiment\nWeak on negative (recall: 0.06)\n\n\nSVM\n92%\nBalanced and strong on positives\nMisclassified most negatives/neutral"
  },
  {
    "objectID": "projects/Amazon-Product-Analysis/amazon-product-analysis.html#business-impact",
    "href": "projects/Amazon-Product-Analysis/amazon-product-analysis.html#business-impact",
    "title": "ğŸ›ï¸ Amazon Product Reviews Sentiment Analysis",
    "section": "ğŸ’¡ Business Impact",
    "text": "ğŸ’¡ Business Impact\n\nProduct Improvement: Frequent negative terms flagged areas for design or quality fixes.\nMarketing: Highlighted strengths (e.g., sound quality) can inform ad copy and product positioning.\nCustomer Engagement: Long, detailed reviews suggest satisfaction; prompting longer feedback could yield richer insights."
  },
  {
    "objectID": "projects/Amazon-Product-Analysis/amazon-product-analysis.html#limitations-future-enhancement",
    "href": "projects/Amazon-Product-Analysis/amazon-product-analysis.html#limitations-future-enhancement",
    "title": "ğŸ›ï¸ Amazon Product Reviews Sentiment Analysis",
    "section": "ğŸ”„ Limitations & Future Enhancement",
    "text": "ğŸ”„ Limitations & Future Enhancement\n\nImbalanced dataset (mostly positive reviews) biased model performance\nModels underperformed on neutral and negative reviews\nFuture improvements: class balancing, hyperparameter tuning, and deep learning approaches"
  },
  {
    "objectID": "projects/Amazon-Product-Analysis/amazon-product-analysis.html#conclusion",
    "href": "projects/Amazon-Product-Analysis/amazon-product-analysis.html#conclusion",
    "title": "ğŸ›ï¸ Amazon Product Reviews Sentiment Analysis",
    "section": "ğŸ§¾ Conclusion",
    "text": "ğŸ§¾ Conclusion\nThis project demonstrated how sentiment analysis can uncover key customer insights from product reviews. Despite model limitations with neutral and negative classification, positive feedback was effectively captured. Further model tuning and data balancing could enhance accuracy across all sentiment categories, supporting more informed business decisions."
  },
  {
    "objectID": "projects/Amazon-Product-Analysis/amazon-product-analysis.html#github-repository",
    "href": "projects/Amazon-Product-Analysis/amazon-product-analysis.html#github-repository",
    "title": "ğŸ›ï¸ Amazon Product Reviews Sentiment Analysis",
    "section": "ğŸ“ GitHub Repository",
    "text": "ğŸ“ GitHub Repository\nğŸ‘‰ View Code on GitHub"
  },
  {
    "objectID": "projects/Yelp-Restaurant-Rating /Yelp Analysis.html",
    "href": "projects/Yelp-Restaurant-Rating /Yelp Analysis.html",
    "title": "My Portfolio",
    "section": "",
    "text": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\n#Read the excel dataset\nYelp = pd.read_excel('/content/data programming project - yelp.xlsx')\n\n\n# Overview of the dataset\n#print(Yelp.head())\nprint(Yelp.info())\n#print(Yelp.describe())\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 2176 entries, 0 to 2175\nData columns (total 36 columns):\n #   Column                          Non-Null Count  Dtype  \n---  ------                          --------------  -----  \n 0   Name                            2176 non-null   object \n 1   Phone                           2073 non-null   object \n 2   Address                         2117 non-null   object \n 3   Email                           982 non-null    object \n 4   Website                         1683 non-null   object \n 5   ServiceArea                     12 non-null     object \n 6   Instagram                       1106 non-null   object \n 7   Facebook                        1046 non-null   object \n 8   Twitter                         268 non-null    object \n 9   Linkedin                        70 non-null     object \n 10  Youtube                         108 non-null    object \n 11  BusinessUrl                     2176 non-null   object \n 12  Rating                          2176 non-null   float64\n 13  ReviewCount                     2176 non-null   int64  \n 14  PriceRange                      1586 non-null   object \n 15  Longitude                       2176 non-null   float64\n 16  Latitude                        2176 non-null   float64\n 17  Alias                           2176 non-null   object \n 18  BizId                           2176 non-null   object \n 19  BusinessSectionUrls_open_hours  2176 non-null   object \n 20  BusinessSectionUrls_reviews     2176 non-null   object \n 21  Categories_0_title              2176 non-null   object \n 22  Categories_0_url                2176 non-null   object \n 23  Categories_1_title              1603 non-null   object \n 24  Categories_1_url                1603 non-null   object \n 25  Categories_2_title              1032 non-null   object \n 26  Categories_2_url                1032 non-null   object \n 27  FormattedAddress                0 non-null      float64\n 28  IsAd                            2176 non-null   bool   \n 29  Neighborhoods_0                 846 non-null    object \n 30  Open_time                       0 non-null      float64\n 31  ParentBusiness                  0 non-null      float64\n 32  Ranking                         2176 non-null   int64  \n 33  RenderAdInfo                    2176 non-null   bool   \n 34  ServicePricing                  0 non-null      float64\n 35  Snippet                         2150 non-null   object \ndtypes: bool(2), float64(7), int64(2), object(25)\nmemory usage: 582.4+ KB\nNone\n\n\n\n# Drop columns with more than 50% missing values as well as columns that are redundant\nYelp = Yelp.dropna(thresh=Yelp.shape[0] * 0.5, axis=1)\nYelp = Yelp.drop(columns=['Website','BusinessUrl','Alias','BizId','BusinessSectionUrls_open_hours','BusinessSectionUrls_reviews','IsAd','RenderAdInfo','Categories_0_url','Categories_1_title', 'Categories_1_url'])\n\n\nprint(Yelp.info(10))\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 2176 entries, 0 to 2175\nData columns (total 12 columns):\n #   Column              Non-Null Count  Dtype  \n---  ------              --------------  -----  \n 0   Name                2176 non-null   object \n 1   Phone               2073 non-null   object \n 2   Address             2117 non-null   object \n 3   Instagram           1106 non-null   object \n 4   Rating              2176 non-null   float64\n 5   ReviewCount         2176 non-null   int64  \n 6   PriceRange          1586 non-null   object \n 7   Longitude           2176 non-null   float64\n 8   Latitude            2176 non-null   float64\n 9   Categories_0_title  2176 non-null   object \n 10  Ranking             2176 non-null   int64  \n 11  Snippet             2150 non-null   object \ndtypes: float64(3), int64(2), object(7)\nmemory usage: 204.1+ KB\nNone\n\n\n\nprint(\"Number of rows (datasets) in the data:\", len(Yelp))\n\nNumber of rows (datasets) in the data: 2176\n\n\n\n#Count missing values in each categories\nmissing_per_column = Yelp.isnull().sum()\nprint(missing_per_column)\n\nName                     0\nPhone                  103\nAddress                 59\nInstagram             1070\nRating                   0\nReviewCount              0\nPriceRange             590\nLongitude                0\nLatitude                 0\nCategories_0_title       0\nRanking                  0\nSnippet                 26\ndtype: int64\n\n\n\n#We will use only Categories 0 title as ou main cuisine type as it has no missing values and correctly represent the true cuisine type of the restaurant\n#Find the most popular cuisine type in the dataset (Top 10)\nfood_category = Yelp['Categories_0_title'].value_counts()\ntop_10 = food_category.head(10)\nprint(top_10)\nplt.figure(figsize=(8, 4))\nsns.barplot(x=top_10.index,y=top_10.values,palette='pastel')\nplt.xlabel('Category')\nplt.ylabel('Count')\nplt.title('Top 10 Cuisine Type by Count')\nplt.xticks(rotation=45)\nplt.show()\n\nCategories_0_title\nMexican          161\nNew American     110\nItalian          108\nKorean            95\nSeafood           93\nJapanese          90\nPizza             80\nMediterranean     62\nChinese           59\nThai              58\nName: count, dtype: int64\n\n\nFutureWarning: \n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n\n  sns.barplot(x=top_10.index,y=top_10.values,palette='pastel')\n\n\n\n\n\n\n\n\n\n\n#Scatter plot to see the correlation between number of reviews and star ratings\nplt.figure(figsize=(8, 4))\nplt.scatter(Yelp['ReviewCount'], Yelp['Rating'], alpha=0.3, color='blue')\nplt.xlabel('Number of Reviews')\nplt.ylabel('Star Ratings')\nplt.title('Scatter Plot: Star Ratings vs. Number of Reviews')\nplt.show()\n\n\n\n\n\n\n\n\n\n# Calculate the correlation between 'ReviewCount' and 'Rating_numeric'\ncorrelation = Yelp['ReviewCount'].corr(Yelp['Rating'])\nprint(f\"Correlation between ReviewCount and Rating: {correlation}\")\n\nCorrelation between ReviewCount and Rating: 0.003222962567526092\n\n\n\n# boxplot to show rating distribution by cuisine types\ntop_categories = Yelp['Categories_0_title'].value_counts().head(10).index\nfiltered_data = Yelp[Yelp['Categories_0_title'].isin(top_categories)]\n\nplt.figure(figsize=(10, 6))\nsns.boxplot(x='Categories_0_title', y='Rating', data=filtered_data, palette=\"Set3\",order=top_categories)\n\nplt.xticks(rotation=45, ha='right')\nplt.title('Rating Distributions (Top 10 Cuisine Types)', fontsize=16)\nplt.xlabel('Cuisine Type', fontsize=14)\nplt.ylabel('Ratings', fontsize=14)\n\nplt.tight_layout()\nplt.show()\n\nFutureWarning: \n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n\n  sns.boxplot(x='Categories_0_title', y='Rating', data=filtered_data, palette=\"Set3\",order=top_categories)\n\n\n\n\n\n\n\n\n\n\n#Correlation between restaurant ranking and star ratings\ncorrelation = Yelp['Ranking'].corr(Yelp['Rating'])\nprint(\"Correlation between Review Count and Rating:\", correlation)\n\nCorrelation between Review Count and Rating: -0.12806450476948608\n\n\n\n#Most prevalent positive and negative words from the cuisine type\nfrom textblob import TextBlob\nfrom wordcloud import WordCloud\nimport matplotlib.pyplot as plt\n\n# Filter data for a specific cuisine type\ncuisine_type = \"Mexican\"\nfiltered_data = Yelp[Yelp['Categories_0_title'] == cuisine_type].copy()\n\n# Function to determine sentiment polarity\ndef get_sentiment(text):\n    try:\n        analysis = TextBlob(str(text))  # Ensure text is converted to a string\n        return \"Positive\" if analysis.sentiment.polarity &gt; 0 else \"Negative\"\n    except:\n        return \"Neutral\"\n\n# Drop NaN values in 'Snippet' and apply sentiment analysis\nfiltered_data = filtered_data.dropna(subset=['Snippet'])\nfiltered_data['Sentiment'] = filtered_data['Snippet'].apply(get_sentiment)\n\n# Combine positive and negative review snippets\npositive_reviews = \" \".join(filtered_data[filtered_data['Sentiment'] == \"Positive\"]['Snippet'])\nnegative_reviews = \" \".join(filtered_data[filtered_data['Sentiment'] == \"Negative\"]['Snippet'])\n\n# Generate word clouds\npositive_wordcloud = WordCloud(width=800, height=400, background_color='white', colormap='Blues').generate(positive_reviews)\nnegative_wordcloud = WordCloud(width=800, height=400, background_color='white', colormap='Reds').generate(negative_reviews)\n\n# Plot the word clouds\nplt.figure(figsize=(16, 8))\n\n# Positive word cloud\nplt.subplot(1, 2, 1)\nplt.imshow(positive_wordcloud, interpolation='bilinear')\nplt.title(f\"Positive Reviews Word Cloud ({cuisine_type})\", fontsize=16)\nplt.axis('off')\n\n# Negative word cloud\nplt.subplot(1, 2, 2)\nplt.imshow(negative_wordcloud, interpolation='bilinear')\nplt.title(f\"Negative Reviews Word Cloud ({cuisine_type})\", fontsize=16)\nplt.axis('off')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n#Most prevalent positive and negative words from the cuisine type\nfrom textblob import TextBlob\nfrom wordcloud import WordCloud\nimport matplotlib.pyplot as plt\n\n# Filter data for a specific cuisine type\ncuisine_type = \"Chinese\"\nfiltered_data = Yelp[Yelp['Categories_0_title'] == cuisine_type].copy()\n\n# Function to determine sentiment polarity\ndef get_sentiment(text):\n    try:\n        analysis = TextBlob(str(text))  # Ensure text is converted to a string\n        return \"Positive\" if analysis.sentiment.polarity &gt; 0 else \"Negative\"\n    except:\n        return \"Neutral\"\n\n# Drop NaN values in 'Snippet' and apply sentiment analysis\nfiltered_data = filtered_data.dropna(subset=['Snippet'])\nfiltered_data['Sentiment'] = filtered_data['Snippet'].apply(get_sentiment)\n\n# Combine positive and negative review snippets\npositive_reviews = \" \".join(filtered_data[filtered_data['Sentiment'] == \"Positive\"]['Snippet'])\nnegative_reviews = \" \".join(filtered_data[filtered_data['Sentiment'] == \"Negative\"]['Snippet'])\n\n# Generate word clouds\npositive_wordcloud = WordCloud(width=800, height=400, background_color='white', colormap='Blues').generate(positive_reviews)\nnegative_wordcloud = WordCloud(width=800, height=400, background_color='white', colormap='Reds').generate(negative_reviews)\n\n# Plot the word clouds\nplt.figure(figsize=(16, 8))\n\n# Positive word cloud\nplt.subplot(1, 2, 1)\nplt.imshow(positive_wordcloud, interpolation='bilinear')\nplt.title(f\"Positive Reviews Word Cloud ({cuisine_type})\", fontsize=16)\nplt.axis('off')\n\n# Negative word cloud\nplt.subplot(1, 2, 2)\nplt.imshow(negative_wordcloud, interpolation='bilinear')\nplt.title(f\"Negative Reviews Word Cloud ({cuisine_type})\", fontsize=16)\nplt.axis('off')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n#Most prevalent positive and negative words from the cuisine type\nfrom textblob import TextBlob\nfrom wordcloud import WordCloud\nimport matplotlib.pyplot as plt\n\n# Filter data for a specific cuisine type\ncuisine_type = \"Italian\"\nfiltered_data = Yelp[Yelp['Categories_0_title'] == cuisine_type].copy()\n\n# Function to determine sentiment polarity\ndef get_sentiment(text):\n    try:\n        analysis = TextBlob(str(text))  # Ensure text is converted to a string\n        return \"Positive\" if analysis.sentiment.polarity &gt; 0 else \"Negative\"\n    except:\n        return \"Neutral\"\n\n# Drop NaN values in 'Snippet' and apply sentiment analysis\nfiltered_data = filtered_data.dropna(subset=['Snippet'])\nfiltered_data['Sentiment'] = filtered_data['Snippet'].apply(get_sentiment)\n\n# Combine positive and negative review snippets\npositive_reviews = \" \".join(filtered_data[filtered_data['Sentiment'] == \"Positive\"]['Snippet'])\nnegative_reviews = \" \".join(filtered_data[filtered_data['Sentiment'] == \"Negative\"]['Snippet'])\n\n# Generate word clouds\npositive_wordcloud = WordCloud(width=800, height=400, background_color='white', colormap='Blues').generate(positive_reviews)\nnegative_wordcloud = WordCloud(width=800, height=400, background_color='white', colormap='Reds').generate(negative_reviews)\n\n# Plot the word clouds\nplt.figure(figsize=(16, 8))\n\n# Positive word cloud\nplt.subplot(1, 2, 1)\nplt.imshow(positive_wordcloud, interpolation='bilinear')\nplt.title(f\"Positive Reviews Word Cloud ({cuisine_type})\", fontsize=16)\nplt.axis('off')\n\n# Negative word cloud\nplt.subplot(1, 2, 2)\nplt.imshow(negative_wordcloud, interpolation='bilinear')\nplt.title(f\"Negative Reviews Word Cloud ({cuisine_type})\", fontsize=16)\nplt.axis('off')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n#Most prevalent positive and negative words from the cuisine type\nfrom textblob import TextBlob\nfrom wordcloud import WordCloud\nimport matplotlib.pyplot as plt\n\n# Filter data for a specific cuisine type\ncuisine_type = \"Seafood\"\nfiltered_data = Yelp[Yelp['Categories_0_title'] == cuisine_type].copy()\n\n# Function to determine sentiment polarity\ndef get_sentiment(text):\n    try:\n        analysis = TextBlob(str(text))  # Ensure text is converted to a string\n        return \"Positive\" if analysis.sentiment.polarity &gt; 0 else \"Negative\"\n    except:\n        return \"Neutral\"\n\n# Drop NaN values in 'Snippet' and apply sentiment analysis\nfiltered_data = filtered_data.dropna(subset=['Snippet'])\nfiltered_data['Sentiment'] = filtered_data['Snippet'].apply(get_sentiment)\n\n# Combine positive and negative review snippets\npositive_reviews = \" \".join(filtered_data[filtered_data['Sentiment'] == \"Positive\"]['Snippet'])\nnegative_reviews = \" \".join(filtered_data[filtered_data['Sentiment'] == \"Negative\"]['Snippet'])\n\n# Generate word clouds\npositive_wordcloud = WordCloud(width=800, height=400, background_color='white', colormap='Blues').generate(positive_reviews)\nnegative_wordcloud = WordCloud(width=800, height=400, background_color='white', colormap='Reds').generate(negative_reviews)\n\n# Plot the word clouds\nplt.figure(figsize=(16, 8))\n\n# Positive word cloud\nplt.subplot(1, 2, 1)\nplt.imshow(positive_wordcloud, interpolation='bilinear')\nplt.title(f\"Positive Reviews Word Cloud ({cuisine_type})\", fontsize=16)\nplt.axis('off')\n\n# Negative word cloud\nplt.subplot(1, 2, 2)\nplt.imshow(negative_wordcloud, interpolation='bilinear')\nplt.title(f\"Negative Reviews Word Cloud ({cuisine_type})\", fontsize=16)\nplt.axis('off')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n#Plot map to see if the location of the restaurant is correlated with the ratings\n!pip install pandas geopandas folium matplotlib\nimport folium\nfrom folium.plugins import MarkerCluster\n\nfiltered_data = Yelp[['Rating', 'Latitude', 'Longitude']].dropna()\n\naverage_lat = filtered_data['Latitude'].mean()\naverage_lon = filtered_data['Longitude'].mean()\nrating_map = folium.Map(location=[average_lat, average_lon], zoom_start=10)\n\nmarker_cluster = MarkerCluster().add_to(rating_map)\n\nfor index, row in filtered_data.iterrows():\n    folium.CircleMarker(\n        location=(row['Latitude'], row['Longitude']),\n        radius=5,\n        color='blue',\n        fill=True,\n        fill_opacity=0.7,\n        fill_color='green' if row['Rating'] &gt;= 4 else 'red',\n        popup=f\"Rating: {row['Rating']}\"\n    ).add_to(marker_cluster)\n\nrating_map.save(\"ratings_map.html\")\nrating_map\n\n\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\nRequirement already satisfied: geopandas in /usr/local/lib/python3.10/dist-packages (1.0.1)\nRequirement already satisfied: folium in /usr/local/lib/python3.10/dist-packages (0.18.0)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\nRequirement already satisfied: numpy&gt;=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\nRequirement already satisfied: python-dateutil&gt;=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\nRequirement already satisfied: pytz&gt;=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\nRequirement already satisfied: tzdata&gt;=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\nRequirement already satisfied: pyogrio&gt;=0.7.2 in /usr/local/lib/python3.10/dist-packages (from geopandas) (0.10.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from geopandas) (24.2)\nRequirement already satisfied: pyproj&gt;=3.3.0 in /usr/local/lib/python3.10/dist-packages (from geopandas) (3.7.0)\nRequirement already satisfied: shapely&gt;=2.0.0 in /usr/local/lib/python3.10/dist-packages (from geopandas) (2.0.6)\nRequirement already satisfied: branca&gt;=0.6.0 in /usr/local/lib/python3.10/dist-packages (from folium) (0.8.0)\nRequirement already satisfied: jinja2&gt;=2.9 in /usr/local/lib/python3.10/dist-packages (from folium) (3.1.4)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from folium) (2.32.3)\nRequirement already satisfied: xyzservices in /usr/local/lib/python3.10/dist-packages (from folium) (2024.9.0)\nRequirement already satisfied: contourpy&gt;=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\nRequirement already satisfied: cycler&gt;=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: fonttools&gt;=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.1)\nRequirement already satisfied: kiwisolver&gt;=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\nRequirement already satisfied: pillow&gt;=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.0.0)\nRequirement already satisfied: pyparsing&gt;=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\nRequirement already satisfied: MarkupSafe&gt;=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2&gt;=2.9-&gt;folium) (3.0.2)\nRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from pyogrio&gt;=0.7.2-&gt;geopandas) (2024.8.30)\nRequirement already satisfied: six&gt;=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil&gt;=2.8.2-&gt;pandas) (1.16.0)\nRequirement already satisfied: charset-normalizer&lt;4,&gt;=2 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;folium) (3.4.0)\nRequirement already satisfied: idna&lt;4,&gt;=2.5 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;folium) (3.10)\nRequirement already satisfied: urllib3&lt;3,&gt;=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;folium) (2.2.3)\n\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\n\n\n\n#Pre-processing the data for machine learning models\nfrom sklearn.preprocessing import LabelEncoder\n\n# Select relevant features and target\nfeatures = Yelp[['Categories_0_title', 'Longitude', 'Latitude', 'ReviewCount']]\ntarget = Yelp['Rating']\n\n# Encode the 'Cuisine_Type' column\nlabel_encoder = LabelEncoder()\nfeatures['Categories_0_title'] = label_encoder.fit_transform(features['Categories_0_title'])\n\n#Bin ratings into categories (e.g., Low, Medium, High)\n# 0 - 2 = low, 2 - 3.5 = medium, 3.5 - 5 = high\ntarget = pd.cut(target, bins=[0, 2.5, 4, 5], labels=['Low', 'Medium', 'High'])\n\nSettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  features['Categories_0_title'] = label_encoder.fit_transform(features['Categories_0_title'])\n\n\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.3, random_state=42)\n\n\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import classification_report, accuracy_score\n#handle missing values\nX_train = X_train.dropna()\ny_train = y_train.dropna()\ny_train = y_train.replace('nan', None).dropna()\ny_test = y_test.replace('nan', None).dropna()\n\nvalid_indices_train = X_train.index.intersection(y_train.index)\nX_train = X_train.loc[valid_indices_train]\ny_train = y_train.loc[valid_indices_train]\n\n# Filter y_test to remove invalid entries before predictions\nvalid_test_indices = y_test.replace('nan', None).dropna().index\ny_test_filtered = y_test.loc[valid_test_indices]\n\n\n#Decision Tree models\ndt_model = DecisionTreeClassifier(random_state=42)\ndt_model.fit(X_train, y_train)\n\n# Re-run predictions for the filtered test set\nX_test_filtered = X_test.loc[valid_test_indices]\ny_pred_dt_filtered = dt_model.predict(X_test_filtered)\n\n# Predict and evaluate\ny_pred_dt = dt_model.predict(X_test)\ny_test = y_test.astype(str)\ny_pred_dt = y_pred_dt.astype(str)\nprint(\"Decision Tree Accuracy:\", accuracy_score(y_test_filtered, y_pred_dt_filtered))\nprint(classification_report(y_test_filtered, y_pred_dt_filtered))\n\nDecision Tree Accuracy: 0.6170542635658914\n              precision    recall  f1-score   support\n\n        High       0.76      0.69      0.72       456\n         Low       0.00      0.00      0.00         6\n      Medium       0.38      0.45      0.41       183\n\n    accuracy                           0.62       645\n   macro avg       0.38      0.38      0.38       645\nweighted avg       0.64      0.62      0.63       645\n\n\n\n\n#Decision Tree model with pruning parameters\ndt_model = DecisionTreeClassifier(\n    random_state=42,\n    max_depth=5,\n    min_samples_split=10,\n    min_samples_leaf=5\n)\n\n# Train the model\ndt_model.fit(X_train, y_train)\n\n# Re-run predictions for the filtered test set\nX_test_filtered = X_test.loc[valid_test_indices]\ny_pred_dt_filtered = dt_model.predict(X_test_filtered)\n\n# Predict and evaluate\ny_pred_dt = dt_model.predict(X_test)\ny_test = y_test.astype(str)\ny_pred_dt = y_pred_dt.astype(str)\n\n# Evaluation metrics\nprint(\"Decision Tree Accuracy:\", accuracy_score(y_test_filtered, y_pred_dt_filtered))\nprint(classification_report(y_test_filtered, y_pred_dt_filtered))\n\nDecision Tree Accuracy: 0.703875968992248\n              precision    recall  f1-score   support\n\n        High       0.77      0.85      0.80       456\n         Low       0.00      0.00      0.00         6\n      Medium       0.48      0.37      0.42       183\n\n    accuracy                           0.70       645\n   macro avg       0.42      0.41      0.41       645\nweighted avg       0.68      0.70      0.69       645\n\n\n\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n\n\n\nfrom sklearn.impute import SimpleImputer\n\n# Apply SimpleImputer to fill missing values in the features with the mean (or median for better robustness)\nimputer = SimpleImputer(strategy='mean')\n\n# Impute missing values for numerical columns in the features\nfeatures_imputed = imputer.fit_transform(features)\n\n# Check for missing values after imputation\nprint(pd.DataFrame(features_imputed).isnull().sum())  # This should show no NaN values now\n\n# Drop rows with missing target values\ntarget = target.dropna()  # Remove rows with NaN in target\n\n# Make sure X aligns with the cleaned y\nfeatures_imputed = features_imputed[target.index]  # Ensure X and y are still aligned after dropping\n\nfrom sklearn.model_selection import train_test_split\n\n# Split the data\nX_train, X_test, y_train, y_test = train_test_split(features_imputed, target, test_size=0.2, random_state=42)\n\n# Check if there are any NaN values in the training and testing sets\nprint(f\"X_train NaNs: {pd.DataFrame(X_train).isnull().sum().sum()}\")\nprint(f\"y_train NaNs: {y_train.isnull().sum()}\")\nprint(f\"X_test NaNs: {pd.DataFrame(X_test).isnull().sum().sum()}\")\nprint(f\"y_test NaNs: {y_test.isnull().sum()}\")\n\n0    0\n1    0\n2    0\n3    0\ndtype: int64\nX_train NaNs: 0\ny_train NaNs: 0\nX_test NaNs: 0\ny_test NaNs: 0\n\n\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# Initialize Random Forest model\nrf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n\n# Train the model\nrf_model.fit(X_train, y_train)\n\n# Predict on the test set\ny_pred_rf = rf_model.predict(X_test)\n\n# Convert predictions and true labels to strings to handle any potential mismatches\ny_test = y_test.astype(str)\ny_pred_rf = y_pred_rf.astype(str)\n\n# Accuracy and classification report\nprint(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\nprint(classification_report(y_test, y_pred_rf))\n\n# Verify the shapes of X_test and y_test\nprint(f\"X_test shape: {X_test.shape}\")\nprint(f\"y_test shape: {y_test.shape}\")\n\nRandom Forest Accuracy: 0.7199074074074074\n              precision    recall  f1-score   support\n\n           0       0.75      0.88      0.81       284\n           1       0.00      0.00      0.00         4\n           2       0.64      0.42      0.51       144\n\n    accuracy                           0.72       432\n   macro avg       0.46      0.43      0.44       432\nweighted avg       0.70      0.72      0.70       432\n\nX_test shape: (432, 4)\ny_test shape: (432,)\n\n\n\nfrom sklearn.decomposition import PCA\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom sklearn.preprocessing import StandardScaler\n\n# Standardize the data (PCA works better with scaled data)\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Apply PCA to reduce dimensions\npca = PCA(n_components=0.95)  # Retain 95% of variance\nX_train_pca = pca.fit_transform(X_train_scaled)\nX_test_pca = pca.transform(X_test_scaled)\n\n# Initialize Random Forest model\nrf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n\n# Train the model on PCA-transformed data\nrf_model.fit(X_train_pca, y_train)\n\n# Predict on the PCA-transformed test set\ny_pred_rf = rf_model.predict(X_test_pca)\n\n# Convert predictions and true labels to strings to handle any potential mismatches\ny_test = y_test.astype(str)\ny_pred_rf = y_pred_rf.astype(str)\n\n# Accuracy and classification report\nprint(\"Random Forest Accuracy(PCA):\", accuracy_score(y_test, y_pred_rf))\nprint(classification_report(y_test, y_pred_rf))\n\n# Check how much variance is explained by the retained components\nexplained_variance = pca.explained_variance_ratio_\nprint(\"Explained Variance by PCA components:\", explained_variance)\nprint(f\"Number of PCA components retained: {pca.n_components_}\")\n\nRandom Forest Accuracy(PCA): 0.6574074074074074\n              precision    recall  f1-score   support\n\n        High       0.70      0.85      0.77       284\n         Low       0.00      0.00      0.00         4\n      Medium       0.49      0.29      0.37       144\n\n    accuracy                           0.66       432\n   macro avg       0.40      0.38      0.38       432\nweighted avg       0.62      0.66      0.63       432\n\nExplained Variance by PCA components: [0.49675527 0.25393994 0.24389005]\nNumber of PCA components retained: 3\n\n\n\n#Try to apply SMOTE to the random forest model\nfrom sklearn.impute import SimpleImputer\n\n# Impute missing values in numerical columns\nimputer = SimpleImputer(strategy='mean')\nX_train = imputer.fit_transform(X_train)\nX_test = imputer.transform(X_test)\n\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\nfrom sklearn.preprocessing import LabelEncoder\n\nlabel_encoder = LabelEncoder()\ny_train = label_encoder.fit_transform(y_train)\ny_test = label_encoder.transform(y_test)\n\nfrom sklearn.model_selection import GridSearchCV\n\nfrom imblearn.over_sampling import SMOTE\n\n# Apply SMOTE to balance the dataset\nsmote = SMOTE(random_state=42)\nX_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n\nrf_remodel = RandomForestClassifier(n_estimators=100, random_state=42)\nrf_remodel.fit(X_train_balanced, y_train_balanced)\n\n# 5. Predict on the test set\ny_pred_rf_remodel = rf_remodel.predict(X_test)\n\n# 6. Evaluate the model\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred_rf_remodel))\nprint(classification_report(y_test, y_pred_rf_remodel))\n\nAccuracy: 0.6620370370370371\n              precision    recall  f1-score   support\n\n           0       0.78      0.74      0.76       284\n           1       0.00      0.00      0.00         4\n           2       0.53      0.53      0.53       144\n\n    accuracy                           0.66       432\n   macro avg       0.44      0.42      0.43       432\nweighted avg       0.69      0.66      0.67       432\n\n\n\n\n#Cross Validation for Random Forest\nfrom sklearn.model_selection import StratifiedKFold, cross_val_score\n\nkf = StratifiedKFold(n_splits=5)\ncv_scores = cross_val_score(rf_model, X_train, y_train, cv=kf, scoring='accuracy')\nprint(\"Cross-Validation Accuracy:\", cv_scores.mean())\n\nCross-Validation Accuracy: 0.7041557128412539\n\n\n\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\n# Assuming 'features' is your dataset\n# If necessary, you can apply scaling (StandardScaler, MinMaxScaler) for better results\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nfeatures_scaled = scaler.fit_transform(features)\nwcss = []\nfor k in range(1, 11):  # Check for k values from 1 to 10\n    kmeans = KMeans(n_clusters=k, init='k-means++', max_iter=300, n_init=10, random_state=42)\n    kmeans.fit(features_scaled)\n    wcss.append(kmeans.inertia_)  # Inertia is the WCSS\nplt.figure(figsize=(8, 6))\nplt.plot(range(1, 11), wcss)\nplt.title('Elbow Method for Optimal k', fontsize=16)\nplt.xlabel('Number of Clusters (k)', fontsize=14)\nplt.ylabel('WCSS (Within-Cluster Sum of Squares)', fontsize=14)\nplt.xticks(range(1, 11))\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# Initialize KNN model\nknn_model = KNeighborsClassifier(n_neighbors=4)  # You can experiment with different values of k\n\n# Train the KNN model\nknn_model.fit(X_train, y_train)\n\n# Predict on the test set\ny_pred_knn = knn_model.predict(X_test)\n\n# Convert predictions and true labels to strings if necessary\ny_test = y_test.astype(str)\ny_pred_knn = y_pred_knn.astype(str)\n\n# Evaluate the KNN model\nprint(\"KNN Accuracy:\", accuracy_score(y_test, y_pred_knn))\nprint(classification_report(y_test, y_pred_knn))\n\n# Verify the shapes of X_test and y_test\nprint(f\"X_test shape: {X_test.shape}\")\nprint(f\"y_test shape: {y_test.shape}\")\n\nKNN Accuracy: 0.6689814814814815\n              precision    recall  f1-score   support\n\n           0       0.69      0.90      0.78       284\n           1       0.00      0.00      0.00         4\n           2       0.52      0.23      0.32       144\n\n    accuracy                           0.67       432\n   macro avg       0.41      0.38      0.37       432\nweighted avg       0.63      0.67      0.62       432\n\nX_test shape: (432, 4)\ny_test shape: (432,)\n\n\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n\n\n\n#KNN afer hyperparameter tune\nfrom sklearn.model_selection import GridSearchCV\n\n# Define parameter grid for tuning\nparam_grid = {'n_neighbors': [3, 5, 7, 9], 'weights': ['uniform', 'distance']}\n\n# Initialize GridSearchCV with cross-validation\ngrid_search = GridSearchCV(KNeighborsClassifier(), param_grid, cv=4, scoring='accuracy')\n\n# Fit the grid search\ngrid_search.fit(X_train, y_train)\n\n# Get the best parameters\nprint(\"Best Parameters:\", grid_search.best_params_)\n\n# Evaluate the model with the best parameters\nbest_knn_model = grid_search.best_estimator_\ny_pred_knn_best = best_knn_model.predict(X_test)\n\n# Convert predictions and true labels to strings if necessary\ny_test = y_test.astype(str)\ny_pred_knn_best = y_pred_knn_best.astype(str)\n\n# Accuracy and classification report for the best model\nprint(\"Best KNN Accuracy:\", accuracy_score(y_test, y_pred_knn_best))\nprint(classification_report(y_test, y_pred_knn_best))\n\nBest Parameters: {'n_neighbors': 9, 'weights': 'uniform'}\nBest KNN Accuracy: 0.6597222222222222\n              precision    recall  f1-score   support\n\n           0       0.70      0.87      0.77       284\n           1       0.00      0.00      0.00         4\n           2       0.49      0.26      0.34       144\n\n    accuracy                           0.66       432\n   macro avg       0.40      0.38      0.37       432\nweighted avg       0.62      0.66      0.62       432\n\n\n\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n\n\n\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# First, make sure to include only numeric columns for correlation\n# You can exclude non-numeric columns such as categorical columns.\ndf_numeric = Yelp.select_dtypes(include=['number'])\n\n# Compute the correlation matrix\ncorrelation_matrix = df_numeric.corr()\n\n# Print the correlation matrix\nprint(correlation_matrix)\n\n# Visualize the correlation matrix using a heatmap\nplt.figure(figsize=(10, 8))\nsns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)\nplt.title('Correlation Matrix')\nplt.show()\n\n               Rating  ReviewCount  Longitude  Latitude   Ranking\nRating       1.000000     0.003223   0.018082 -0.071159 -0.128065\nReviewCount  0.003223     1.000000   0.044630 -0.075662 -0.115116\nLongitude    0.018082     0.044630   1.000000 -0.976865 -0.025678\nLatitude    -0.071159    -0.075662  -0.976865  1.000000  0.002244\nRanking     -0.128065    -0.115116  -0.025678  0.002244  1.000000\n\n\n\n\n\n\n\n\n\n\n#Feature of importance from random forest\nimport matplotlib.pyplot as plt\n\nfeature_importances = rf_model.feature_importances_\n\n# Plot feature importances\nplt.figure(figsize=(10, 6))\nplt.bar(features.columns, feature_importances, color='skyblue')\nplt.xlabel('Features')\nplt.ylabel('Importance')\nplt.title('Feature Importance in Rating Prediction')\nplt.show()\n\n\n\n\n\n\n\n\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom imblearn.over_sampling import SMOTE\n\n# 1. Prepare features and target\nfeatures = Yelp[['Categories_0_title', 'Longitude', 'Latitude', 'ReviewCount']].copy()\nlabel_encoder = LabelEncoder()\nfeatures['Categories_0_title'] = label_encoder.fit_transform(features['Categories_0_title'].astype(str))\n\n# Bin the ratings into categories and remove NaN values\ntarget = Yelp['Rating'].dropna()\ntarget = pd.cut(target, bins=[0, 2, 3.5, 5], labels=['Low', 'Medium', 'High'])\ntarget = target.astype(str)  # Ensure the target is a string type for classification\n\n# 2. Split into training and test sets\nX_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n\n# Ensure no NaN values\nX_train = features.dropna()\ny_train = target[X_train.index]\n\n# 3. Apply SMOTE to balance classes\n# Apply SMOTE to balance classes\nsmote = SMOTE(random_state=42)\nX_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n\n# 4. Train the Decision Tree model\ndt_model = DecisionTreeClassifier(random_state=42)\ndt_model.fit(X_train_resampled, y_train_resampled)\n\n# 5. Predict on the test set\ny_pred = dt_model.predict(X_test)\n\n# 6. Evaluate the model\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\nprint(classification_report(y_test, y_pred))\n\nAccuracy: 1.0\n              precision    recall  f1-score   support\n\n        High       1.00      1.00      1.00       401\n      Medium       1.00      1.00      1.00        30\n         nan       1.00      1.00      1.00         5\n\n    accuracy                           1.00       436\n   macro avg       1.00      1.00      1.00       436\nweighted avg       1.00      1.00      1.00       436\n\n\n\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import LabelEncoder\n\n\n# Train and evaluate Decision Tree model\ndt_model.fit(X_train, y_train)\ny_pred_dt = dt_model.predict(X_test)\ndt_accuracy = accuracy_score(y_test, y_pred_dt)\nprint(\"Decision Tree Stratified Accuracy:\", dt_accuracy)\nprint(classification_report(y_test, y_pred_dt))\n\n# Train and evaluate Random Forest model\nrf_model.fit(X_train, y_train)\ny_pred_rf = rf_model.predict(X_test)\nrf_accuracy = accuracy_score(y_test, y_pred_rf)\nprint(\"Random Forest Stratified Accuracy:\", rf_accuracy)\nprint(classification_report(y_test, y_pred_rf))\n\nDecision Tree Stratified Accuracy: 1.0\n              precision    recall  f1-score   support\n\n        High       1.00      1.00      1.00       401\n      Medium       1.00      1.00      1.00        30\n         nan       1.00      1.00      1.00         5\n\n    accuracy                           1.00       436\n   macro avg       1.00      1.00      1.00       436\nweighted avg       1.00      1.00      1.00       436\n\nRandom Forest Stratified Accuracy: 1.0\n              precision    recall  f1-score   support\n\n        High       1.00      1.00      1.00       401\n      Medium       1.00      1.00      1.00        30\n         nan       1.00      1.00      1.00         5\n\n    accuracy                           1.00       436\n   macro avg       1.00      1.00      1.00       436\nweighted avg       1.00      1.00      1.00       436"
  },
  {
    "objectID": "projects/Bank-Churn-Prediction/bank-churn-prediction.html",
    "href": "projects/Bank-Churn-Prediction/bank-churn-prediction.html",
    "title": "ğŸ¦ Predicting Bank Customer Churn",
    "section": "",
    "text": "As digital banking continues to grow, identifying and preventing customer churnâ€”especially silent attritionâ€”has become critical for banks. This project applied multiple machine learning models to predict customer churn and uncover key behavioral and demographic risk factors to enable proactive retention strategies."
  },
  {
    "objectID": "projects/Bank-Churn-Prediction/bank-churn-prediction.html#project-overview",
    "href": "projects/Bank-Churn-Prediction/bank-churn-prediction.html#project-overview",
    "title": "ğŸ¦ Predicting Bank Customer Churn",
    "section": "",
    "text": "As digital banking continues to grow, identifying and preventing customer churnâ€”especially silent attritionâ€”has become critical for banks. This project applied multiple machine learning models to predict customer churn and uncover key behavioral and demographic risk factors to enable proactive retention strategies."
  },
  {
    "objectID": "projects/Bank-Churn-Prediction/bank-churn-prediction.html#objectives",
    "href": "projects/Bank-Churn-Prediction/bank-churn-prediction.html#objectives",
    "title": "ğŸ¦ Predicting Bank Customer Churn",
    "section": "ğŸ¯ Objectives",
    "text": "ğŸ¯ Objectives\n\nVisualize current customer behavior and demographics\nBuild predictive models to classify customers at risk of churn\nIdentify actionable drivers of attrition for strategic intervention"
  },
  {
    "objectID": "projects/Bank-Churn-Prediction/bank-churn-prediction.html#data-methods",
    "href": "projects/Bank-Churn-Prediction/bank-churn-prediction.html#data-methods",
    "title": "ğŸ¦ Predicting Bank Customer Churn",
    "section": "ğŸ—‚ï¸ Data & Methods",
    "text": "ğŸ—‚ï¸ Data & Methods\n\nData: 10,000 records from a European bank (Kaggle)\nFeatures: Age, Gender, Geography, Balance, Tenure, Products, Activity, etc.\nTools: Python, Scikit-learn, SMOTE, PCA\nModels Used: Logistic Regression, Gaussian Naive Bayes, Decision Tree, Random Forest"
  },
  {
    "objectID": "projects/Bank-Churn-Prediction/bank-churn-prediction.html#model-performance-summary",
    "href": "projects/Bank-Churn-Prediction/bank-churn-prediction.html#model-performance-summary",
    "title": "ğŸ¦ Predicting Bank Customer Churn",
    "section": "ğŸ¤– Model Performance Summary",
    "text": "ğŸ¤– Model Performance Summary\n\n\n\n\n\n\n\n\n\n\nModel\nAccuracy\nPrecision (Churn)\nRecall (Churn)\nF1-Score (Churn)\n\n\n\n\nLogistic Regression\n80.9%\n60%\n19% â†’ 77% (with SMOTE)\n29% â†’ 77%\n\n\nNaive Bayes\n78.7%\n36% â†’ 70%\n6% â†’ 74%\n11% â†’ 72%\n\n\nDecision Tree\n85% (after pruning)\n80%\n37%\n51%\n\n\nRandom Forest\n86% â†’ 84% (with SMOTE)\n76% â†’ 58%\n47% â†’ 64%\n58% â†’ 61%\n\n\n\n\nâœ… Random Forest with SMOTE achieved the best balance for identifying churners, despite a slight drop in precision."
  },
  {
    "objectID": "projects/Bank-Churn-Prediction/bank-churn-prediction.html#feature-importance-logistic-regression",
    "href": "projects/Bank-Churn-Prediction/bank-churn-prediction.html#feature-importance-logistic-regression",
    "title": "ğŸ¦ Predicting Bank Customer Churn",
    "section": "ğŸ” Feature Importance â€“ Logistic Regression",
    "text": "ğŸ” Feature Importance â€“ Logistic Regression\n\n\n\nThis chart displays the standardized coefficients from the Logistic Regression model, highlighting which features most influence customer churn predictions.\n\nAge and Balance are the strongest positive predictors of churn â€” older customers and those with higher balances are more likely to leave.\nIsActiveMember has the strongest negative coefficient, indicating active users are significantly less likely to churn.\nOther features like Geography, Estimated Salary, and Gender show smaller but still notable impacts.\n\nThese insights help the bank prioritize retention efforts around customer age, engagement, and account value."
  },
  {
    "objectID": "projects/Bank-Churn-Prediction/bank-churn-prediction.html#key-insights",
    "href": "projects/Bank-Churn-Prediction/bank-churn-prediction.html#key-insights",
    "title": "ğŸ¦ Predicting Bank Customer Churn",
    "section": "ğŸ” Key Insights",
    "text": "ğŸ” Key Insights\n\nDemographics: Older customers are more likely to churn; geographic differences (France/Germany higher than Spain).\nBehavioral Indicators:\n\nInactive members have a 27% churn rate vs.Â 14% for active.\nCustomers with fewer products are more likely to churn.\n\nTop Predictive Features: Age, Number of Products, Balance, IsActiveMember."
  },
  {
    "objectID": "projects/Bank-Churn-Prediction/bank-churn-prediction.html#strategic-recommendations",
    "href": "projects/Bank-Churn-Prediction/bank-churn-prediction.html#strategic-recommendations",
    "title": "ğŸ¦ Predicting Bank Customer Churn",
    "section": "ğŸ’¡ Strategic Recommendations",
    "text": "ğŸ’¡ Strategic Recommendations\n\nEngagement: Target inactive users and those with only 1â€“2 products via cross-sell campaigns.\nPersonalization: Design region-specific and age-aware outreach strategies.\nRetention: Monitor older customers and offer digital support to reduce disengagement.\nModel Use: Deploy Random Forest with SMOTE to support real-time churn alerts."
  },
  {
    "objectID": "projects/Bank-Churn-Prediction/bank-churn-prediction.html#conclusion",
    "href": "projects/Bank-Churn-Prediction/bank-churn-prediction.html#conclusion",
    "title": "ğŸ¦ Predicting Bank Customer Churn",
    "section": "ğŸ§¾ Conclusion",
    "text": "ğŸ§¾ Conclusion\nThis project shows how machine learning can effectively identify churn risk using behavioral and demographic signals. With Random Forest as the most effective model, supported by SMOTE balancing, banks can proactively reduce attrition by targeting the right customers at the right time. The insights gained can guide smarter customer engagement and long-term profitability."
  },
  {
    "objectID": "projects/Bank-Churn-Prediction/bank-churn-prediction.html#github-repository",
    "href": "projects/Bank-Churn-Prediction/bank-churn-prediction.html#github-repository",
    "title": "ğŸ¦ Predicting Bank Customer Churn",
    "section": "ğŸ“ GitHub Repository",
    "text": "ğŸ“ GitHub Repository\nğŸ‘‰ View Code on GitHub"
  },
  {
    "objectID": "projects/Bank-Churn-Prediction/Group_8B_ML_Final_Project_ipynb_final.html",
    "href": "projects/Bank-Churn-Prediction/Group_8B_ML_Final_Project_ipynb_final.html",
    "title": "My Portfolio",
    "section": "",
    "text": "# Things to do\n# Clean Data\n# Build a model (1 for each)\n\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy.stats import ttest_ind, chi2_contingency\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report\n\n# Load the dataset\ndata = pd.read_csv('bank_churn.csv')  # Replace with your file path\n\n# Encode categorical variables\ndata['Geography'] = data['Geography'].astype('category').cat.codes\ndata['Gender'] = data['Gender'].astype('category').cat.codes\n\n# Separate features and target\nX = data.drop(['CustomerId', 'Surname', 'Exited'], axis=1)\ny = data['Exited']\n\n# Compare churners and non-churners\nchurners = data[data['Exited'] == 1]\nnon_churners = data[data['Exited'] == 0]\n\n# Statistical tests for numerical features\nfor col in X.columns:\n    stat, p_val = ttest_ind(churners[col], non_churners[col], equal_var=False)\n    print(f\"{col}: t-statistic={stat:.2f}, p-value={p_val:.2e}\")\n\n# Example: Plot distributions for balance\nsns.histplot(churners['Balance'], color='red', label='Churners', kde=True)\nsns.histplot(non_churners['Balance'], color='blue', label='Non-Churners', kde=True)\nplt.legend()\nplt.title('Balance Distribution')\nplt.show()\n\n# Predictive Modeling: Random Forest\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n\nrf_model = RandomForestClassifier(random_state=42)\nrf_model.fit(X_train, y_train)\ny_pred = rf_model.predict(X_test)\n\nprint(\"Random Forest Classification Report:\\n\", classification_report(y_test, y_pred))\n\n# Feature Importance\nfeature_importances = pd.DataFrame({\n    'Feature': X.columns,\n    'Importance': rf_model.feature_importances_\n}).sort_values(by='Importance', ascending=False)\n\nprint(feature_importances)\n\nCreditScore: t-statistic=-2.63, p-value=8.46e-03\nGeography: t-statistic=3.86, p-value=1.15e-04\nGender: t-statistic=-10.69, p-value=3.27e-26\nAge: t-statistic=30.42, p-value=4.71e-179\nTenure: t-statistic=-1.38, p-value=1.66e-01\nBalance: t-statistic=12.47, p-value=6.32e-35\nNumOfProducts: t-statistic=-3.70, p-value=2.19e-04\nHasCrCard: t-statistic=-0.71, p-value=4.78e-01\nIsActiveMember: t-statistic=-16.13, p-value=2.38e-56\nEstimatedSalary: t-statistic=1.20, p-value=2.29e-01\n\n\n\n\n\n\n\n\n\nRandom Forest Classification Report:\n               precision    recall  f1-score   support\n\n           0       0.88      0.97      0.92      1593\n           1       0.78      0.46      0.58       407\n\n    accuracy                           0.86      2000\n   macro avg       0.83      0.71      0.75      2000\nweighted avg       0.86      0.86      0.85      2000\n\n           Feature  Importance\n3              Age    0.239934\n9  EstimatedSalary    0.147069\n0      CreditScore    0.144104\n5          Balance    0.141194\n6    NumOfProducts    0.129134\n4           Tenure    0.081958\n8   IsActiveMember    0.039596\n1        Geography    0.038467\n7        HasCrCard    0.019583\n2           Gender    0.018959\n\n\n\n# Churn distribution (Exited = 1 means churned)\nchurn_counts = data['Exited'].value_counts(normalize=True)\nprint(\"Churn Distribution:\\n\", churn_counts)\n\n# Plot churn distribution\nsns.barplot(x=churn_counts.index, y=churn_counts.values, palette=\"coolwarm\")\nplt.title('Churn Distribution')\nplt.xlabel('Churn Status (0 = Non-Churn, 1 = Churn)')\nplt.ylabel('Proportion')\nplt.xticks([0, 1], ['Non-Churn', 'Churn'])\nplt.show()\n\n# Distribution of Age by Churn Status\nsns.histplot(data=data, x='Age', hue='Exited', kde=True, palette=\"coolwarm\", alpha=0.6)\nplt.title('Age Distribution by Churn Status')\nplt.xlabel('Age')\nplt.ylabel('Frequency')\nplt.legend(title='Churn Status', labels=['Non-Churn', 'Churn'])\nplt.show()\n\n# Gender distribution by Churn Status\nsns.countplot(data=data, x='Gender', hue='Exited', palette=\"coolwarm\")\nplt.title('Gender Distribution by Churn Status')\nplt.xlabel('Gender (0 = Male, 1 = Female)')\nplt.ylabel('Count')\nplt.legend(title='Churn Status', labels=['Non-Churn', 'Churn'])\nplt.show()\n\n# Product usage distribution by Churn Status\nsns.boxplot(data=data, x='Exited', y='NumOfProducts', palette=\"coolwarm\")\nplt.title('Number of Products by Churn Status')\nplt.xlabel('Churn Status (0 = Non-Churn, 1 = Churn)')\nplt.ylabel('Number of Products')\nplt.xticks([0, 1], ['Non-Churn', 'Churn'])\nplt.show()\n\n# Balance distribution by Churn Status\nsns.boxplot(data=data, x='Exited', y='Balance', palette=\"coolwarm\")\nplt.title('Account Balance by Churn Status')\nplt.xlabel('Churn Status (0 = Non-Churn, 1 = Churn)')\nplt.ylabel('Balance')\nplt.xticks([0, 1], ['Non-Churn', 'Churn'])\nplt.show()\n\nChurn Distribution:\n Exited\n0    0.7963\n1    0.2037\nName: proportion, dtype: float64\n\n\nFutureWarning: \n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n\n  sns.barplot(x=churn_counts.index, y=churn_counts.values, palette=\"coolwarm\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFutureWarning: \n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n\n  sns.boxplot(data=data, x='Exited', y='NumOfProducts', palette=\"coolwarm\")\n\n\n\n\n\n\n\n\n\nFutureWarning: \n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n\n  sns.boxplot(data=data, x='Exited', y='Balance', palette=\"coolwarm\")\n\n\n\n\n\n\n\n\n\n\n\n# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# 1. ë°ì´í„° ë¡œë“œ\nfile_path = '/content/Bank_Churn.csv'  # CSV íŒŒì¼ ê²½ë¡œ\ndata = pd.read_csv(file_path)\n\n# ë²”ì£¼í˜• ì—´ ìë™ ê°ì§€ í›„ ë³€í™˜\ncategorical_cols = data.select_dtypes(include=['object']).columns\ndata_dummy = pd.get_dummies(data, columns=categorical_cols, drop_first=True)\n\n# 2. ìˆ«ìí˜• ë³€ìˆ˜ ì„ íƒ\nnumeric_data = data.select_dtypes(include=['float64', 'int64'])  # ìˆ«ìí˜• ì—´ë§Œ ì„ íƒ\n\n# 3. ìƒê´€ í–‰ë ¬ ê³„ì‚°\ncorr_matrix = numeric_data.corr()  # ìƒê´€ ê³„ìˆ˜ ê³„ì‚°\n\n# 4. ìƒê´€ í–‰ë ¬ íˆíŠ¸ë§µ ì‹œê°í™”\nplt.figure(figsize=(10, 8))  # ê·¸ë˜í”„ í¬ê¸° ì„¤ì •\nsns.heatmap(\n    corr_matrix,\n    annot=True,  # ìƒê´€ ê³„ìˆ˜ ê°’ í‘œì‹œ\n    fmt=\".2f\",   # ê°’ í‘œì‹œ í˜•ì‹ (ì†Œìˆ˜ì  2ìë¦¬)\n    cmap='coolwarm',  # ìƒ‰ìƒ íŒ”ë ˆíŠ¸\n    cbar=True     # ì»¬ëŸ¬ ë°” í‘œì‹œ\n)\nplt.title(\"Correlation Matrix Heatmap\", fontsize=16)  # ì œëª© ì¶”ê°€\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nfrom scipy.stats import f_oneway\n\n# Churn rate by geography\nchurn_rate_by_geo = data.groupby('Geography')['Exited'].mean()\nprint(churn_rate_by_geo)\n\n# Visualize churn rates\nchurn_rate_by_geo.plot(kind='bar', color=['red', 'blue', 'green'])\nplt.title('Churn Rate by Geography')\nplt.xticks([0, 1, 2], ['France', 'Germany', 'Spain'], rotation=0)\nplt.show()\n\n# ANOVA test for Balance by Geography\nanova_stat, p_val = f_oneway(\n    data[data['Geography'] == 0]['Balance'],\n    data[data['Geography'] == 1]['Balance'],\n    data[data['Geography'] == 2]['Balance']\n)\nprint(f\"ANOVA Test: F-statistic={anova_stat:.2f}, p-value={p_val:.2e}\")\n\nGeography\n0    0.161548\n1    0.324432\n2    0.166734\nName: Exited, dtype: float64\n\n\n\n\n\n\n\n\n\nANOVA Test: F-statistic=958.43, p-value=0.00e+00\n\n\n\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\n\n# Scale features\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\n# Perform PCA for visualization (optional)\npca = PCA(n_components=2)\nX_pca = pca.fit_transform(X_scaled)\n\n# K-Means clustering\nkmeans = KMeans(n_clusters=4, random_state=42)\ndata['Cluster'] = kmeans.fit_predict(X_scaled)\n\n# Visualize clusters\nplt.scatter(X_pca[:, 0], X_pca[:, 1], c=data['Cluster'], cmap='viridis', alpha=0.7)\nplt.title('Customer Segments (PCA)')\nplt.xlabel('PC1')\nplt.ylabel('PC2')\nplt.colorbar(label='Cluster')\nplt.show()\n\n# Cluster profiles\ncluster_profiles = data.groupby('Cluster').mean()\nprint(cluster_profiles)\n\n\n\n\n\n\n\n\n\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\n/usr/local/lib/python3.10/dist-packages/pandas/core/groupby/groupby.py in _agg_py_fallback(self, how, values, ndim, alt)\n   1941         try:\n-&gt; 1942             res_values = self._grouper.agg_series(ser, alt, preserve_dtype=True)\n   1943         except Exception as err:\n\n/usr/local/lib/python3.10/dist-packages/pandas/core/groupby/ops.py in agg_series(self, obj, func, preserve_dtype)\n    863 \n--&gt; 864         result = self._aggregate_series_pure_python(obj, func)\n    865 \n\n/usr/local/lib/python3.10/dist-packages/pandas/core/groupby/ops.py in _aggregate_series_pure_python(self, obj, func)\n    884         for i, group in enumerate(splitter):\n--&gt; 885             res = func(group)\n    886             res = extract_result(res)\n\n/usr/local/lib/python3.10/dist-packages/pandas/core/groupby/groupby.py in &lt;lambda&gt;(x)\n   2453                 \"mean\",\n-&gt; 2454                 alt=lambda x: Series(x, copy=False).mean(numeric_only=numeric_only),\n   2455                 numeric_only=numeric_only,\n\n/usr/local/lib/python3.10/dist-packages/pandas/core/series.py in mean(self, axis, skipna, numeric_only, **kwargs)\n   6548     ):\n-&gt; 6549         return NDFrame.mean(self, axis, skipna, numeric_only, **kwargs)\n   6550 \n\n/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py in mean(self, axis, skipna, numeric_only, **kwargs)\n  12419     ) -&gt; Series | float:\n&gt; 12420         return self._stat_function(\n  12421             \"mean\", nanops.nanmean, axis, skipna, numeric_only, **kwargs\n\n/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py in _stat_function(self, name, func, axis, skipna, numeric_only, **kwargs)\n  12376 \n&gt; 12377         return self._reduce(\n  12378             func, name=name, axis=axis, skipna=skipna, numeric_only=numeric_only\n\n/usr/local/lib/python3.10/dist-packages/pandas/core/series.py in _reduce(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\n   6456                 )\n-&gt; 6457             return op(delegate, skipna=skipna, **kwds)\n   6458 \n\n/usr/local/lib/python3.10/dist-packages/pandas/core/nanops.py in f(values, axis, skipna, **kwds)\n    146             else:\n--&gt; 147                 result = alt(values, axis=axis, skipna=skipna, **kwds)\n    148 \n\n/usr/local/lib/python3.10/dist-packages/pandas/core/nanops.py in new_func(values, axis, skipna, mask, **kwargs)\n    403 \n--&gt; 404         result = func(values, axis=axis, skipna=skipna, mask=mask, **kwargs)\n    405 \n\n/usr/local/lib/python3.10/dist-packages/pandas/core/nanops.py in nanmean(values, axis, skipna, mask)\n    719     the_sum = values.sum(axis, dtype=dtype_sum)\n--&gt; 720     the_sum = _ensure_numeric(the_sum)\n    721 \n\n/usr/local/lib/python3.10/dist-packages/pandas/core/nanops.py in _ensure_numeric(x)\n   1700             # GH#44008, GH#36703 avoid casting e.g. strings to numeric\n-&gt; 1701             raise TypeError(f\"Could not convert string '{x}' to numeric\")\n   1702         try:\n\nTypeError: Could not convert string 'HargraveHillMitchellGerasimovYenMcWilliamsLombardoClarkeOsborneLavineBianchiTylerMartinOkagbueBucchoT'ienClarkHammondBrownlessGlauertPisanoPalermoBallardCavenaghReadPostleBuleyLeonardOnyeoruluOsborneFuDunbabinMauldonParsonsKoWelchChidozieCalabresiZetticciMacDonaldKaodilinakachukwuArthurLiChiaVasinForwoodTaylorMadukweBennelongAlexeevaMacleanChigolumWilkinsonTreacyTaubmanRobinsonHawkinsFuCampbellAshboltRozierOgbonnayaCocciT'aoFordTsaiOnuoraMcDonaldMillerHayLucasSmithPachecoTsaoIfesinachiHughesJessMortonRossiReppertCh'iuFieldingZetticciBoyleWallworkDavidsonO'DonnellAhmedChuangTienHartleySkinnerMcEncroeGordonTs'aiHunterHsiehKnowlesDayTsaoNwabugwuYoungKerrFreemanSeleznyovIkedinachukwuAmosSimmonsRobinsonBianchiChenIbrahimovaNolanScottMonaldoColeAngeloKoTingBlackIkemefunaMorrisonCelisChengOuthwaitePaiMitchellKoFiskChiangHeathDellucciT'angStevensonWeiPisaniMannaRicciCarrFindlayHughesChukwuemekaSwiftRossUspenskyCookNewboldHeHiltonSunEvansPisanoAnkudinovLewisKirbyMartinHsiaWesterbergKryukovaSeleznevaFreemanLoMacleodPisanoMacartneyLuWaltonBrookesShihUkaegbunamDavideBurnsHanReichardPriceRitchieMackenziePendergrassEvansBillsonTengObialoLinMcKayRickardsBegumOnyinyechukwukaMaOkwuadigboChanGrecoLombardiAlexandrovaFallaciMaiStoutDuncanCrawfordGetherLarionovaPaiCraigCh'iuRahmanMcMillanPickeringMiramsMcIntyrePagnottoFengDonaldsonChambersMarceloEjimoforSageseNapolitaniWallaceSmallBledsoeWertheimP'anAchebeRussoMaccallumWatkinsMitchelFerdinandChin...\n\nThe above exception was the direct cause of the following exception:\n\nTypeError                                 Traceback (most recent call last)\n&lt;ipython-input-4-c6a351abe19c&gt; in &lt;cell line: 26&gt;()\n     24 \n     25 # Cluster profiles\n---&gt; 26 cluster_profiles = data.groupby('Cluster').mean()\n     27 print(cluster_profiles)\n\n/usr/local/lib/python3.10/dist-packages/pandas/core/groupby/groupby.py in mean(self, numeric_only, engine, engine_kwargs)\n   2450             )\n   2451         else:\n-&gt; 2452             result = self._cython_agg_general(\n   2453                 \"mean\",\n   2454                 alt=lambda x: Series(x, copy=False).mean(numeric_only=numeric_only),\n\n/usr/local/lib/python3.10/dist-packages/pandas/core/groupby/groupby.py in _cython_agg_general(self, how, alt, numeric_only, min_count, **kwargs)\n   1996             return result\n   1997 \n-&gt; 1998         new_mgr = data.grouped_reduce(array_func)\n   1999         res = self._wrap_agged_manager(new_mgr)\n   2000         if how in [\"idxmin\", \"idxmax\"]:\n\n/usr/local/lib/python3.10/dist-packages/pandas/core/internals/managers.py in grouped_reduce(self, func)\n   1467                 #  while others do not.\n   1468                 for sb in blk._split():\n-&gt; 1469                     applied = sb.apply(func)\n   1470                     result_blocks = extend_blocks(applied, result_blocks)\n   1471             else:\n\n/usr/local/lib/python3.10/dist-packages/pandas/core/internals/blocks.py in apply(self, func, **kwargs)\n    391         one\n    392         \"\"\"\n--&gt; 393         result = func(self.values, **kwargs)\n    394 \n    395         result = maybe_coerce_values(result)\n\n/usr/local/lib/python3.10/dist-packages/pandas/core/groupby/groupby.py in array_func(values)\n   1993 \n   1994             assert alt is not None\n-&gt; 1995             result = self._agg_py_fallback(how, values, ndim=data.ndim, alt=alt)\n   1996             return result\n   1997 \n\n/usr/local/lib/python3.10/dist-packages/pandas/core/groupby/groupby.py in _agg_py_fallback(self, how, values, ndim, alt)\n   1944             msg = f\"agg function failed [how-&gt;{how},dtype-&gt;{ser.dtype}]\"\n   1945             # preserve the kind of exception that raised\n-&gt; 1946             raise type(err)(msg) from err\n   1947 \n   1948         if ser.dtype == object:\n\nTypeError: agg function failed [how-&gt;mean,dtype-&gt;object]\n\n\n\n\n# Import necessary libraries\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.cluster import KMeans\nfrom sklearn.decomposition import PCA\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Load the dataset\ndata = pd.read_csv('bank_churn.csv')  # Replace with your dataset file path\n\n# Preprocessing for clustering\n# Drop irrelevant columns and encode categorical variables\ndata['Geography'] = data['Geography'].astype('category').cat.codes\ndata['Gender'] = data['Gender'].astype('category').cat.codes\nX = data.drop(['CustomerId', 'Surname', 'Exited'], axis=1)  # Keep only numerical features\n\n# Standardize the features\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\n# K-Means Clustering\n# Define the optimal number of clusters using the Elbow Method\ninertia = []\nrange_n_clusters = range(1, 11)\nfor k in range_n_clusters:\n    kmeans = KMeans(n_clusters=k, random_state=42)\n    kmeans.fit(X_scaled)\n    inertia.append(kmeans.inertia_)\n\n# Plot the Elbow Method\nplt.figure(figsize=(8, 6))\nplt.plot(range_n_clusters, inertia, marker='o')\nplt.title('Elbow Method for Optimal Number of Clusters')\nplt.xlabel('Number of Clusters (k)')\nplt.ylabel('Inertia')\nplt.show()\n\n# Choose the optimal k (based on the elbow plot) and fit K-Means\noptimal_k = 4  # Example, adjust based on the elbow plot\nkmeans = KMeans(n_clusters=optimal_k, random_state=42)\ndata['Cluster'] = kmeans.fit_predict(X_scaled)\n\n# Visualize the clusters using PCA for dimensionality reduction\npca = PCA(n_components=2)\nX_pca = pca.fit_transform(X_scaled)\n\nplt.figure(figsize=(10, 6))\nsns.scatterplot(x=X_pca[:, 0], y=X_pca[:, 1], hue=data['Cluster'], palette='viridis', s=60)\nplt.title('Customer Segments (PCA Visualization)')\nplt.xlabel('Principal Component 1')\nplt.ylabel('Principal Component 2')\nplt.legend(title='Cluster')\nplt.show()\n\n# Ensure only numeric columns are included in the analysis\nnumeric_data = data.select_dtypes(include=[float, int])\n\n# Include the cluster column for grouping\nnumeric_data['Cluster'] = data['Cluster']\n\n# Compute cluster profiles\ncluster_profiles = numeric_data.groupby('Cluster').mean()\n\nprint(\"Cluster Profiles:\\n\", cluster_profiles)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCluster Profiles:\n            CustomerId  CreditScore        Age    Tenure        Balance  \\\nCluster                                                                  \n0        1.569082e+07   650.592581  39.685641  4.929325  103679.746658   \n1        1.569068e+07   650.840863  37.984534  5.075295    9411.432112   \n2        1.569022e+07   649.755751  39.240903  4.984944  105665.965926   \n3        1.569228e+07   650.964444  38.502716  5.098765   81422.771284   \n\n         NumOfProducts  HasCrCard  IsActiveMember  EstimatedSalary    Exited  \nCluster                                                                       \n0             1.266390   0.701311        0.494404    100726.031871  0.291653  \n1             2.121286   0.715100        0.530729     99748.752515  0.118030  \n2             1.128816   0.706399        0.501464     99839.175186  0.229611  \n3             1.694321   0.699259        0.544198     99819.231778  0.141235  \n\n\n\n# Import necessary libraries\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.metrics import classification_report, accuracy_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\n\n# Step 1: Load dataset\ndata = pd.read_csv('bank_churn.csv')  # Replace with your dataset file path\n\n# Step 2: Data Preprocessing\n# Encode categorical variables\nle_geography = LabelEncoder()\nle_gender = LabelEncoder()\ndata['Geography'] = le_geography.fit_transform(data['Geography'])\ndata['Gender'] = le_gender.fit_transform(data['Gender'])\n\n# Define features (X) and target (y)\nX = data.drop(['CustomerId', 'Surname', 'Exited'], axis=1)  # Drop irrelevant columns\ny = data['Exited']\n\n# Split dataset into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n\n# Standardize the features\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Step 3: Logistic Regression\nlog_model = LogisticRegression(random_state=42)\nlog_model.fit(X_train_scaled, y_train)\n\ny_pred_log = log_model.predict(X_test_scaled)\n\nprint(\"Logistic Regression Classification Report:\\n\", classification_report(y_test, y_pred_log))\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred_log))\n\n# Step 4: Naive Bayes\nnb_model = GaussianNB()\nnb_model.fit(X_train_scaled, y_train)\n\ny_pred_nb = nb_model.predict(X_test_scaled)\n\nprint(\"Naive Bayes Classification Report:\\n\", classification_report(y_test, y_pred_nb))\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred_nb))\n\n# Step 5: Decision Tree\ndt_model = DecisionTreeClassifier(max_depth=5, random_state=42)\ndt_model.fit(X_train, y_train)\n\ny_pred_dt = dt_model.predict(X_test)\n\nprint(\"Decision Tree Classification Report:\\n\", classification_report(y_test, y_pred_dt))\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred_dt))\n\n\nLogistic Regression Classification Report:\n               precision    recall  f1-score   support\n\n           0       0.82      0.97      0.89      1593\n           1       0.59      0.14      0.23       407\n\n    accuracy                           0.81      2000\n   macro avg       0.70      0.56      0.56      2000\nweighted avg       0.77      0.81      0.75      2000\n\nAccuracy: 0.805\nNaive Bayes Classification Report:\n               precision    recall  f1-score   support\n\n           0       0.83      0.98      0.90      1593\n           1       0.76      0.24      0.36       407\n\n    accuracy                           0.83      2000\n   macro avg       0.79      0.61      0.63      2000\nweighted avg       0.82      0.83      0.79      2000\n\nAccuracy: 0.829\nDecision Tree Classification Report:\n               precision    recall  f1-score   support\n\n           0       0.86      0.98      0.91      1593\n           1       0.80      0.37      0.51       407\n\n    accuracy                           0.85      2000\n   macro avg       0.83      0.68      0.71      2000\nweighted avg       0.85      0.85      0.83      2000\n\nAccuracy: 0.854\n\n\n\n# Ivy part\npreprocessed_data = pd.read_csv('preprocessed_data.csv')\n# Import required libraries\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nimport pandas as pd\n\n# Split the data into features (X) and target (y)\nX = preprocessed_data.drop('Exited', axis=1)\ny = preprocessed_data['Exited']\n\n# Split the dataset into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n\n# Dictionary to store model results\nmodel_results = {}\n\n# Function to train and evaluate models\ndef train_and_evaluate_model(model, model_name):\n    # Train the model\n    model.fit(X_train, y_train)\n    # Make predictions\n    y_pred = model.predict(X_test)\n    # Calculate accuracy\n    acc = accuracy_score(y_test, y_pred)\n    # Confusion Matrix\n    conf_matrix = confusion_matrix(y_test, y_pred)\n    # Classification Report\n    class_report = classification_report(y_test, y_pred)\n    # Store results\n    model_results[model_name] = {\n        \"Accuracy\": acc,\n        \"Confusion Matrix\": conf_matrix,\n        \"Classification Report\": class_report\n    }\n    return model\n\n# Train and evaluate models\n# Random Forest\nrf_model = train_and_evaluate_model(RandomForestClassifier(random_state=42), \"Random Forest\")\n\n# Logistic Regression\nlr_model = train_and_evaluate_model(LogisticRegression(max_iter=500, random_state=42), \"Logistic Regression\")\n\n# Naive Bayes\nnb_model = train_and_evaluate_model(GaussianNB(), \"Naive Bayes\")\n\n# Decision Tree\ndt_model = train_and_evaluate_model(DecisionTreeClassifier(random_state=42), \"Decision Tree\")\n\n# Display results for each model\nfor model_name, results in model_results.items():\n    print(f\"--- {model_name} ---\")\n    print(f\"Accuracy: {results['Accuracy']}\")\n    #print(f\"Confusion Matrix:\\n{results['Confusion Matrix']}\")\n    print(f\"Classification Report:\\n{results['Classification Report']}\")\n    print(\"\\n\")\n\n--- Random Forest ---\nAccuracy: 0.8645\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.88      0.97      0.92      1593\n           1       0.78      0.46      0.58       407\n\n    accuracy                           0.86      2000\n   macro avg       0.83      0.71      0.75      2000\nweighted avg       0.86      0.86      0.85      2000\n\n\n\n--- Logistic Regression ---\nAccuracy: 0.8095\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.82      0.97      0.89      1593\n           1       0.60      0.19      0.29       407\n\n    accuracy                           0.81      2000\n   macro avg       0.71      0.58      0.59      2000\nweighted avg       0.78      0.81      0.77      2000\n\n\n\n--- Naive Bayes ---\nAccuracy: 0.7865\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.80      0.97      0.88      1593\n           1       0.36      0.06      0.11       407\n\n    accuracy                           0.79      2000\n   macro avg       0.58      0.52      0.49      2000\nweighted avg       0.71      0.79      0.72      2000\n\n\n\n--- Decision Tree ---\nAccuracy: 0.783\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.87      0.85      0.86      1593\n           1       0.47      0.51      0.49       407\n\n    accuracy                           0.78      2000\n   macro avg       0.67      0.68      0.68      2000\nweighted avg       0.79      0.78      0.79      2000\n\n\n\n\n\n/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n\n\n\n# Ivy part\n# # SMOTE\n# Import required libraries\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nimport pandas as pd\n\n# Split the data into features (X) and target (y)\nX = preprocessed_data.drop('Exited', axis=1)\ny = preprocessed_data['Exited']\n\n# Apply SMOTE to balance the dataset\nsmote = SMOTE(random_state=42)\nX_resampled, y_resampled = smote.fit_resample(X, y)\n\n# Split the resampled dataset into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(\n    X_resampled, y_resampled, test_size=0.2, random_state=42, stratify=y_resampled\n)\n\n# Dictionary to store model results\nmodel_results_smote = {}\n\n# Function to train and evaluate models\ndef train_and_evaluate_model(model, model_name):\n    # Train the model\n    model.fit(X_train, y_train)\n    # Make predictions\n    y_pred = model.predict(X_test)\n    # Calculate accuracy\n    acc = accuracy_score(y_test, y_pred)\n    # Confusion Matrix\n    conf_matrix = confusion_matrix(y_test, y_pred)\n    # Classification Report\n    class_report = classification_report(y_test, y_pred)\n    # Store results\n    model_results_smote[model_name] = {\n        \"Accuracy\": acc,\n        \"Confusion Matrix\": conf_matrix,\n        \"Classification Report\": class_report\n    }\n    return model\n\n# Train and evaluate models\n# Random Forest\nrf_model_smote = train_and_evaluate_model(RandomForestClassifier(random_state=42), \"Random Forest (SMOTE)\")\n\n# Logistic Regression\nlr_model_smote = train_and_evaluate_model(LogisticRegression(max_iter=500, random_state=42), \"Logistic Regression (SMOTE)\")\n\n# Naive Bayes\nnb_model_smote = train_and_evaluate_model(GaussianNB(), \"Naive Bayes (SMOTE)\")\n\n# Decision Tree\ndt_model_smote = train_and_evaluate_model(DecisionTreeClassifier(random_state=42), \"Decision Tree (SMOTE)\")\n\n# Display results for each model\nfor model_name, results in model_results_smote.items():\n    print(f\"--- {model_name} ---\")\n    print(f\"Accuracy: {results['Accuracy']}\")\n    print(f\"Confusion Matrix:\\n{results['Confusion Matrix']}\")\n    print(f\"Classification Report:\\n{results['Classification Report']}\")\n    print(\"\\n\")\n\n/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n\n\n--- Random Forest (SMOTE) ---\nAccuracy: 0.8612680477087257\nConfusion Matrix:\n[[1393  200]\n [ 242 1351]]\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.85      0.87      0.86      1593\n           1       0.87      0.85      0.86      1593\n\n    accuracy                           0.86      3186\n   macro avg       0.86      0.86      0.86      3186\nweighted avg       0.86      0.86      0.86      3186\n\n\n\n--- Logistic Regression (SMOTE) ---\nAccuracy: 0.7727558066541117\nConfusion Matrix:\n[[1239  354]\n [ 370 1223]]\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.77      0.78      0.77      1593\n           1       0.78      0.77      0.77      1593\n\n    accuracy                           0.77      3186\n   macro avg       0.77      0.77      0.77      3186\nweighted avg       0.77      0.77      0.77      3186\n\n\n\n--- Naive Bayes (SMOTE) ---\nAccuracy: 0.7115505335844319\nConfusion Matrix:\n[[1084  509]\n [ 410 1183]]\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.73      0.68      0.70      1593\n           1       0.70      0.74      0.72      1593\n\n    accuracy                           0.71      3186\n   macro avg       0.71      0.71      0.71      3186\nweighted avg       0.71      0.71      0.71      3186\n\n\n\n--- Decision Tree (SMOTE) ---\nAccuracy: 0.7875078468298807\nConfusion Matrix:\n[[1228  365]\n [ 312 1281]]\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.80      0.77      0.78      1593\n           1       0.78      0.80      0.79      1593\n\n    accuracy                           0.79      3186\n   macro avg       0.79      0.79      0.79      3186\nweighted avg       0.79      0.79      0.79      3186\n\n\n\n\n\n\n#Jess\n# L1 regularization on logistic regression\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy.stats import ttest_ind, chi2_contingency\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report\n\npreprocessed_data = pd.read_csv('/content/preprocessed_data.csv')\n# Import required libraries\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nimport pandas as pd\n\n# Split the data into features (X) and target (y)\nX = preprocessed_data.drop('Exited', axis=1)\ny = preprocessed_data['Exited']\n\n# Split the dataset into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n\n# Dictionary to store model results\nmodel_results = {}\n\n# Function to train and evaluate models\ndef train_and_evaluate_model(model, model_name):\n    # Train the model\n    model.fit(X_train, y_train)\n    # Make predictions\n    y_pred = model.predict(X_test)\n    # Calculate accuracy\n    acc = accuracy_score(y_test, y_pred)\n    # Confusion Matrix\n    conf_matrix = confusion_matrix(y_test, y_pred)\n    # Classification Report\n    class_report = classification_report(y_test, y_pred)\n    # Store results\n    model_results[model_name] = {\n        \"Accuracy\": acc,\n        \"Confusion Matrix\": conf_matrix,\n        \"Classification Report\": class_report\n    }\n    return model\n\n# Logistic Regression with L1 Regularization\nlr_l1_model = train_and_evaluate_model(\n    LogisticRegression(\n        penalty='l1',  # Use L1 regularization\n        solver='liblinear',  # Required solver for L1 regularization\n        max_iter=500,\n        random_state=42\n    ),\n    \"Logistic Regression (L1 Regularization)\"\n)\n\n\n# Train and evaluate models\n# Random Forest\nrf_model = train_and_evaluate_model(RandomForestClassifier(random_state=42), \"Random Forest\")\n\n# Logistic Regression\nlr_l1_model = train_and_evaluate_model(\n    LogisticRegression(penalty='l1', solver='liblinear', max_iter=500, random_state=42),\n    \"Logistic Regression (L1 Regularization)\"\n)\n\n# Naive Bayes\nnb_model = train_and_evaluate_model(GaussianNB(), \"Naive Bayes\")\nfrom sklearn.model_selection import GridSearchCV\n\n# Decision Tree with Pruning\ndt_pruned_model = train_and_evaluate_model(\n    DecisionTreeClassifier(max_depth=5, min_samples_split=10, min_samples_leaf=5, random_state=42),\n    \"Decision Tree (Pruned)\"\n)\n\n\n# Display results for each model\nfor model_name, results in model_results.items():\n    print(f\"--- {model_name} ---\")\n    print(f\"Accuracy: {results['Accuracy']}\")\n    #print(f\"Confusion Matrix:\\n{results['Confusion Matrix']}\")\n    print(f\"Classification Report:\\n{results['Classification Report']}\")\n    print(\"\\n\")\n\n--- Logistic Regression (L1 Regularization) ---\nAccuracy: 0.8085\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.82      0.97      0.89      1593\n           1       0.60      0.18      0.28       407\n\n    accuracy                           0.81      2000\n   macro avg       0.71      0.58      0.59      2000\nweighted avg       0.78      0.81      0.77      2000\n\n\n\n--- Random Forest ---\nAccuracy: 0.8645\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.88      0.97      0.92      1593\n           1       0.78      0.46      0.58       407\n\n    accuracy                           0.86      2000\n   macro avg       0.83      0.71      0.75      2000\nweighted avg       0.86      0.86      0.85      2000\n\n\n\n--- Naive Bayes ---\nAccuracy: 0.7865\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.80      0.97      0.88      1593\n           1       0.36      0.06      0.11       407\n\n    accuracy                           0.79      2000\n   macro avg       0.58      0.52      0.49      2000\nweighted avg       0.71      0.79      0.72      2000\n\n\n\n--- Decision Tree (Pruned) ---\nAccuracy: 0.856\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.86      0.97      0.91      1593\n           1       0.79      0.40      0.53       407\n\n    accuracy                           0.86      2000\n   macro avg       0.83      0.69      0.72      2000\nweighted avg       0.85      0.86      0.84      2000\n\n\n\n\n\n\n#Jess\n# PCA for Random Forest\nfrom sklearn.decomposition import PCA\nfrom sklearn.pipeline import Pipeline\n\n# Number of principal components to retain (e.g., retain 95% variance or a fixed number of components)\nn_components = 10  # Adjust based on your dataset\n\n# Create a pipeline with PCA and Random Forest\npipeline = Pipeline([\n    ('pca', PCA(n_components=n_components, random_state=42)),\n    ('rf', RandomForestClassifier(random_state=42))\n])\n\n# Train the pipeline\npipeline.fit(X_train, y_train)\n\n# Make predictions\ny_pred = pipeline.predict(X_test)\n\n# Evaluate the model\nacc = accuracy_score(y_test, y_pred)\nconf_matrix = confusion_matrix(y_test, y_pred)\nclass_report = classification_report(y_test, y_pred)\n\n# Display results\nprint(\"--- Random Forest with PCA ---\")\nprint(f\"Accuracy: {acc}\")\nprint(f\"Confusion Matrix:\\n{conf_matrix}\")\nprint(f\"Classification Report:\\n{class_report}\")\n\n\n\n--- Random Forest with PCA ---\nAccuracy: 0.8545\nConfusion Matrix:\n[[1519   74]\n [ 217  190]]\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.88      0.95      0.91      1593\n           1       0.72      0.47      0.57       407\n\n    accuracy                           0.85      2000\n   macro avg       0.80      0.71      0.74      2000\nweighted avg       0.84      0.85      0.84      2000\n\n\n\n\n#Jess\n# PCA for Naive Bayes\nfrom sklearn.decomposition import PCA\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n\n# Number of principal components to retain\nn_components = 10  # Adjust based on dataset\n\n# Create a pipeline with PCA and Naive Bayes\npipeline = Pipeline([\n    ('pca', PCA(n_components=n_components, random_state=42)),\n    ('nb', GaussianNB())\n])\n\n# Train the pipeline\npipeline.fit(X_train, y_train)\n\n# Make predictions\ny_pred = pipeline.predict(X_test)\n\n# Evaluate the model\nacc = accuracy_score(y_test, y_pred)\nconf_matrix = confusion_matrix(y_test, y_pred)\nclass_report = classification_report(y_test, y_pred)\n\n# Display results\nprint(\"--- Naive Bayes with PCA ---\")\nprint(f\"Accuracy: {acc}\")\nprint(f\"Confusion Matrix:\\n{conf_matrix}\")\nprint(f\"Classification Report:\\n{class_report}\")\n\n--- Naive Bayes with PCA ---\nAccuracy: 0.783\nConfusion Matrix:\n[[1547   46]\n [ 388   19]]\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.80      0.97      0.88      1593\n           1       0.29      0.05      0.08       407\n\n    accuracy                           0.78      2000\n   macro avg       0.55      0.51      0.48      2000\nweighted avg       0.70      0.78      0.71      2000\n\n\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix\n\ndef plot_confusion_matrix(y_test, y_pred, model_name):\n    \"\"\"Plot confusion matrix as a heatmap.\"\"\"\n    cm = confusion_matrix(y_test, y_pred)\n    plt.figure(figsize=(8, 6))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['No Churn', 'Churn'], yticklabels=['No Churn', 'Churn'])\n    plt.title(f'Confusion Matrix for {model_name}')\n    plt.xlabel('Predicted')\n    plt.ylabel('Actual')\n    plt.show()\n\n\n# Confusion Matrix for Logistic Regression\nplot_confusion_matrix(y_test, y_pred_log, \"Logistic Regression\")\n\n# Logistic Regression Feature Importance (Coefficients)\ncoefficients = pd.DataFrame({\n    'Feature': X.columns,\n    'Coefficient': log_model.coef_[0]\n}).sort_values(by='Coefficient', ascending=False)\n\n# Plot coefficients\nplt.figure(figsize=(10, 6))\nsns.barplot(x='Coefficient', y='Feature', data=coefficients, palette='viridis')\nplt.title('Feature Importance (Logistic Regression Coefficients)')\nplt.xlabel('Coefficient Value')\nplt.ylabel('Feature')\nplt.show()\n\n\n\n\n\n\n\n\nFutureWarning: \n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n\n  sns.barplot(x='Coefficient', y='Feature', data=coefficients, palette='viridis')\n\n\n\n\n\n\n\n\n\n\n# Confusion Matrix for Naive Bayes\nplot_confusion_matrix(y_test, y_pred_nb, \"Naive Bayes\")\n\n# Naive Bayes does not provide direct feature importance visualization.\n# You can interpret probabilities, but this is not visualized in standard models.\n\n\n\n\n\n\n\n\n\nfrom sklearn.tree import plot_tree\n\n# Confusion Matrix for Decision Tree\nplot_confusion_matrix(y_test, y_pred_dt, \"Decision Tree\")\n\n# Visualize Decision Tree\nplt.figure(figsize=(20, 10))\nplot_tree(dt_model, feature_names=X.columns, class_names=['No Churn', 'Churn'], filled=True)\nplt.title(\"Decision Tree Visualization\")\nplt.show()\n\n# Feature Importance for Decision Tree\ndt_importance = pd.DataFrame({\n    'Feature': X.columns,\n    'Importance': dt_model.feature_importances_\n}).sort_values(by='Importance', ascending=False)\n\n# Plot feature importance\nplt.figure(figsize=(10, 6))\nsns.barplot(x='Importance', y='Feature', data=dt_importance, palette='coolwarm')\nplt.title('Feature Importance (Decision Tree)')\nplt.xlabel('Importance Score')\nplt.ylabel('Feature')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFutureWarning: \n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n\n  sns.barplot(x='Importance', y='Feature', data=dt_importance, palette='coolwarm')\n\n\n\n\n\n\n\n\n\n\n# Calculate mean and variance of 'CreditScore' for each class in the target variable 'Exited'\ncredit_score_stats = data.groupby('Exited')['CreditScore'].agg(['mean', 'var'])\n\nclass_probabilities = data['Exited'].value_counts(normalize=True).rename(\"P(Class)\").sort_index()\ncredit_score_stats['P(Class)'] = class_probabilities\n\ncredit_score_stats\n\n\n  \n    \n\n\n\n\n\n\nmean\nvar\nP(Class)\n\n\nExited\n\n\n\n\n\n\n\n0\n651.853196\n9149.656542\n0.7963\n\n\n1\n645.351497\n10064.403894\n0.2037\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n\n  \n    \n    \n\n  \n    \n  \n    \n    \n  \n\n    \n  \n\n\n\n#P(Geography|Exited)\ngeo_exited_counts = data.groupby(['Geography', 'Exited']).size()\nexited_counts = data['Exited'].value_counts()\ngeo_given_exited = geo_exited_counts / exited_counts\ngeo_given_exited_table = geo_given_exited.unstack()\n\nprint(geo_given_exited_table)\n\nExited            0         1\nGeography                    \n0          0.527942  0.397644\n1          0.212859  0.399607\n2          0.259199  0.202749\n\n\n\n#P(Balance|Exited)\nimport numpy as np\ndef gaussian_probability(x, mean, var):\n    return (1 / np.sqrt(2 * np.pi * var)) * np.exp(-((x - mean) ** 2) / (2 * var))\n\nbalance_stats = data.groupby('Exited')['Balance'].agg(['mean', 'var'])\n\n#Specify a balance value for which to calculate the probabilities\nbalance_value = 50000  # Example balance value\n\nbalance_given_exited = {\n    class_label: gaussian_probability(balance_value, row['mean'], row['var'])\n    for class_label, row in balance_stats.iterrows()\n}\n\nprint(balance_given_exited)\n\n{0: 5.945340348787947e-06, 1: 5.333952035061307e-06}\n\n\n\n#P(Age|Exited)\nimport numpy as np\ndef gaussian_probability(x, mean, var):\n    return (1 / np.sqrt(2 * np.pi * var)) * np.exp(-((x - mean) ** 2) / (2 * var))\n\nage_stats = data.groupby('Exited')['Age'].agg(['mean', 'var'])\n\n#Specify an age value for which to calculate the probabilities\nage_value = 40  # Example age value\n\nage_given_exited = {\n    class_label: gaussian_probability(age_value, row['mean'], row['var'])\n    for class_label, row in age_stats.iterrows()\n}\n\nprint(age_given_exited)\n\n{0: 0.038130613680163516, 1: 0.03614527361626094}\n\n\n\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# 1. ë°ì´í„° ë¡œë“œ\nfile_path = '/content/Bank_Churn.csv'  # ì ì ˆí•œ íŒŒì¼ ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš”\ndata = pd.read_csv(file_path)\n\n# 2. ê·¸ë˜í”„ ìŠ¤íƒ€ì¼ ì„¤ì •\nsns.set_style(\"whitegrid\")\n\n# 3. ê·¸ë˜í”„ ìƒì„±\nfig, axes = plt.subplots(2, 2, figsize=(14, 10))  # 2x2 ì„œë¸Œí”Œë¡¯\n\n# ìˆ«ì ê°’ í‘œì‹œ í•¨ìˆ˜ ì •ì˜\ndef add_counts(ax):\n    \"\"\"ë§‰ëŒ€ ìœ„ì— ìˆ«ì ê°’ ì¶”ê°€\"\"\"\n    for container in ax.containers:\n        ax.bar_label(container, fmt='%d', label_type='edge', fontsize=9, padding=3)\n\n# (a) Gender vs Exited\nax = sns.countplot(x='Gender', hue='Exited', data=data, ax=axes[0, 0], palette='coolwarm')\nadd_counts(ax)\naxes[0, 0].set_title(\"(a) Gender vs Exited\")\naxes[0, 0].set_xlabel(\"Gender\")\naxes[0, 0].set_ylabel(\"Count\")\n\n# (b) HasCrCard vs Exited\nax = sns.countplot(x='HasCrCard', hue='Exited', data=data, ax=axes[0, 1], palette='coolwarm')\nadd_counts(ax)\naxes[0, 1].set_title(\"(b) HasCrCard vs Exited\")\naxes[0, 1].set_xlabel(\"HasCrCard\")\naxes[0, 1].set_ylabel(\"Count\")\n\n# (c) IsActiveMember vs Exited\nax = sns.countplot(x='IsActiveMember', hue='Exited', data=data, ax=axes[1, 0], palette='coolwarm')\nadd_counts(ax)\naxes[1, 0].set_title(\"(c) IsActiveMember vs Exited\")\naxes[1, 0].set_xlabel(\"IsActiveMember\")\naxes[1, 0].set_ylabel(\"Count\")\n\n# (d) Geography (Countries) vs Exited\nax = sns.countplot(x='Geography', hue='Exited', data=data, ax=axes[1, 1], palette='coolwarm')\nadd_counts(ax)\naxes[1, 1].set_title(\"(d) Geography vs Exited\")\naxes[1, 1].set_xlabel(\"Countries\")\naxes[1, 1].set_ylabel(\"Count\")\n\n# 4. ë ˆì´ì•„ì›ƒ ì¡°ì • ë° ì¶œë ¥\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n# Import necessary libraries\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\n\n# Load the dataset\ndata = pd.read_csv('bank_churn.csv')  # Replace with your dataset file path\n\n# Encode categorical variables\nle_geography = LabelEncoder()\nle_gender = LabelEncoder()\ndata['Geography'] = le_geography.fit_transform(data['Geography'])\ndata['Gender'] = le_gender.fit_transform(data['Gender'])\n\n# Define features (X) and target (y)\nX = data.drop(['CustomerId', 'Surname', 'Exited'], axis=1)  # Drop irrelevant columns\ny = data['Exited']\n\n# Split dataset into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n\n# Standardize the features\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Train Logistic Regression Model\nlog_model = LogisticRegression(random_state=42, max_iter=500)\nlog_model.fit(X_train_scaled, y_train)\n\n# Predictions\ny_pred_log = log_model.predict(X_test_scaled)\n\n# Confusion Matrix\ncm_log = confusion_matrix(y_test, y_pred_log)\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm_log, annot=True, fmt='d', cmap='Blues', xticklabels=['No Churn', 'Churn'], yticklabels=['No Churn', 'Churn'])\nplt.title('Confusion Matrix - Logistic Regression')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.show()\n\n# Classification Report\nprint(\"Classification Report - Logistic Regression:\\n\", classification_report(y_test, y_pred_log))\n\n# Feature Importance (Coefficients)\ncoefficients = pd.DataFrame({\n    'Feature': X.columns,\n    'Coefficient': log_model.coef_[0]\n}).sort_values(by='Coefficient', ascending=False)\n\n# Plot Feature Importance\nplt.figure(figsize=(10, 6))\nsns.barplot(x='Coefficient', y='Feature', data=coefficients, palette='viridis')\nplt.title('Feature Importance - Logistic Regression')\nplt.xlabel('Coefficient Value')\nplt.ylabel('Feature')\nplt.show()\n\n\n\n\n\n\n\n\nClassification Report - Logistic Regression:\n               precision    recall  f1-score   support\n\n           0       0.82      0.97      0.89      1593\n           1       0.59      0.14      0.23       407\n\n    accuracy                           0.81      2000\n   macro avg       0.70      0.56      0.56      2000\nweighted avg       0.77      0.81      0.75      2000\n\n\n\nFutureWarning: \n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n\n  sns.barplot(x='Coefficient', y='Feature', data=coefficients, palette='viridis')\n\n\n\n\n\n\n\n\n\n\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Train Random Forest Model\nrf_model = RandomForestClassifier(n_estimators=100, random_state=42)\nrf_model.fit(X_train, y_train)\n\n# Predictions\ny_pred_rf = rf_model.predict(X_test)\n\n# Confusion Matrix\ncm_rf = confusion_matrix(y_test, y_pred_rf)\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm_rf, annot=True, fmt='d', cmap='Blues', xticklabels=['No Churn', 'Churn'], yticklabels=['No Churn', 'Churn'])\nplt.title('Confusion Matrix - Random Forest')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.show()\n\n# Classification Report\nprint(\"Classification Report - Random Forest:\\n\", classification_report(y_test, y_pred_rf))\n\n# Feature Importance\nrf_importances = pd.DataFrame({\n    'Feature': X.columns,\n    'Importance': rf_model.feature_importances_\n}).sort_values(by='Importance', ascending=False)\n\n# Plot Feature Importance\nplt.figure(figsize=(10, 6))\nsns.barplot(x='Importance', y='Feature', data=rf_importances, palette='coolwarm')\nplt.title('Feature Importance - Random Forest')\nplt.xlabel('Importance Score')\nplt.ylabel('Feature')\nplt.show()\n\n\n\n\n\n\n\n\nClassification Report - Random Forest:\n               precision    recall  f1-score   support\n\n           0       0.88      0.97      0.92      1593\n           1       0.78      0.46      0.58       407\n\n    accuracy                           0.86      2000\n   macro avg       0.83      0.71      0.75      2000\nweighted avg       0.86      0.86      0.85      2000\n\n\n\nFutureWarning: \n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n\n  sns.barplot(x='Importance', y='Feature', data=rf_importances, palette='coolwarm')"
  },
  {
    "objectID": "projects/Yelp-Restaurant-Rating /yelp-restaurant-ratings-analysis.html",
    "href": "projects/Yelp-Restaurant-Rating /yelp-restaurant-ratings-analysis.html",
    "title": "ğŸ½ï¸ Yelp Restaurant Ratings Analysis",
    "section": "",
    "text": "This project analyzes Yelp restaurant data across California to identify key drivers behind customer ratings and provide actionable insights for small restaurant owners. Using machine learning models and data visualizations, the study reveals how cuisine type, location, and customer feedback influence restaurant success."
  },
  {
    "objectID": "projects/Yelp-Restaurant-Rating /yelp-restaurant-ratings-analysis.html#project-overview",
    "href": "projects/Yelp-Restaurant-Rating /yelp-restaurant-ratings-analysis.html#project-overview",
    "title": "ğŸ½ï¸ Yelp Restaurant Ratings Analysis",
    "section": "",
    "text": "This project analyzes Yelp restaurant data across California to identify key drivers behind customer ratings and provide actionable insights for small restaurant owners. Using machine learning models and data visualizations, the study reveals how cuisine type, location, and customer feedback influence restaurant success."
  },
  {
    "objectID": "projects/Yelp-Restaurant-Rating /yelp-restaurant-ratings-analysis.html#objectives",
    "href": "projects/Yelp-Restaurant-Rating /yelp-restaurant-ratings-analysis.html#objectives",
    "title": "ğŸ½ï¸ Yelp Restaurant Ratings Analysis",
    "section": "ğŸ¯ Objectives",
    "text": "ğŸ¯ Objectives\n\nIdentify popular cuisines and their rating patterns\nUnderstand the impact of location and number of reviews on ratings\nPredict restaurant success using classification models\nSupport small restaurant owners with data-driven strategies"
  },
  {
    "objectID": "projects/Yelp-Restaurant-Rating /yelp-restaurant-ratings-analysis.html#data-methods",
    "href": "projects/Yelp-Restaurant-Rating /yelp-restaurant-ratings-analysis.html#data-methods",
    "title": "ğŸ½ï¸ Yelp Restaurant Ratings Analysis",
    "section": "ğŸ—‚ï¸ Data & Methods",
    "text": "ğŸ—‚ï¸ Data & Methods\n\nData Source: Yelp data scraped via Python (2,177 restaurant entries)\nFeatures: Cuisine type, review count, price range, location (lat/lon), rating\nTools: Python, Pandas, Scikit-learn, Matplotlib\nModels Used: Decision Tree, K-Nearest Neighbor, Random Forest"
  },
  {
    "objectID": "projects/Yelp-Restaurant-Rating /yelp-restaurant-ratings-analysis.html#key-insights",
    "href": "projects/Yelp-Restaurant-Rating /yelp-restaurant-ratings-analysis.html#key-insights",
    "title": "ğŸ½ï¸ Yelp Restaurant Ratings Analysis",
    "section": "ğŸ“Š Key Insights",
    "text": "ğŸ“Š Key Insights\n\nTop Cuisines: Mexican, New American, and Italian are the most popular in California\nMexican Cuisine: Shows wide variability in ratings, indicating inconsistent experiences\nLocation & Review Count Matter: These were the most important predictors in rating performance"
  },
  {
    "objectID": "projects/Yelp-Restaurant-Rating /yelp-restaurant-ratings-analysis.html#model-performance",
    "href": "projects/Yelp-Restaurant-Rating /yelp-restaurant-ratings-analysis.html#model-performance",
    "title": "ğŸ½ï¸ Yelp Restaurant Ratings Analysis",
    "section": "ğŸ¤– Model Performance",
    "text": "ğŸ¤– Model Performance\n\n\n\nModel\nAccuracy\nF1 Score\nPrecision\nRecall\n\n\n\n\nDecision Tree\n61.7%\n0.72\n0.76\n0.69\n\n\nKNN (Tuned)\n64.1%\n0.77\n0.66\n0.93\n\n\nRandom Forest\n71.8%\n0.81\n0.74\n0.89\n\n\n\n\nRandom Forest performed best overall, identifying high-rated restaurants effectively.\nKNN excelled in recall, while Decision Tree had the fewest false positives."
  },
  {
    "objectID": "projects/Yelp-Restaurant-Rating /yelp-restaurant-ratings-analysis.html#business-recommendations",
    "href": "projects/Yelp-Restaurant-Rating /yelp-restaurant-ratings-analysis.html#business-recommendations",
    "title": "ğŸ½ï¸ Yelp Restaurant Ratings Analysis",
    "section": "ğŸ’¼ Business Recommendations",
    "text": "ğŸ’¼ Business Recommendations\n\nLocation Strategy: Choose areas with high traffic or market through social platforms to boost visibility in suburban areas.\nReview Management: Actively solicit and respond to reviews to enhance credibility and ratings.\nQuality Consistency: Standardize food and service quality, especially in cuisines with rating volatility like Mexican."
  },
  {
    "objectID": "projects/Yelp-Restaurant-Rating /yelp-restaurant-ratings-analysis.html#conclusion",
    "href": "projects/Yelp-Restaurant-Rating /yelp-restaurant-ratings-analysis.html#conclusion",
    "title": "ğŸ½ï¸ Yelp Restaurant Ratings Analysis",
    "section": "ğŸ§¾ Conclusion",
    "text": "ğŸ§¾ Conclusion\nThis project highlights how Yelp data can help small restaurants better understand customer behavior and optimize operations. By applying machine learning and analysis techniques, restaurant owners can gain strategic insights into location, cuisine impact, and review managementâ€”ultimately leading to better customer satisfaction and improved performance."
  },
  {
    "objectID": "projects/Yelp-Restaurant-Rating /yelp-restaurant-ratings-analysis.html#github-repository",
    "href": "projects/Yelp-Restaurant-Rating /yelp-restaurant-ratings-analysis.html#github-repository",
    "title": "ğŸ½ï¸ Yelp Restaurant Ratings Analysis",
    "section": "ğŸ“ GitHub Repository",
    "text": "ğŸ“ GitHub Repository\nğŸ‘‰ View Code on GitHub"
  },
  {
    "objectID": "projects/Amazon-Product-Analysis/Team_Obagi_10B_CSA_Project.html",
    "href": "projects/Amazon-Product-Analysis/Team_Obagi_10B_CSA_Project.html",
    "title": "My Portfolio",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport re\nimport nltk\nfrom nltk.sentiment import SentimentIntensityAnalyzer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom google.colab import files\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom wordcloud import WordCloud\n\n\n# Load dataset\ndf = pd.read_csv('/content/amazon.csv')\n\n\n# Display basic info\ndf.info()\ndf.head()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 1465 entries, 0 to 1464\nData columns (total 16 columns):\n #   Column               Non-Null Count  Dtype \n---  ------               --------------  ----- \n 0   product_id           1465 non-null   object\n 1   product_name         1465 non-null   object\n 2   category             1465 non-null   object\n 3   discounted_price     1465 non-null   object\n 4   actual_price         1465 non-null   object\n 5   discount_percentage  1465 non-null   object\n 6   rating               1465 non-null   object\n 7   rating_count         1463 non-null   object\n 8   about_product        1465 non-null   object\n 9   user_id              1465 non-null   object\n 10  user_name            1465 non-null   object\n 11  review_id            1465 non-null   object\n 12  review_title         1465 non-null   object\n 13  review_content       1465 non-null   object\n 14  img_link             1465 non-null   object\n 15  product_link         1465 non-null   object\ndtypes: object(16)\nmemory usage: 183.3+ KB\n\n\n\n  \n    \n\n\n\n\n\n\nproduct_id\nproduct_name\ncategory\ndiscounted_price\nactual_price\ndiscount_percentage\nrating\nrating_count\nabout_product\nuser_id\nuser_name\nreview_id\nreview_title\nreview_content\nimg_link\nproduct_link\n\n\n\n\n0\nB07JW9H4J1\nWayona Nylon Braided USB to Lightning Fast Cha...\nComputers&Accessories|Accessories&Peripherals|...\nâ‚¹399\nâ‚¹1,099\n64%\n4.2\n24,269\nHigh Compatibility : Compatible With iPhone 12...\nAG3D6O4STAQKAY2UVGEUV46KN35Q,AHMY5CWJMMK5BJRBB...\nManav,Adarsh gupta,Sundeep,S.Sayeed Ahmed,jasp...\nR3HXWT0LRP0NMF,R2AJM3LFTLZHFO,R6AQJGUP6P86,R1K...\nSatisfied,Charging is really fast,Value for mo...\nLooks durable Charging is fine tooNo complains...\nhttps://m.media-amazon.com/images/W/WEBP_40237...\nhttps://www.amazon.in/Wayona-Braided-WN3LG1-Sy...\n\n\n1\nB098NS6PVG\nAmbrane Unbreakable 60W / 3A Fast Charging 1.5...\nComputers&Accessories|Accessories&Peripherals|...\nâ‚¹199\nâ‚¹349\n43%\n4.0\n43,994\nCompatible with all Type C enabled devices, be...\nAECPFYFQVRUWC3KGNLJIOREFP5LQ,AGYYVPDD7YG7FYNBX...\nArdKn,Nirbhay kumar,Sagar Viswanathan,Asp,Plac...\nRGIQEG07R9HS2,R1SMWZQ86XIN8U,R2J3Y1WL29GWDE,RY...\nA Good Braided Cable for Your Type C Device,Go...\nI ordered this cable to connect my phone to An...\nhttps://m.media-amazon.com/images/W/WEBP_40237...\nhttps://www.amazon.in/Ambrane-Unbreakable-Char...\n\n\n2\nB096MSW6CT\nSounce Fast Phone Charging Cable & Data Sync U...\nComputers&Accessories|Accessories&Peripherals|...\nâ‚¹199\nâ‚¹1,899\n90%\n3.9\n7,928\nã€ Fast Charger& Data Syncã€‘-With built-in safet...\nAGU3BBQ2V2DDAMOAKGFAWDDQ6QHA,AESFLDV2PT363T2AQ...\nKunal,Himanshu,viswanath,sai niharka,saqib mal...\nR3J3EQQ9TZI5ZJ,R3E7WBGK7ID0KV,RWU79XKQ6I1QF,R2...\nGood speed for earlier versions,Good Product,W...\nNot quite durable and sturdy,https://m.media-a...\nhttps://m.media-amazon.com/images/W/WEBP_40237...\nhttps://www.amazon.in/Sounce-iPhone-Charging-C...\n\n\n3\nB08HDJ86NZ\nboAt Deuce USB 300 2 in 1 Type-C & Micro USB S...\nComputers&Accessories|Accessories&Peripherals|...\nâ‚¹329\nâ‚¹699\n53%\n4.2\n94,363\nThe boAt Deuce USB 300 2 in 1 cable is compati...\nAEWAZDZZJLQUYVOVGBEUKSLXHQ5A,AG5HTSFRRE6NL3M5S...\nOmkar dhale,JD,HEMALATHA,Ajwadh a.,amar singh ...\nR3EEUZKKK9J36I,R3HJVYCLYOY554,REDECAZ7AMPQC,R1...\nGood product,Good one,Nice,Really nice product...\nGood product,long wire,Charges good,Nice,I bou...\nhttps://m.media-amazon.com/images/I/41V5FtEWPk...\nhttps://www.amazon.in/Deuce-300-Resistant-Tang...\n\n\n4\nB08CF3B7N1\nPortronics Konnect L 1.2M Fast Charging 3A 8 P...\nComputers&Accessories|Accessories&Peripherals|...\nâ‚¹154\nâ‚¹399\n61%\n4.2\n16,905\n[CHARGE & SYNC FUNCTION]- This cable comes wit...\nAE3Q6KSUK5P75D5HFYHCRAOLODSA,AFUGIFH5ZAFXRDSZH...\nrahuls6099,Swasat Borah,Ajay Wadke,Pranali,RVK...\nR1BP4L2HH9TFUP,R16PVJEXKV6QZS,R2UPDB81N66T4P,R...\nAs good as original,Decent,Good one for second...\nBought this instead of original apple, does th...\nhttps://m.media-amazon.com/images/W/WEBP_40237...\nhttps://www.amazon.in/Portronics-Konnect-POR-1...\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n\n    \n  \n\n\n\n# Drop unnecessary columns based on project plan\ncolumns_to_keep = ['product_id', 'product_name', 'category','discounted_price','actual_price', 'rating', 'rating_count', 'about_product',\n                   'user_id', 'review_id', 'review_title', 'review_content']\ndf = df[columns_to_keep]\n\n\n# Handle missing values\ndf.dropna(subset=['review_content', 'rating'], inplace=True)\n\n\n# Add review length column\ndf['review_length'] = df['review_content'].apply(lambda x: len(str(x).split()))\n\n\nimport nltk\nnltk.download('stopwords')\nfrom sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n\n[nltk_data] Downloading package stopwords to /root/nltk_data...\n[nltk_data]   Unzipping corpora/stopwords.zip.\n\n\n\nimport nltk\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords # Import stopwords from nltk.corpus\nfrom sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n\n# Define stopwords\nstop_words = set(stopwords.words('english'))\n\n# Add custom stopwords\ncustom_stopwords = [\"product\", \"like\",\"good\",\"easy\",\"use\"]  # Add your specific words\nstop_words.update(custom_stopwords)  # Update stopwords set\n\n# Function to preprocess text\ndef preprocess_text(text):\n    text = text.lower()  # Lowercase\n    text = re.sub(r'\\d+', '', text)  # Remove numbers\n    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n    tokens = text.split()  # Tokenization\n    tokens = [word for word in tokens if word not in stop_words]  # Remove stopwords\n    return ' '.join(tokens)\n\n[nltk_data] Downloading package stopwords to /root/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n\n\n\n# Apply preprocessing\ndf['cleaned_review'] = df['review_content'].astype(str).apply(preprocess_text)\n\n\nreviews = df['cleaned_review']\n\nvectorizer = TfidfVectorizer(min_df=5, max_df=0.8, max_features=5000, stop_words='english')\nX = vectorizer.fit_transform(reviews)\n\n# Get the terms (words) and their corresponding term frequencies (TF)\nterms = vectorizer.get_feature_names_out()\nterm_frequencies = X.sum(axis=0).A1  # Sum across all documents\n\nfrequency_df = pd.DataFrame(list(zip(terms, term_frequencies)), columns=['Word', 'Frequency'])\nfrequency_df = frequency_df.sort_values(by='Frequency', ascending=False)\n\n# Display the top 10 most frequent words\nprint(frequency_df.head(10))\n\n          Word  Frequency\n2519   quality  70.256776\n397      cable  67.148906\n486   charging  51.103816\n2387     price  46.262668\n3589   working  37.917501\n2267     phone  37.902488\n3433     using  36.223175\n242    battery  34.270183\n3346        tv  32.496618\n384        buy  32.475281\n\n\n\n# Initialize Sentiment Analyzer\nnltk.download('vader_lexicon')\nsia = SentimentIntensityAnalyzer()\n\n[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n\n\n\ndef get_sentiment(text):\n    \"\"\"Classifies sentiment as Positive, Neutral, or Negative.\"\"\"\n    score = sia.polarity_scores(text)['compound']\n    if score &gt; 0.05:\n        return 1\n    elif score &lt; -0.05:\n        return -1\n    else:\n        return 0\n\n\n# Apply sentiment analysis\ndf['sentiment'] = df['cleaned_review'].apply(get_sentiment)\n\n\ndf['cleaned_review'].head(5)\n\n\n\n\n\n\n\n\ncleaned_review\n\n\n\n\n0\nlooks durable charging fine toono complainscha...\n\n\n1\nordered cable connect phone android auto car c...\n\n\n2\nquite durable sturdyhttpsmmediaamazoncomimages...\n\n\n3\nproductlong wirecharges goodnicei bought cable...\n\n\n4\nbought instead original apple work rs fast app...\n\n\n\n\ndtype: object\n\n\n\n# Define a mapping dictionary\nsentiment_mapping = {1: \"Positive\", 0: \"Neutral\", -1: \"Negative\"}\n\n# Create a new column with mapped sentiment labels\ndf[\"sentiment_label_text\"] = df[\"sentiment\"].map(sentiment_mapping)\n\n# Display the first few rows\nprint(df[[\"sentiment\", \"sentiment_label_text\"]].head())\n\n   sentiment sentiment_label_text\n0          1             Positive\n1          1             Positive\n2          1             Positive\n3          1             Positive\n4          1             Positive\n\n\n\n# Sentiment distribution\nplt.figure(figsize=(6,4))\nsns.countplot(x='sentiment_label_text', data=df, palette='coolwarm')\nplt.title('Sentiment Distribution')\nplt.show()\n\nFutureWarning: \n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n\n  sns.countplot(x='sentiment_label_text', data=df, palette='coolwarm')\n\n\n\n\n\n\n\n\n\n\n# Review Length vs. Sentiment\nplt.figure(figsize=(8,5))\nsns.boxplot(x='sentiment_label_text', y='review_length', data=df, palette='coolwarm')\nplt.title('Review Length vs. Sentiment')\nplt.show()\n\nFutureWarning: \n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n\n  sns.boxplot(x='sentiment_label_text', y='review_length', data=df, palette='coolwarm')\n\n\n\n\n\n\n\n\n\n\n# Regression Analysis: Review Length vs. Rating\nX = df[['review_length']]\n# Convert 'rating' to numeric, handling errors, and then drop NaNs\ny = pd.to_numeric(df['rating'], errors='coerce').dropna()\n# Filter the DataFrame based on the valid ratings in 'y'\ndf = df[df.index.isin(y.index)]\nX = df[['review_length']]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n\ny_pred = model.predict(X_test)\n\n\n# Regression Metrics\nprint(\"Mean Squared Error:\", mean_squared_error(y_test, y_pred))\nprint(\"R-squared Score:\", r2_score(y_test, y_pred))\n\nMean Squared Error: 0.07705379430653071\nR-squared Score: 0.00699365804788743\n\n\n\n# Plot Regression\nplt.figure(figsize=(8,5))\n# Ensure 'rating' is numeric before plotting\ndf['rating'] = pd.to_numeric(df['rating'], errors='coerce')\ndf = df.dropna(subset=['rating'])  # Drop rows with invalid ratings\nsns.regplot(x=df['review_length'], y=df['rating'], scatter_kws={'alpha':0.3}, line_kws={'color':'red'})\nplt.title('Review Length vs. Rating')\nplt.xlabel('Review Length')\nplt.ylabel('Rating')\nplt.show()\n\n\n\n\n\n\n\n\n\n# Sentiment vs. Product Rating\nplt.figure(figsize=(8,5))\nsns.boxplot(x='sentiment_label_text', y='rating', data=df, palette='coolwarm')\nplt.title('Sentiment vs. Product Rating')\nplt.show()\n\nFutureWarning: \n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n\n  sns.boxplot(x='sentiment_label_text', y='rating', data=df, palette='coolwarm')\n\n\n\n\n\n\n\n\n\n\n# Distribution of Review Lengths by Sentiment\nplt.figure(figsize=(8,5))\nsns.histplot(data=df, x='review_length', hue='sentiment_label_text', bins=30, kde=True, palette='coolwarm')\nplt.title('Distribution of Review Lengths by Sentiment')\nplt.show()\n\n\n\n\n\n\n\n\n\ncorrelation = df[\"review_length\"].corr(df[\"rating\"])\nprint(f\"Correlation between review length and rating: {correlation:.4f}\")\n\nCorrelation between review length and rating: 0.0787\n\n\n\ncorrelation = df[\"review_length\"].corr(df[\"sentiment\"])\nprint(f\"Correlation between review length and sentiment: {correlation:.4f}\")\n\nCorrelation between review length and sentiment: 0.0835\n\n\n\n#Top 5 categories that has the most review\ntop_categories = df['category'].value_counts().head(5)\n\n# Display the top 5 categories with the most reviews\nprint(top_categories)\n\ncategory\nComputers&Accessories|Accessories&Peripherals|Cables&Accessories|Cables|USBCables    233\nElectronics|WearableTechnology|SmartWatches                                           76\nElectronics|Mobiles&Accessories|Smartphones&BasicMobiles|Smartphones                  68\nElectronics|HomeTheater,TV&Video|Televisions|SmartTelevisions                         63\nElectronics|Headphones,Earbuds&Accessories|Headphones|In-Ear                          52\nName: count, dtype: int64\n\n\n\n# Plot the bar chart\nplt.figure(figsize=(10, 6))\nsns.barplot(x=top_categories.values, y=top_categories.index, palette=\"viridis\")\n\n# Add labels and title\nplt.xlabel(\"Number of Reviews\")\nplt.ylabel(\"Category\")\nplt.title(\"Top 5 Categories with Most Reviews\")\nplt.xticks(rotation=45)\nplt.show()\n\nFutureWarning: \n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n\n  sns.barplot(x=top_categories.values, y=top_categories.index, palette=\"viridis\")\n\n\n\n\n\n\n\n\n\n\nprint(df[\"cleaned_review\"].isnull().sum())\nprint(df[\"cleaned_review\"].str.len().sum())\n\nprint(df[\"sentiment\"].value_counts())\n\n0\n1301289\nsentiment\n 1    1344\n-1     101\n 0      19\nName: count, dtype: int64\n\n\n\n# Filter positive reviews\npositive_reviews = df[\"cleaned_review\"].dropna().astype(str)\n\n# Initialize TfidfVectorizer\nvectorizer = TfidfVectorizer(min_df=5, max_df=0.8, max_features=5000,ngram_range=(2,3))\n\n# Fit and transform the positive reviews\ntfidf_matrix = vectorizer.fit_transform(positive_reviews)\n\n# Get feature names (words) and their corresponding TF-IDF scores\nfeature_names = vectorizer.get_feature_names_out()\ntfidf_scores = tfidf_matrix.sum(axis=0).A1  # Sum TF-IDF scores for each word\n\n# Create dictionary of words and their TF-IDF scores\nword_scores = dict(zip(feature_names, tfidf_scores))\n\n# Generate WordCloud\nwordcloud = WordCloud(width=800, height=400, background_color=\"white\", colormap=\"viridis\").generate_from_frequencies(word_scores)\n\n# Plot the WordCloud\nplt.figure(figsize=(10, 5))\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis(\"off\")\nplt.title(\"Positive Reviews WordCloud (TF-IDF)\", fontsize=14)\nplt.show()\n\n\n\n\n\n\n\n\n\n# Filter negative reviews\nnegative_reviews = df[df['sentiment'] == -1]['cleaned_review']\n\n# Vectorize the negative reviews using TfidfVectorizer\nvectorizer = TfidfVectorizer(max_features=5000, ngram_range=(2, 3))\nX = vectorizer.fit_transform(negative_reviews)\n\n# Get the feature names (words/phrases)\nfeature_names = vectorizer.get_feature_names_out()\n\n# Get the tf-idf scores for each feature (word/phrase)\ntfidf_scores = X.sum(axis=0).A1  # Summing scores across all reviews for each feature\n\n# Create a dictionary of words and their corresponding scores\nword_scores = dict(zip(feature_names, tfidf_scores))\n\n# Generate the word cloud\nwordcloud = WordCloud(width=800, height=400, background_color='white', colormap=\"Reds\").generate_from_frequencies(word_scores)\n\n# Plot the word cloud\nplt.figure(figsize=(10, 5))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis('off')\nplt.show()\n\n\n\n\n\n\n\n\n\nfrom sklearn.linear_model import LogisticRegression\n\n# Convert text into numerical vectors using TF-IDF\nvectorizer = TfidfVectorizer(max_features=5000)\nX = vectorizer.fit_transform(df['cleaned_review'])\ny = df['sentiment']\n\n# Split data into training & test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\n# Train a Logistic Regression model\nmodel = LogisticRegression(class_weight='balanced', random_state=42)\nmodel.fit(X_train, y_train)  # Model now gives equal importance to all classes\n\n# Predict sentiment\ny_pred = model.predict(X_test)\n\nprint(pd.Series(y_train).value_counts())\nprint(pd.Series(y_test).value_counts())\n\n# Evaluate model performance\naccuracy = accuracy_score(y_test, y_pred)\nprint(f\"Model Accuracy: {accuracy:.2f}\")\nprint(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n\nsentiment\n 1    944\n-1     69\n 0     11\nName: count, dtype: int64\nsentiment\n 1    400\n-1     32\n 0      8\nName: count, dtype: int64\nModel Accuracy: 0.92\nClassification Report:\n               precision    recall  f1-score   support\n\n          -1       0.83      0.16      0.26        32\n           0       0.00      0.00      0.00         8\n           1       0.92      1.00      0.96       400\n\n    accuracy                           0.92       440\n   macro avg       0.58      0.39      0.41       440\nweighted avg       0.90      0.92      0.89       440\n\n\n\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n\n\n\n# Convert text to numerical features using TF-IDF\nvectorizer = TfidfVectorizer(min_df=5, max_df=0.8, max_features=5000, ngram_range=(3,4))\n\nX = vectorizer.fit_transform(df['cleaned_review'])\n\n# Get feature names\nfeature_names = vectorizer.get_feature_names_out()\nprint(\"Top 10 Features:\", feature_names[:10])\n\nTop 10 Features: ['accessory travelling without' 'accessory travelling without risking'\n 'accuracy feel little' 'accuracy feel little bit' 'accurate near trust'\n 'accurate near trust emergency' 'accurate sensors efficiently'\n 'accurate sensors efficiently worked' 'accurate sensorsbad ui'\n 'accurate sensorsbad ui fonts']\n\n\n\n# Plot the top 10 frequent words\ntop_10_words = frequency_df.head(10)\n\nplt.figure(figsize=(10, 6))\nplt.barh(top_10_words['Word'], top_10_words['Frequency'], color='skyblue')\nplt.xlabel('Frequency')\nplt.title('Top 10 Most Frequent Words')\nplt.gca().invert_yaxis()\nplt.show()\n\n\n\n\n\n\n\n\n\n# Use SMOTE to handle the class imbalance\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.model_selection import train_test_split\n\n# Convert text data into numerical features (e.g., TF-IDF)\nvectorizer = TfidfVectorizer(min_df=5, max_df=0.8, max_features=5000)\nX = vectorizer.fit_transform(df['cleaned_review'])\ny = df['sentiment']\n\n# Split data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\n# Adjust SMOTE to handle small classes\nsmote = SMOTE(sampling_strategy='auto', random_state=42, k_neighbors=min(3, len(y_train.unique()) - 1))\n\nX_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n\n# Check class balance\nprint(pd.Series(y_train_resampled).value_counts())\nprint(pd.Series(y_train).value_counts())\n\nsentiment\n 1    944\n-1    944\n 0    944\nName: count, dtype: int64\nsentiment\n 1    944\n-1     69\n 0     11\nName: count, dtype: int64\n\n\n\n# Machine learning models accuracy after fixing the class imbalance on the train test\n# Train Logistic Regression model\nmodel = LogisticRegression(class_weight='balanced', random_state=42)\nmodel.fit(X_train_resampled, y_train_resampled)\n\n# Predict sentiment\ny_pred = model.predict(X_test)\n\n# Evaluate model performance\naccuracy = accuracy_score(y_test, y_pred)\nprint(f\"Model Accuracy: {accuracy:.2f}\")\nprint(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n\nModel Accuracy: 0.92\nClassification Report:\n               precision    recall  f1-score   support\n\n          -1       1.00      0.16      0.27        32\n           0       0.00      0.00      0.00         8\n           1       0.92      1.00      0.96       400\n\n    accuracy                           0.92       440\n   macro avg       0.64      0.39      0.41       440\nweighted avg       0.91      0.92      0.89       440\n\n\n\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n\n\n\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Train Random Forest\nrf_model = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')\nrf_model.fit(X_train, y_train)\n\n# Predict sentiment\ny_pred_rf_1 = rf_model.predict(X_test)\n\n# Evaluate model performance\naccuracy = accuracy_score(y_test, y_pred_rf_1)\nprint(f\"Model Accuracy: {accuracy:.2f}\")\nprint(\"Classification Report:\\n\", classification_report(y_test, y_pred_rf_1))\n\nModel Accuracy: 0.91\nClassification Report:\n               precision    recall  f1-score   support\n\n          -1       1.00      0.06      0.12        32\n           0       0.00      0.00      0.00         8\n           1       0.91      1.00      0.95       400\n\n    accuracy                           0.91       440\n   macro avg       0.64      0.35      0.36       440\nweighted avg       0.90      0.91      0.88       440\n\n\n\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n\n\n\nfrom sklearn.svm import SVC\n\n# Train SVM\nsvm_model = SVC(kernel='linear', class_weight='balanced', random_state=42)\nsvm_model.fit(X_train_resampled, y_train_resampled)\n\n# Predictions\ny_pred_svm = svm_model.predict(X_test)\n\n# Evaluate model performance\naccuracy = accuracy_score(y_test, y_pred_svm)\nprint(f\"Model Accuracy: {accuracy:.2f}\")\nprint(\"Classification Report:\\n\", classification_report(y_test, y_pred_svm))\n\nModel Accuracy: 0.92\nClassification Report:\n               precision    recall  f1-score   support\n\n          -1       1.00      0.16      0.27        32\n           0       0.00      0.00      0.00         8\n           1       0.92      1.00      0.96       400\n\n    accuracy                           0.92       440\n   macro avg       0.64      0.39      0.41       440\nweighted avg       0.91      0.92      0.89       440\n\n\n\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n\n\n\n#Topic Modeling on Negative Reviews\n#LDA to find topics in negative reviews\nfrom sklearn.decomposition import LatentDirichletAllocation\nfrom sklearn.feature_extraction.text import CountVectorizer\n\nvectorizer = CountVectorizer(max_features=5000, stop_words='english', ngram_range=(2,3))\nX = vectorizer.fit_transform(df[df['sentiment'] == -1]['cleaned_review'])\n\nlda_model = LatentDirichletAllocation(n_components=5, random_state=42)\nlda_model.fit(X)\n\n# Print topics\nfor index, topic in enumerate(lda_model.components_):\n    words = [vectorizer.get_feature_names_out()[i] for i in topic.argsort()[-10:]]\n    print(f\"Topic {index+1}: {', '.join(words)}\")\n\nTopic 1: stopped working, value money, till date, dont buy, charging cable, buy cheap, vacuum mop, worth money, suction power, battery life\nTopic 2: wall hanging hook, addresswhy bad badthey, floor mount, badthey come support, ok smart, buy floor mount, quality poor, bad service, google tv, installation guy\nTopic 3: goodgreat really durablegood, headphone jack, problem earphone jack, able hear, customer care, got delivered, need frequently, quality bad, using months, cord length\nTopic 4: poor quality, smudge proof, switch socket, click time, gas stove, change temperature, picture quality, set minutes, fast charging, charging cable\nTopic 5: worth price, local cable, iam using, worth money, year warranty, remote control, sound quality, quality price, tv mains, picture quality"
  },
  {
    "objectID": "projects/Netflix-Recommendation/NLP_group_8_project.html",
    "href": "projects/Netflix-Recommendation/NLP_group_8_project.html",
    "title": "tfidf",
    "section": "",
    "text": "import pandas as pd\nimport re\n\n# Load dataset\ndf = pd.read_csv('/content/netflix_titles.csv', encoding='ISO-8859-1')\n\n# --------------------------------\n# Step 1: Create 'year' column based on 'rating'\n# --------------------------------\nrating_to_year = {\n    'G': 0, 'PG': 10, 'PG-13': 13, 'R': 17, 'NC-17': 18,\n    'NR': 0, 'UR': 0, 'TV-Y': 0, 'TV-Y7': 7, 'TV-Y7-FV': 7,\n    'TV-G': 0, 'TV-PG': 10, 'TV-14': 14, 'TV-MA': 17\n}\n\n# Map the 'rating' column to the new 'year' column\ndf['year'] = df['rating'].map(rating_to_year).fillna(0).astype(int)\n\n# --------------------------------\n# Step 2: Remove non-English words from 'description'\n# --------------------------------\n# Function to remove non-English words\ndef clean_description(text):\n    if pd.isna(text):  # Handle NaN values\n        return \"\"\n    # Keep only English characters (letters, numbers, punctuation)\n    return re.sub(r'[^a-zA-Z0-9.,!?\\'\" ]', '', text)\n\n# Apply cleaning function to 'description'\ndf['description'] = df['description'].apply(clean_description)\n\n# --------------------------------\n# Display cleaned data\n# --------------------------------\nprint(df[['rating', 'year', 'description']].head(10))\n\n# Optional: Save the cleaned data to a new CSV file\ndf.to_csv('/content/netflix_titles_cleaned.csv', index=False)\n\n  rating  year                                        description\n0  PG-13    13  As her father nears the end of his life, filmm...\n1  TV-MA    17  After crossing paths at a party, a Cape Town t...\n2  TV-MA    17  To protect his family from a powerful drug lor...\n3  TV-MA    17  Feuds, flirtations and toilet talk go down amo...\n4  TV-MA    17  In a city of coaching centers known to train I...\n5  TV-MA    17  The arrival of a charismatic young priest brin...\n6     PG    10  Equestria's divided. But a brighteyed hero bel...\n7  TV-MA    17  On a photo shoot in Ghana, an American model s...\n8  TV-14    14  A talented batch of amateur bakers face off in...\n9  PG-13    13  A woman adjusting to life after a loss contend...\n\n\n\nimport pandas as pd\nimport numpy as np\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom sklearn.preprocessing import MinMaxScaler\n\n\n!pip install matplotlib\nimport matplotlib.pyplot as plt\n\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\nRequirement already satisfied: contourpy&gt;=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\nRequirement already satisfied: cycler&gt;=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: fonttools&gt;=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\nRequirement already satisfied: kiwisolver&gt;=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\nRequirement already satisfied: numpy&gt;=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.0.2)\nRequirement already satisfied: packaging&gt;=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\nRequirement already satisfied: pillow&gt;=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\nRequirement already satisfied: pyparsing&gt;=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\nRequirement already satisfied: python-dateutil&gt;=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\nRequirement already satisfied: six&gt;=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil&gt;=2.7-&gt;matplotlib) (1.17.0)\n\n\n\ndf = pd.read_csv('/content/netflix_titles.csv', encoding='ISO-8859-1')\n\n\n#data = pd.read_csv('/content/netflix_titles.csv', encoding='iso-8859-1')\n\n\n# Drop columns 'Unnamed: 12' to 'Unnamed: 19'\n# df = df.drop(columns=['Unnamed: 12', 'Unnamed: 13', 'Unnamed: 14', 'Unnamed: 15', 'Unnamed: 16', 'Unnamed: 17', 'Unnamed: 18', 'Unnamed: 19','Unnamed: 20', 'Unnamed: 21','Unnamed: 22', 'Unnamed: 23', 'Unnamed: 24', 'Unnamed: 25'])\n# Display the cleaned DataFrame\ndf.head()\n\n\n  \n    \n\n\n\n\n\n\nshow_id\ntype\ntitle\ndirector\ncast\ncountry\ndate_added\nrelease_year\nrating\nduration\nlisted_in\ndescription\n\n\n\n\n0\ns1\nMovie\nDick Johnson Is Dead\nKirsten Johnson\nNaN\nUnited States\n25-Sep-21\n2020\nPG-13\n90 min\nDocumentaries\nAs her father nears the end of his life, filmm...\n\n\n1\ns2\nTV Show\nBlood & Water\nNaN\nAma Qamata, Khosi Ngema, Gail Mabalane, Thaban...\nSouth Africa\n24-Sep-21\n2021\nTV-MA\n2 Seasons\nInternational TV Shows, TV Dramas, TV Mysteries\nAfter crossing paths at a party, a Cape Town t...\n\n\n2\ns3\nTV Show\nGanglands\nJulien Leclercq\nSami Bouajila, Tracy Gotoas, Samuel Jouy, Nabi...\nNaN\n24-Sep-21\n2021\nTV-MA\n1 Season\nCrime TV Shows, International TV Shows, TV Act...\nTo protect his family from a powerful drug lor...\n\n\n3\ns4\nTV Show\nJailbirds New Orleans\nNaN\nNaN\nNaN\n24-Sep-21\n2021\nTV-MA\n1 Season\nDocuseries, Reality TV\nFeuds, flirtations and toilet talk go down amo...\n\n\n4\ns5\nTV Show\nKota Factory\nNaN\nMayur More, Jitendra Kumar, Ranjan Raj, Alam K...\nIndia\n24-Sep-21\n2021\nTV-MA\n2 Seasons\nInternational TV Shows, Romantic TV Shows, TV ...\nIn a city of coaching centers known to train I...\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n\n    \n  \n\n\n\n# Fill missing values with 'Unknown' for director, cast, and country. Flag the missing values without losing any data (we can always drop missing values if wanted)\ndf['director'] = df['director'].fillna('Unknown')\ndf['cast'] = df['cast'].fillna('Unknown')\ndf['country'] = df['country'].fillna('Unknown')\n\n# Drop duplicate rows based on the 'title' column\ndf = df.drop_duplicates(subset=['title'], keep='first')\n\n\nprint(df['rating'].unique())\n\n['PG-13' 'TV-MA' 'PG' 'TV-14' 'TV-PG' 'TV-Y' 'TV-Y7' 'R' 'TV-G' 'G'\n 'NC-17' '74 min' '84 min' '66 min' 'NR' nan 'TV-Y7-FV' 'UR' 'A']\n\n\n\n# rating= {\n#     \"G\": \"age &gt;= 0\",\n#     \"PG\": \"age &gt;= 10\",\n#     \"PG-13\": \"age &gt;= 13\",\n#     \"R\": \"age &gt;= 17\",\n#     \"NC-17\": \"age &gt;= 18\",\n#     \"NR\": \"Unknown\",\n#     \"UR\": \"Unknown\",\n#     \"TV-Y\": \"age &gt;= 0\",\n#     \"TV-Y7\": \"age &gt;= 7\",\n#     \"TV-Y7-FV\": \"age &gt;= 7\",\n#     \"TV-G\": \"age &gt;= 0\",\n#     \"TV-PG\": \"age &gt;= 10\",\n#     \"TV-14\": \"age &gt;= 14\",\n#     \"TV-MA\": \"age &gt;= 17\",\n# }\n\n\nage_ratings_numeric = {\n    \"G\": \"age &gt;= 0\",\n    \"PG\": \"age &gt;= 10\",\n    \"PG-13\": \"age &gt;= 13\",\n    \"R\": \"age &gt;= 17\",\n    \"NC-17\": \"age &gt;= 18\",\n    \"NR\": \"Unknown\",\n    \"UR\": \"Unknown\",\n    \"TV-Y\": \"age &gt;= 0\",\n    \"TV-Y7\": \"age &gt;= 7\",\n    \"TV-Y7-FV\": \"age &gt;= 7\",\n    \"TV-G\": \"age &gt;= 0\",\n    \"TV-PG\": \"age &gt;= 10\",\n    \"TV-14\": \"age &gt;= 14\",\n    \"TV-MA\": \"age &gt;= 17\",\n}\n\n\ndf = df[df['rating'].isin(age_ratings_numeric.keys())]\n\n\ndf['age_numeric'] = df['rating'].map(age_ratings_numeric)\n\n# Drop \"Unknown\" values\ndf = df[df['age_numeric'] != \"Unknown\"]\n\n# Recalculate counts\nage_counts = df['age_numeric'].value_counts()\n\n# Plot\nplt.figure(figsize=(12,6))\nplt.bar(age_counts.index, age_counts.values, color='royalblue', edgecolor='black')\nplt.xlabel(\"Age Ratings\", fontsize=14)\nplt.ylabel(\"Count\", fontsize=14)\nplt.title(\"Age Distribution of Netflix Content\", fontsize=16)\nplt.xticks(rotation=45, fontsize=12)\nplt.yticks(fontsize=12)\nplt.grid(axis='y', linestyle='--', alpha=0.7)\nplt.show()\n\n\n\n\n\n\n\n\n\n\ncontent_type_distribution = df['type'].value_counts()\n\ncontent_type_distribution.plot(kind='bar', color='royalblue')\nplt.title('Content Type Distribution')\nplt.xlabel('Type')\nplt.ylabel('Count')\nplt.show()\n\n\n\n\n\n\n\n\n\nimport nltk\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nimport string\nfrom nltk.stem import WordNetLemmatizer\nimport string\n\n\nnltk.download('punkt')\nnltk.download('punkt_tab')\nnltk.download('stopwords')\nnltk.download('wordnet')\n\nstop_words = set(stopwords.words('english'))\nlemmatizer = WordNetLemmatizer()\n\n\ndef clean_and_tokenize(text):\n    text = text.lower()\n    tokens = word_tokenize(text)\n    tokens = [word for word in tokens if word.isalnum()]\n    tokens = [word for word in tokens if word not in stop_words]\n    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n    return tokens\n\n\ndf[\"tokenized_description\"] = df[\"description\"].fillna(\"\").apply(clean_and_tokenize)\n\n\ndf[[\"title\", \"tokenized_description\"]].head()\n\n[nltk_data] Downloading package punkt to /root/nltk_data...\n[nltk_data]   Unzipping tokenizers/punkt.zip.\n[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n[nltk_data] Downloading package stopwords to /root/nltk_data...\n[nltk_data]   Unzipping corpora/stopwords.zip.\n[nltk_data] Downloading package wordnet to /root/nltk_data...\n\n\n\n  \n    \n\n\n\n\n\n\ntitle\ntokenized_description\n\n\n\n\n0\nDick Johnson Is Dead\n[father, nears, end, life, filmmaker, kirsten,...\n\n\n1\nBlood & Water\n[crossing, path, party, cape, town, teen, set,...\n\n\n2\nGanglands\n[protect, family, powerful, drug, lord, skille...\n\n\n3\nJailbirds New Orleans\n[feud, flirtation, toilet, talk, go, among, in...\n\n\n4\nKota Factory\n[city, coaching, center, known, train, finest,...\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n\n    \n  \n\n\n\nimport pandas as pd\nimport spacy\nimport re\nimport string\n\n# Load spaCy model\nnlp = spacy.load(\"en_core_web_sm\")\n\n# Prepare stopwords (combining spaCy + NLTK)\nimport nltk\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\n\nstopwords_spacy = spacy.lang.en.stop_words.STOP_WORDS\nstopwords_nltk = set(stopwords.words('english'))\ncustom_stopwords = stopwords_spacy.union(stopwords_nltk)\ncustom_stopwords = custom_stopwords.union({\"netflix\", \"series\", \"season\"})\n\n# Define preprocessing function\ndef preprocess_text_spacy(text):\n    text = re.sub(r'[^\\x00-\\x7F]+', ' ', text)  # remove non-ASCII\n    text = text.strip()\n    doc = nlp(text.lower())\n\n    clean_tokens = []\n    for token in doc:\n        if (\n            token.text not in custom_stopwords\n            and token.text not in string.punctuation\n            and re.search('[a-zA-Z0-9]', token.text)\n        ):\n            clean_tokens.append(token.lemma_)\n\n    return clean_tokens\n\n# Apply preprocessing\ndf['processed_description'] = df['description'].astype(str).apply(preprocess_text_spacy)\n\n# Preview\nprint(df[['description', 'processed_description']].head(10))\n\n[nltk_data] Downloading package stopwords to /root/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n\n\n                                         description  \\\n0  As her father nears the end of his life, filmm...   \n1  After crossing paths at a party, a Cape Town t...   \n2  To protect his family from a powerful drug lor...   \n3  Feuds, flirtations and toilet talk go down amo...   \n4  In a city of coaching centers known to train I...   \n5  The arrival of a charismatic young priest brin...   \n6  Equestria's divided. But a bright-eyed hero be...   \n7  On a photo shoot in Ghana, an American model s...   \n8  A talented batch of amateur bakers face off in...   \n9  A woman adjusting to life after a loss contend...   \n\n                               processed_description  \n0  [father, near, end, life, filmmaker, kirsten, ...  \n1  [cross, path, party, cape, town, teen, set, pr...  \n2  [protect, family, powerful, drug, lord, skille...  \n3  [feuds, flirtation, toilet, talk, incarcerated...  \n4  [city, coaching, center, know, train, india, f...  \n5  [arrival, charismatic, young, priest, bring, g...  \n6  [equestria, divided, bright, eyed, hero, belie...  \n7  [photo, shoot, ghana, american, model, slip, t...  \n8  [talented, batch, amateur, baker, face, 10, we...  \n9  [woman, adjust, life, loss, contend, feisty, b...  \n\n\n\n# Join tokens back into a single string so TF-IDF can handle them easily\ndf['processed_text_str'] = df['processed_description'].apply(lambda tokens: ' '.join(tokens))\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\n# Initialize and fit the TF-IDF vectorizer on the processed descriptions\nvectorizer = TfidfVectorizer()\nX_tfidf = vectorizer.fit_transform(df['processed_text_str'])\nprint(\"TF-IDF matrix shape:\", X_tfidf.shape)  # (number of samples, number of features)\n\n# Get some insights: average TF-IDF weight for each term across the corpus\navg_tfidf = np.mean(X_tfidf.toarray(), axis=0)\ntop_n = 20\ntop_indices = avg_tfidf.argsort()[-top_n:][::-1]\ntop_features = [vectorizer.get_feature_names_out()[i] for i in top_indices]\nprint(\"Top TF-IDF features:\", top_features)\n\nTF-IDF matrix shape: (8715, 15269)\nTop TF-IDF features: ['life', 'young', 'find', 'family', 'woman', 'new', 'man', 'friend', 'love', 'world', 'year', 'take', 'help', 'documentary', 'school', 'old', 'try', 'home', 'father', 'story']\n\n\n\nimport pandas as pd\nimport re\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.preprocessing import LabelEncoder\n\n# Load dataset\ndf = pd.read_csv('/content/netflix_titles.csv', encoding='ISO-8859-1')\n\n# Step 1: Extract Primary Genre\n# Take the first genre listed as the 'primary genre'\ndf['genre'] = df['listed_in'].astype(str).apply(lambda x: x.split(',')[0].strip())\n\n# Step 2: Clean Descriptions\ndef clean_description(text):\n    if pd.isna(text):  # Handle NaN values\n        return \"\"\n    return re.sub(r'[^a-zA-Z0-9.,!?\\'\" ]', '', text)\n\ndf['cleaned_description'] = df['description'].apply(clean_description)\n\n# Step 3: TF-IDF Vectorization\nvectorizer = TfidfVectorizer(stop_words='english', ngram_range=(1, 2), min_df=3, max_df=0.9)\nX = vectorizer.fit_transform(df['cleaned_description'])\n\n# Step 4: Encode Genre Labels\nlabel_encoder = LabelEncoder()\ny = label_encoder.fit_transform(df['genre'])\n\n# Check results\nprint(\"âœ… Sample Data:\")\nprint(df[['title', 'genre', 'cleaned_description']].head(5))\n\nâœ… Sample Data:\n                   title                   genre  \\\n0   Dick Johnson Is Dead           Documentaries   \n1          Blood & Water  International TV Shows   \n2              Ganglands          Crime TV Shows   \n3  Jailbirds New Orleans              Docuseries   \n4           Kota Factory  International TV Shows   \n\n                                 cleaned_description  \n0  As her father nears the end of his life, filmm...  \n1  After crossing paths at a party, a Cape Town t...  \n2  To protect his family from a powerful drug lor...  \n3  Feuds, flirtations and toilet talk go down amo...  \n4  In a city of coaching centers known to train I...  \n\n\n\nimport pandas as pd\n\n# 1) Load dataset\ndf = pd.read_csv('netflix_titles.csv', encoding='ISO-8859-1')\n\n# 2) Convert 'listed_in' to a list of genres\ndf['genre_list'] = df['listed_in'].astype(str).apply(lambda x: [g.strip() for g in x.split(',')])\n\n\nimport re\n\ndef clean_description(text):\n    if pd.isna(text):\n        return \"\"\n    # Remove non-alphanumeric except basic punctuation\n    return re.sub(r'[^a-zA-Z0-9.,!?\\'\" ]', '', text)\n\ndf['cleaned_description'] = df['description'].apply(clean_description)\n\n\nfrom sklearn.preprocessing import MultiLabelBinarizer\n\nmlb = MultiLabelBinarizer()\ny = mlb.fit_transform(df['genre_list'])  # shape: (num_samples, num_unique_genres)\ngenre_labels = mlb.classes_  # array of genre names\n\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nvectorizer = TfidfVectorizer(stop_words='english', ngram_range=(1,2), min_df=2, max_df=0.9)\nX = vectorizer.fit_transform(df['cleaned_description'])  # shape: (num_samples, num_features)\n\nprint(\"Feature matrix shape:\", X.shape)\nprint(\"Label matrix shape:\", y.shape)\n\nFeature matrix shape: (8809, 17008)\nLabel matrix shape: (8809, 48)\n\n\n\nmodel training part\n\nfrom sklearn.metrics import f1_score, make_scorer\n\ndef multi_label_f1_micro(y_true, y_pred):\n    return f1_score(y_true, y_pred, average='micro')\n\nf1_micro_scorer = make_scorer(multi_label_f1_micro)\n\n\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.naive_bayes import MultinomialNB\n\n\nmodels = {\n    \"LogisticRegression\": LogisticRegression(max_iter=1000),\n    \"RandomForest\": RandomForestClassifier(n_estimators=200, random_state=42),\n    \"XGBoost\": XGBClassifier(eval_metric='logloss', use_label_encoder=False, random_state=42),\n    \"NaiveBayes\": MultinomialNB()\n}\n\n\nfrom sklearn.decomposition import TruncatedSVD\n\nsvd = TruncatedSVD(n_components=300, random_state=42)\nX_reduced = svd.fit_transform(X)  # use the output of TF-IDF\n\n\nimport pandas as pd\nimport re\n\n# Load the dataset\ndf = pd.read_csv('netflix_titles.csv', encoding='ISO-8859-1')\n\n# Extract the first genre from 'listed_in'\ndf['genre'] = df['listed_in'].astype(str).apply(lambda x: x.split(',')[0].strip())\n\n# Clean the 'description' column\ndef clean_description(text):\n    if pd.isna(text):\n        return \"\"\n    return re.sub(r'[^a-zA-Z0-9.,!?\\'\" ]', '', text)\n\ndf['cleaned_description'] = df['description'].apply(clean_description)\n\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nvectorizer = TfidfVectorizer(\n    stop_words='english',\n    ngram_range=(1, 2),\n    min_df=2,\n    max_df=0.9\n)\nX = vectorizer.fit_transform(df['cleaned_description'])\n\n\nfrom sklearn.preprocessing import LabelEncoder\n\nlabel_encoder = LabelEncoder()\ny = label_encoder.fit_transform(df['genre'])\n\n\nfrom sklearn.decomposition import TruncatedSVD, NMF\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.naive_bayes import MultinomialNB\n\n\nfrom sklearn.pipeline import Pipeline\n\n# 1) Logistic Regression + SVD\npipe_lr = Pipeline([\n    ('svd', TruncatedSVD(n_components=300, random_state=42)),\n    ('clf', LogisticRegression(max_iter=1000, solver='saga', n_jobs=-1))\n])\n\n# 2) MultinomialNB + NMF (ensures non-negative features)\npipe_nb = Pipeline([\n    ('nmf', NMF(n_components=50, init='random', random_state=42)),\n    ('clf', MultinomialNB())\n])\n\n# 3) RandomForest + SVD\npipe_rf = Pipeline([\n    ('svd', TruncatedSVD(n_components=300, random_state=42)),\n    ('clf', RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1))\n])\n\n# 4) XGBoost + SVD\npipe_xgb = Pipeline([\n    ('svd', TruncatedSVD(n_components=300, random_state=42)),\n    ('clf', XGBClassifier(eval_metric='logloss', use_label_encoder=False, random_state=42, n_jobs=-1))\n])\n\n\nimport numpy as np\nfrom sklearn.model_selection import KFold, cross_val_score\nfrom sklearn.metrics import f1_score, make_scorer\n\ndef f1_micro(y_true, y_pred):\n    return f1_score(y_true, y_pred, average='micro')\n\nf1_micro_scorer = make_scorer(f1_micro)\n\nkf = KFold(n_splits=3, shuffle=True, random_state=42)\n\nmodels = {\n    \"LogisticRegression+SVD\": pipe_lr,\n    \"MultinomialNB+NMF\": pipe_nb,\n    \"RandomForest+SVD\": pipe_rf,\n    \"XGBoost+SVD\": pipe_xgb\n}\n\nfor name, model_pipeline in models.items():\n    scores = cross_val_score(\n        model_pipeline,\n        X,\n        y,\n        cv=kf,\n        scoring=f1_micro_scorer,\n        n_jobs=-1\n    )\n    print(f\"Model: {name}\")\n    print(f\"F1-micro (3-fold avg): {np.mean(scores):.4f} Â± {np.std(scores):.4f}\")\n    print(\"-\" * 50)\n\nModel: LogisticRegression+SVD\nF1-micro (3-fold avg): 0.3544 Â± 0.0153\n--------------------------------------------------\nModel: MultinomialNB+NMF\nF1-micro (3-fold avg): 0.1816 Â± 0.0116\n--------------------------------------------------\nModel: RandomForest+SVD\nF1-micro (3-fold avg): 0.3382 Â± 0.0128\n--------------------------------------------------\nModel: XGBoost+SVD\nF1-micro (3-fold avg): nan Â± nan\n--------------------------------------------------\n\n\n/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n2 fits failed out of a total of 3.\nThe score on these train-test partitions for these parameters will be set to nan.\nIf these failures are not expected, you can try to debug them by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\", line 662, in fit\n    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n  File \"/usr/local/lib/python3.11/dist-packages/xgboost/core.py\", line 726, in inner_f\n    return func(**kwargs)\n           ^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py\", line 1559, in fit\n    raise ValueError(\nValueError: Invalid classes inferred from unique values of `y`.  Expected: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n 24 25 26 27 28 29 30 31 32 33], got [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 20 21 22 23 24\n 25 27 29 30 31 32 33 34 36 37]\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\", line 662, in fit\n    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n  File \"/usr/local/lib/python3.11/dist-packages/xgboost/core.py\", line 726, in inner_f\n    return func(**kwargs)\n           ^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py\", line 1559, in fit\n    raise ValueError(\nValueError: Invalid classes inferred from unique values of `y`.  Expected: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n 24 25 26 27 28 29 30 31 32 33 34 35 36], got [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14 15 16 17 18 19 20 21 22 23 24\n 25 26 27 28 29 30 31 32 33 34 35 36 37]\n\n  warnings.warn(some_fits_failed_message, FitFailedWarning)\n\n\n\n\nclustering\n\n# Join tokens back into a single string so TF-IDF can handle them easily\ndf['processed_text_str'] = df['processed_description'].apply(lambda tokens: ' '.join(tokens))\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\n# Initialize and fit the TF-IDF vectorizer on the processed descriptions\nvectorizer = TfidfVectorizer()\nX_tfidf = vectorizer.fit_transform(df['processed_text_str'])\nprint(\"TF-IDF matrix shape:\", X_tfidf.shape)  # (number of samples, number of features)\n\n# Get some insights: average TF-IDF weight for each term across the corpus\navg_tfidf = np.mean(X_tfidf.toarray(), axis=0)\ntop_n = 20\ntop_indices = avg_tfidf.argsort()[-top_n:][::-1]\ntop_features = [vectorizer.get_feature_names_out()[i] for i in top_indices]\nprint(\"Top TF-IDF features:\", top_features)\n\nTF-IDF matrix shape: (8809, 15318)\nTop TF-IDF features: ['life', 'young', 'find', 'family', 'woman', 'new', 'man', 'friend', 'love', 'world', 'year', 'take', 'help', 'documentary', 'school', 'old', 'try', 'home', 'father', 'story']\n\n\n\nfrom sklearn.cluster import KMeans\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\n# Vectorize the processed descriptions\nvectorizer = TfidfVectorizer(stop_words='english', ngram_range=(1, 2), min_df=2, max_df=0.9)\nX_tfidf_desc = vectorizer.fit_transform(df['processed_text_str'])  # Use processed description\n\n# Perform KMeans clustering\nnum_clusters = 6\nkmeans = KMeans(n_clusters=num_clusters, random_state=42)\nclusters = kmeans.fit_predict(X_tfidf_desc)\n\n# Assign cluster labels\ndf['cluster'] = clusters\n\n# Display results\nprint(\"Cluster assignments (first 10):\")\nprint(df[['title', 'processed_text_str', 'cluster']].head(10))\n\nCluster assignments (first 10):\n                              title  \\\n0              Dick Johnson Is Dead   \n1                     Blood & Water   \n2                         Ganglands   \n3             Jailbirds New Orleans   \n4                      Kota Factory   \n5                     Midnight Mass   \n6  My Little Pony: A New Generation   \n7                           Sankofa   \n8     The Great British Baking Show   \n9                      The Starling   \n\n                                  processed_text_str  cluster  \n0  father near end life filmmaker kirsten johnson...        4  \n1  cross path party cape town teen set prove priv...        4  \n2  protect family powerful drug lord skilled thie...        2  \n3  feud flirtation toilet talk incarcerated woman...        1  \n4  city coach center know train india fine colleg...        5  \n5  arrival charismatic young priest bring gloriou...        1  \n6  equestria divided bright eyed hero believe ear...        4  \n7  photo shoot ghana american model slip time ens...        4  \n8  talented batch amateur baker face 10 week comp...        3  \n9  woman adjust life loss contend feisty bird tak...        1  \n\n\n\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\n\n# Finding the optimal number of clusters using the Elbow Method\ninertia = []\nsilhouette_scores = []\n\nfor k in range(2, 11):  # Test multiple cluster sizes\n    kmeans = KMeans(n_clusters=k, random_state=42)\n    kmeans.fit(X_tfidf_desc)\n    inertia.append(kmeans.inertia_)  # Elbow Method\n    silhouette_scores.append(silhouette_score(X_tfidf_desc, kmeans.labels_))  # Silhouette Score\n\n# Plot Elbow Method\nplt.figure(figsize=(10, 5))\nplt.plot(range(2, 11), inertia, marker='o')\nplt.title('Elbow Method - Optimal K')\nplt.xlabel('Number of Clusters')\nplt.ylabel('Inertia')\nplt.show()\n\n# Plot Silhouette Scores\nplt.figure(figsize=(10, 5))\nplt.plot(range(2, 11), silhouette_scores, marker='o', color='green')\nplt.title('Silhouette Score - Optimal K')\nplt.xlabel('Number of Clusters')\nplt.ylabel('Silhouette Score')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfrom sklearn.cluster import KMeans\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\n# Vectorize the processed descriptions\nvectorizer = TfidfVectorizer(stop_words='english', ngram_range=(1, 2), min_df=2, max_df=0.9)\nX_tfidf_desc = vectorizer.fit_transform(df['processed_text_str'])  # Use processed description\n\n# Perform KMeans clustering\nnum_clusters = 6\nkmeans = KMeans(n_clusters=num_clusters, random_state=42)\nclusters = kmeans.fit_predict(X_tfidf_desc)\n\n# Assign cluster labels\ndf['cluster'] = clusters\n\n# Display results\nprint(\"Cluster assignments (first 10):\")\nprint(df[['title', 'processed_text_str', 'cluster']].head(10))\n\nCluster assignments (first 10):\n                              title  \\\n0              Dick Johnson Is Dead   \n1                     Blood & Water   \n2                         Ganglands   \n3             Jailbirds New Orleans   \n4                      Kota Factory   \n5                     Midnight Mass   \n6  My Little Pony: A New Generation   \n7                           Sankofa   \n8     The Great British Baking Show   \n9                      The Starling   \n\n                                  processed_text_str  cluster  \n0  father near end life filmmaker kirsten johnson...        4  \n1  cross path party cape town teen set prove priv...        4  \n2  protect family powerful drug lord skilled thie...        2  \n3  feud flirtation toilet talk incarcerated woman...        1  \n4  city coach center know train india fine colleg...        5  \n5  arrival charismatic young priest bring gloriou...        1  \n6  equestria divided bright eyed hero believe ear...        4  \n7  photo shoot ghana american model slip time ens...        4  \n8  talented batch amateur baker face 10 week comp...        3  \n9  woman adjust life loss contend feisty bird tak...        1  \n\n\n\n# Display Sample Titles from Each Cluster\nfor cluster_id in sorted(df['cluster'].unique()):\n    print(f\"\\nCluster {cluster_id} Titles:\")\n    print(df[df['cluster'] == cluster_id][['title', 'processed_text_str']].head(5))\n\n# Show Top Words in Each Cluster\nfrom collections import Counter\nimport numpy as np\n\ndef get_top_words(cluster_num, top_n=10):\n    cluster_text = \" \".join(df[df['cluster'] == cluster_num]['processed_text_str'])\n    word_counts = Counter(cluster_text.split())\n    return dict(word_counts.most_common(top_n))\n\n# Display the top words in each cluster\nfor cluster_id in sorted(df['cluster'].unique()):\n    print(f\"\\nCluster {cluster_id} Top Words:\")\n    print(get_top_words(cluster_id, top_n=10))\n\n\nCluster 0 Titles:\n                          title  \\\n48                 Training Day   \n82                      Lucifer   \n84         Omo Ghetto: the Saga   \n91   The Women and the Murderer   \n122                  In the Cut   \n\n                                    processed_text_str  \n48   rookie cop day prove veteran lapd narcotic off...  \n82   bore lord hell devil relocate los angeles open...  \n84   twin reunite good hearted female gangster upti...  \n91   documentary trace capture serial killer guy ge...  \n122  embark affair cop probe murder young woman ins...  \n\nCluster 1 Titles:\n                    title                                 processed_text_str\n3   Jailbirds New Orleans  feud flirtation toilet talk incarcerated woman...\n5           Midnight Mass  arrival charismatic young priest bring gloriou...\n9            The Starling  woman adjust life loss contend feisty bird tak...\n12           Je Suis Karl  family murder terrorist bombing young woman un...\n24                  Jeans  father man love insist twin son marry twin sis...\n\nCluster 2 Titles:\n                     title                                 processed_text_str\n2                Ganglands  protect family powerful drug lord skilled thie...\n26          Minsara Kanavu  tangle love triangle ensue man fall woman stud...\n28              Dark Skies  family idyllic suburban life shatter alien for...\n47   The Smart Money Woman  glamorous millennial strive success juggle car...\n103         Shadow Parties  family face destruction long run conflict comm...\n\nCluster 3 Titles:\n                               title  \\\n8      The Great British Baking Show   \n13  Confessions of an Invisible Girl   \n18                         Intrusion   \n21            Resurrection: Ertugrul   \n34           Tayo and Little Wizards   \n\n                                   processed_text_str  \n8   talented batch amateur baker face 10 week comp...  \n13  clever socially awkward tet join new school fi...  \n18  deadly home invasion couple new dream house tr...  \n21  good deed unwittingly endanger clan 13th centu...  \n34  tayo speed adventure friend kidnap evil magici...  \n\nCluster 4 Titles:\n                                  title  \\\n0                  Dick Johnson Is Dead   \n1                         Blood & Water   \n6      My Little Pony: A New Generation   \n7                               Sankofa   \n10  Vendetta: Truth, Lies and The Mafia   \n\n                                   processed_text_str  \n0   father near end life filmmaker kirsten johnson...  \n1   cross path party cape town teen set prove priv...  \n6   equestria divided bright eyed hero believe ear...  \n7   photo shoot ghana american model slip time ens...  \n10  sicily boast bold anti mafia coalition happen ...  \n\nCluster 5 Titles:\n                     title                                 processed_text_str\n4             Kota Factory  city coach center know train india fine colleg...\n11        Bangkok Breaking  struggle earn living bangkok man join emergenc...\n30         Ankahi Kahaniya  big city life buzz lonely soul discover surpri...\n36          The Stronghold  tired small time grind marseille cop chance bu...\n45  My Heroes Were Cowboys  robin wiltshire painful childhood rescue weste...\n\nCluster 0 Top Words:\n{'murder': 264, 'cop': 118, 'detective': 90, 'crime': 73, 'case': 65, 'killer': 56, 'police': 48, 'find': 46, 'suspect': 36, 'investigate': 36}\n\nCluster 1 Top Words:\n{'young': 612, 'woman': 549, 'man': 248, 'life': 154, 'find': 109, 'love': 104, 'father': 72, 'year': 58, 'new': 55, 'mother': 52}\n\nCluster 2 Top Words:\n{'family': 611, 'love': 432, 'life': 163, 'fall': 111, 'find': 87, 'year': 76, 'man': 63, 'young': 59, 'home': 55, 'girl': 54}\n\nCluster 3 Top Words:\n{'friend': 541, 'new': 441, 'good': 154, 'life': 109, 'find': 105, 'school': 80, 'help': 74, 'world': 62, 'old': 61, 'high': 60}\n\nCluster 4 Top Words:\n{'life': 565, 'world': 383, 'find': 340, 'documentary': 279, 'year': 247, 'man': 240, 'take': 231, 'story': 220, 'school': 201, 'high': 190}\n\nCluster 5 Top Words:\n{'struggle': 197, 'city': 194, 'big': 146, 'new': 135, 'york': 92, 'life': 69, 'world': 50, 'find': 46, 'family': 29, 'young': 29}\n\n\n\n# Plot the distribution of clustersimport seaborn as sns\nimport seaborn as sns\n\nplt.figure(figsize=(8, 5))\nsns.countplot(x='cluster', data=df, palette='viridis')\nplt.title(\"Distribution of Clusters\")\nplt.xlabel(\"Cluster\")\nplt.ylabel(\"Count\")\nplt.show()\n\nFutureWarning: \n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n\n  sns.countplot(x='cluster', data=df, palette='viridis')\n\n\n\n\n\n\n\n\n\n\n\ntopic modeling\n\n### Topic Modeling\n# Use Latent Dirichlet Allocation (LDA) on the TF-IDF matrix to discover topics.\nfrom sklearn.decomposition import LatentDirichletAllocation\n\nnum_topics = 5\nlda = LatentDirichletAllocation(n_components=num_topics, random_state=42)\nlda.fit(X_tfidf)\nfeature_names = vectorizer.get_feature_names_out()\n\nprint(\"\\nTopics discovered:\")\nfor topic_idx, topic in enumerate(lda.components_):\n    top_words = [feature_names[i] for i in topic.argsort()[-10:]]\n    print(f\"Topic {topic_idx+1}: {', '.join(top_words)}\")\n\n\nTopics discovered:\nTopic 1: mischievous, growth, turn upside, haddish, retaliate, turf war, fair, undo, laga, flawed\nTopic 2: flawed, mischievous, uncover dark, laga, fair, life star, turf war, undo, fast, leave family\nTopic 3: consultant, undo, fair, mischievous, turn upside, turf war, flawed, leave family, fast, laga\nTopic 4: flawed, turf war, leave family, familiar face, fast, fair, life star, undo, mischievous, laga\nTopic 5: turn obsessive, leave family, undo, fair, mischievous, turn upside, turf war, life star, fast, laga\n\n\n\nimport pandas as pd\nimport re\n\n# Load the dataset\ndf = pd.read_csv('netflix_titles.csv', encoding='ISO-8859-1')\n\n# Extract the first genre from 'listed_in' and store in a new column 'genre'\ndf['genre'] = df['listed_in'].astype(str).apply(lambda x: x.split(',')[0].strip())\n\n# Clean the 'description' column: remove unwanted characters\ndef clean_description(text):\n    if pd.isna(text):\n        return \"\"\n    return re.sub(r'[^a-zA-Z0-9.,!?\\'\" ]', '', text).strip()\n\ndf['cleaned_description'] = df['description'].apply(clean_description)\n\n# (Optional) Inspect the cleaned data\nprint(df[['title', 'genre', 'cleaned_description']].head(5))\n\n                   title                   genre  \\\n0   Dick Johnson Is Dead           Documentaries   \n1          Blood & Water  International TV Shows   \n2              Ganglands          Crime TV Shows   \n3  Jailbirds New Orleans              Docuseries   \n4           Kota Factory  International TV Shows   \n\n                                 cleaned_description  \n0  As her father nears the end of his life, filmm...  \n1  After crossing paths at a party, a Cape Town t...  \n2  To protect his family from a powerful drug lor...  \n3  Feuds, flirtations and toilet talk go down amo...  \n4  In a city of coaching centers known to train I...  \n\n\n\n\nprediction for type ( optional )\n\nimport pandas as pd\nimport re\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\n# 1) Load dataset\ndf = pd.read_csv('netflix_titles.csv', encoding='ISO-8859-1')\n\n# 2) Clean the description\ndef clean_description(text):\n    if pd.isna(text):\n        return \"\"\n    return re.sub(r'[^a-zA-Z0-9.,!?\\'\" ]', '', text).strip()\n\ndf['cleaned_description'] = df['description'].apply(clean_description)\n\n# 3) Define target: \"Movie\" vs. \"TV Show\"\ny = df['type']  # 'Movie' or 'TV Show'\n\n# 4) TF-IDF vectorization of the cleaned descriptions\nvectorizer = TfidfVectorizer(stop_words='english', ngram_range=(1,2), min_df=2, max_df=0.9)\nX_tfidf = vectorizer.fit_transform(df['cleaned_description'])\n\n# 5) Split data\nX_train, X_test, y_train, y_test = train_test_split(\n    X_tfidf,\n    y,\n    test_size=0.2,\n    random_state=42\n)\n\nprint(\"Shapes:\", X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n\nShapes: (7047, 17008) (1762, 17008) (7047,) (1762,)\n\n\n\nimport numpy as np\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom collections import Counter\n\ndef classify_by_similarity(new_text, vectorizer, X_train, y_train, k=5):\n    \"\"\"\n    Classify a new text as 'Movie' or 'TV Show' using similarity to training data.\n\n    Parameters:\n    - new_text: string (description to classify)\n    - vectorizer: the fitted TfidfVectorizer\n    - X_train: TF-IDF matrix for training descriptions\n    - y_train: Series or array of labels ('Movie'/'TV Show') for training\n    - k: number of neighbors to consider\n\n    Returns:\n    - predicted_type: the predicted label ('Movie' or 'TV Show')\n    \"\"\"\n    # 1) Transform new text into TF-IDF vector\n    new_vec = vectorizer.transform([new_text])\n\n    # 2) Compute cosine similarity with each training sample\n    sims = cosine_similarity(new_vec, X_train).flatten()\n\n    # 3) Get indices of top-k neighbors (largest similarity)\n    top_k_idx = np.argsort(sims)[::-1][:k]\n\n    # 4) Majority vote among those k neighbors\n    #    If y_train is a pandas Series, we can use .iloc;\n    #    If y_train is a NumPy array, index it directly.\n    if isinstance(y_train, pd.Series):\n        top_k_labels = y_train.iloc[top_k_idx]\n    else:\n        top_k_labels = y_train[top_k_idx]\n\n    # 5) Determine the most common label\n    predicted_type = Counter(top_k_labels).most_common(1)[0][0]\n\n    return predicted_type\n\n\n\nresult\n\n# Example: A new description\nnew_description = \"A gripping story of a detective unraveling mysteries in a futuristic world.\"\n\npredicted_label = classify_by_similarity(\n    new_text=new_description,\n    vectorizer=vectorizer,\n    X_train=X_train,\n    y_train=y_train,\n    k=5  # top-5 neighbors\n)\n\nprint(\"Predicted label by similarity-based method:\", predicted_label)\n\nPredicted label by similarity-based method: Movie\n\n\n\nimport pandas as pd\nimport re\nimport string\n\n# Load the dataset\ndf = pd.read_csv('netflix_titles.csv', encoding='ISO-8859-1')\n\n# Fill missing values for columns we'll use\nfor col in ['listed_in', 'type', 'cast', 'description']:\n    df[col] = df[col].fillna('')\n\n# Combine features into a single text field\ndef combine_features(row):\n    return f\"{row['listed_in']} {row['type']} {row['cast']} {row['description']}\"\n\ndf['combined_features'] = df.apply(combine_features, axis=1)\n\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\nimport numpy as np\n\n# Vectorize the combined text\nvectorizer = TfidfVectorizer(stop_words='english')\ntfidf_matrix = vectorizer.fit_transform(df['combined_features'])\nprint(\"TF-IDF matrix shape:\", tfidf_matrix.shape)\n\n# Example: Compute similarity for a query\nquery = \"Comedy Movie Adam Sandler funny heartwarming family\"\nquery_vec = vectorizer.transform([query])\nsimilarities = cosine_similarity(query_vec, tfidf_matrix).flatten()\ntop_indices = np.argsort(similarities)[::-1][:5]\nprint(\"Top recommendations using TF-IDF:\")\nprint(df.iloc[top_indices][['title', 'listed_in', 'type']])\n\nTF-IDF matrix shape: (8809, 47360)\nTop recommendations using TF-IDF:\n                        title                           listed_in     type\n4482  ADAM SANDLER 100% FRESH                     Stand-Up Comedy    Movie\n1879          Hubie Halloween             Comedies, Horror Movies    Movie\n6089    Adam Ruins Everything                         TV Comedies  TV Show\n5639      Jim Gaffigan: Cinco                     Stand-Up Comedy    Movie\n6271          Bedtime Stories  Children & Family Movies, Comedies    Movie\n\n\n\nimport spacy\n\n!python -m spacy download en_core_web_md\n\nnlp = spacy.load(\"en_core_web_md\")  # Using a medium model with pretrained vectors\n\ndef get_doc_vector(text):\n    doc = nlp(text)\n    # Average the token vectors (excluding stop words and punctuation)\n    vectors = [token.vector for token in doc if token.has_vector and not token.is_stop and not token.is_punct]\n    if vectors:\n        return np.mean(vectors, axis=0)\n    else:\n        return np.zeros(nlp.vocab.vectors_length)\n\n# Compute document vectors for each title\ndf['doc_vector'] = df['combined_features'].apply(get_doc_vector)\n\n# Create a matrix of document vectors\ndoc_vectors = np.stack(df['doc_vector'].values)\n\n# Similarity example using word embeddings\nquery_vector = get_doc_vector(query)\nfrom sklearn.metrics.pairwise import cosine_similarity\nembedding_similarities = cosine_similarity([query_vector], doc_vectors).flatten()\ntop_indices_embed = np.argsort(embedding_similarities)[::-1][:5]\nprint(\"Top recommendations using Word Embeddings:\")\nprint(df.iloc[top_indices_embed][['title', 'listed_in', 'type']])\n\nCollecting en-core-web-md==3.7.1\n  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.7.1/en_core_web_md-3.7.1-py3-none-any.whl (42.8 MB)\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 42.8/42.8 MB 12.3 MB/s eta 0:00:00\nRequirement already satisfied: spacy&lt;3.8.0,&gt;=3.7.2 in /usr/local/lib/python3.11/dist-packages (from en-core-web-md==3.7.1) (3.7.5)\nRequirement already satisfied: spacy-legacy&lt;3.1.0,&gt;=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy&lt;3.8.0,&gt;=3.7.2-&gt;en-core-web-md==3.7.1) (3.0.12)\nRequirement already satisfied: spacy-loggers&lt;2.0.0,&gt;=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy&lt;3.8.0,&gt;=3.7.2-&gt;en-core-web-md==3.7.1) (1.0.5)\nRequirement already satisfied: murmurhash&lt;1.1.0,&gt;=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy&lt;3.8.0,&gt;=3.7.2-&gt;en-core-web-md==3.7.1) (1.0.12)\nRequirement already satisfied: cymem&lt;2.1.0,&gt;=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy&lt;3.8.0,&gt;=3.7.2-&gt;en-core-web-md==3.7.1) (2.0.11)\nRequirement already satisfied: preshed&lt;3.1.0,&gt;=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy&lt;3.8.0,&gt;=3.7.2-&gt;en-core-web-md==3.7.1) (3.0.9)\nRequirement already satisfied: thinc&lt;8.3.0,&gt;=8.2.2 in /usr/local/lib/python3.11/dist-packages (from spacy&lt;3.8.0,&gt;=3.7.2-&gt;en-core-web-md==3.7.1) (8.2.5)\nRequirement already satisfied: wasabi&lt;1.2.0,&gt;=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy&lt;3.8.0,&gt;=3.7.2-&gt;en-core-web-md==3.7.1) (1.1.3)\nRequirement already satisfied: srsly&lt;3.0.0,&gt;=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy&lt;3.8.0,&gt;=3.7.2-&gt;en-core-web-md==3.7.1) (2.5.1)\nRequirement already satisfied: catalogue&lt;2.1.0,&gt;=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy&lt;3.8.0,&gt;=3.7.2-&gt;en-core-web-md==3.7.1) (2.0.10)\nRequirement already satisfied: weasel&lt;0.5.0,&gt;=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy&lt;3.8.0,&gt;=3.7.2-&gt;en-core-web-md==3.7.1) (0.4.1)\nRequirement already satisfied: typer&lt;1.0.0,&gt;=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy&lt;3.8.0,&gt;=3.7.2-&gt;en-core-web-md==3.7.1) (0.15.2)\nRequirement already satisfied: tqdm&lt;5.0.0,&gt;=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy&lt;3.8.0,&gt;=3.7.2-&gt;en-core-web-md==3.7.1) (4.67.1)\nRequirement already satisfied: requests&lt;3.0.0,&gt;=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy&lt;3.8.0,&gt;=3.7.2-&gt;en-core-web-md==3.7.1) (2.32.3)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,&lt;3.0.0,&gt;=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy&lt;3.8.0,&gt;=3.7.2-&gt;en-core-web-md==3.7.1) (2.10.6)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy&lt;3.8.0,&gt;=3.7.2-&gt;en-core-web-md==3.7.1) (3.1.6)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy&lt;3.8.0,&gt;=3.7.2-&gt;en-core-web-md==3.7.1) (75.1.0)\nRequirement already satisfied: packaging&gt;=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy&lt;3.8.0,&gt;=3.7.2-&gt;en-core-web-md==3.7.1) (24.2)\nRequirement already satisfied: langcodes&lt;4.0.0,&gt;=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy&lt;3.8.0,&gt;=3.7.2-&gt;en-core-web-md==3.7.1) (3.5.0)\nRequirement already satisfied: numpy&gt;=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy&lt;3.8.0,&gt;=3.7.2-&gt;en-core-web-md==3.7.1) (1.26.4)\nRequirement already satisfied: language-data&gt;=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes&lt;4.0.0,&gt;=3.2.0-&gt;spacy&lt;3.8.0,&gt;=3.7.2-&gt;en-core-web-md==3.7.1) (1.3.0)\nRequirement already satisfied: annotated-types&gt;=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,&lt;3.0.0,&gt;=1.7.4-&gt;spacy&lt;3.8.0,&gt;=3.7.2-&gt;en-core-web-md==3.7.1) (0.7.0)\nRequirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,&lt;3.0.0,&gt;=1.7.4-&gt;spacy&lt;3.8.0,&gt;=3.7.2-&gt;en-core-web-md==3.7.1) (2.27.2)\nRequirement already satisfied: typing-extensions&gt;=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,&lt;3.0.0,&gt;=1.7.4-&gt;spacy&lt;3.8.0,&gt;=3.7.2-&gt;en-core-web-md==3.7.1) (4.12.2)\nRequirement already satisfied: charset-normalizer&lt;4,&gt;=2 in /usr/local/lib/python3.11/dist-packages (from requests&lt;3.0.0,&gt;=2.13.0-&gt;spacy&lt;3.8.0,&gt;=3.7.2-&gt;en-core-web-md==3.7.1) (3.4.1)\nRequirement already satisfied: idna&lt;4,&gt;=2.5 in /usr/local/lib/python3.11/dist-packages (from requests&lt;3.0.0,&gt;=2.13.0-&gt;spacy&lt;3.8.0,&gt;=3.7.2-&gt;en-core-web-md==3.7.1) (3.10)\nRequirement already satisfied: urllib3&lt;3,&gt;=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests&lt;3.0.0,&gt;=2.13.0-&gt;spacy&lt;3.8.0,&gt;=3.7.2-&gt;en-core-web-md==3.7.1) (2.3.0)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests&lt;3.0.0,&gt;=2.13.0-&gt;spacy&lt;3.8.0,&gt;=3.7.2-&gt;en-core-web-md==3.7.1) (2025.1.31)\nRequirement already satisfied: blis&lt;0.8.0,&gt;=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc&lt;8.3.0,&gt;=8.2.2-&gt;spacy&lt;3.8.0,&gt;=3.7.2-&gt;en-core-web-md==3.7.1) (0.7.11)\nRequirement already satisfied: confection&lt;1.0.0,&gt;=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc&lt;8.3.0,&gt;=8.2.2-&gt;spacy&lt;3.8.0,&gt;=3.7.2-&gt;en-core-web-md==3.7.1) (0.1.5)\nRequirement already satisfied: click&gt;=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer&lt;1.0.0,&gt;=0.3.0-&gt;spacy&lt;3.8.0,&gt;=3.7.2-&gt;en-core-web-md==3.7.1) (8.1.8)\nRequirement already satisfied: shellingham&gt;=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer&lt;1.0.0,&gt;=0.3.0-&gt;spacy&lt;3.8.0,&gt;=3.7.2-&gt;en-core-web-md==3.7.1) (1.5.4)\nRequirement already satisfied: rich&gt;=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer&lt;1.0.0,&gt;=0.3.0-&gt;spacy&lt;3.8.0,&gt;=3.7.2-&gt;en-core-web-md==3.7.1) (13.9.4)\nRequirement already satisfied: cloudpathlib&lt;1.0.0,&gt;=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel&lt;0.5.0,&gt;=0.1.0-&gt;spacy&lt;3.8.0,&gt;=3.7.2-&gt;en-core-web-md==3.7.1) (0.21.0)\nRequirement already satisfied: smart-open&lt;8.0.0,&gt;=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel&lt;0.5.0,&gt;=0.1.0-&gt;spacy&lt;3.8.0,&gt;=3.7.2-&gt;en-core-web-md==3.7.1) (7.1.0)\nRequirement already satisfied: MarkupSafe&gt;=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2-&gt;spacy&lt;3.8.0,&gt;=3.7.2-&gt;en-core-web-md==3.7.1) (3.0.2)\nRequirement already satisfied: marisa-trie&gt;=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data&gt;=1.2-&gt;langcodes&lt;4.0.0,&gt;=3.2.0-&gt;spacy&lt;3.8.0,&gt;=3.7.2-&gt;en-core-web-md==3.7.1) (1.2.1)\nRequirement already satisfied: markdown-it-py&gt;=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich&gt;=10.11.0-&gt;typer&lt;1.0.0,&gt;=0.3.0-&gt;spacy&lt;3.8.0,&gt;=3.7.2-&gt;en-core-web-md==3.7.1) (3.0.0)\nRequirement already satisfied: pygments&lt;3.0.0,&gt;=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich&gt;=10.11.0-&gt;typer&lt;1.0.0,&gt;=0.3.0-&gt;spacy&lt;3.8.0,&gt;=3.7.2-&gt;en-core-web-md==3.7.1) (2.18.0)\nRequirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open&lt;8.0.0,&gt;=5.2.1-&gt;weasel&lt;0.5.0,&gt;=0.1.0-&gt;spacy&lt;3.8.0,&gt;=3.7.2-&gt;en-core-web-md==3.7.1) (1.17.2)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py&gt;=2.2.0-&gt;rich&gt;=10.11.0-&gt;typer&lt;1.0.0,&gt;=0.3.0-&gt;spacy&lt;3.8.0,&gt;=3.7.2-&gt;en-core-web-md==3.7.1) (0.1.2)\nInstalling collected packages: en-core-web-md\nSuccessfully installed en-core-web-md-3.7.1\nâœ” Download and installation successful\nYou can now load the package via spacy.load('en_core_web_md')\nâš  Restart to reload dependencies\nIf you are in a Jupyter or Colab notebook, you may need to restart Python in\norder to load all the package's dependencies. You can do this by selecting the\n'Restart kernel' or 'Restart runtime' option.\nTop recommendations using Word Embeddings:\n                                             title  \\\n6039                               A Haunted House   \n4010  Jeff Dunham's Very Special Christmas Special   \n4009             Jeff Dunham: Minding the Monsters   \n3733           Adam Devine: Best Time of Our Lives   \n4474                                 Santo CachÃƒÂ³n   \n\n                                            listed_in   type  \n6039                          Comedies, Horror Movies  Movie  \n4010                                  Stand-Up Comedy  Movie  \n4009                                  Stand-Up Comedy  Movie  \n3733                                  Stand-Up Comedy  Movie  \n4474  Comedies, International Movies, Romantic Movies  Movie  \n\n\n\ndef recommend_titles(user_genre, user_type, user_actor, user_sentiment, user_description, top_n=5, method=\"tfidf\"):\n    \"\"\"\n    Recommend titles based on user inputs and similarity measure.\n\n    Parameters:\n      user_genre (str): Desired genre(s)\n      user_type (str): 'Movie' or 'TV Show'\n      user_actor (str): Actor/actress names\n      user_sentiment (str): Sentiment descriptors (e.g., 'funny', 'heartwarming')\n      user_description (str): Additional keywords\n      top_n (int): Number of recommendations to return\n      method (str): 'tfidf' or 'embedding' for similarity calculation\n\n    Returns:\n      DataFrame: Top recommended titles.\n    \"\"\"\n    # Combine user inputs into a query string\n    user_query = f\"{user_genre} {user_type} {user_actor} {user_sentiment} {user_description}\"\n\n    if method == \"tfidf\":\n        query_vec = vectorizer.transform([user_query])\n        sims = cosine_similarity(query_vec, tfidf_matrix).flatten()\n    elif method == \"embedding\":\n        query_vec = get_doc_vector(user_query)\n        sims = cosine_similarity([query_vec], doc_vectors).flatten()\n    else:\n        raise ValueError(\"Method must be either 'tfidf' or 'embedding'\")\n\n    top_indices = np.argsort(sims)[::-1][:top_n]\n    return df.iloc[top_indices][['title', 'listed_in', 'type']], sims[top_indices]\n\n# Test the recommendation function\nuser_genre = \"Comedy\"\nuser_type = \"Movie\"\nuser_actor = \"Adam Sandler\"\nuser_sentiment = \"funny heartwarming\"\nuser_description = \"family vacation\"\nrecommended_titles, sim_scores = recommend_titles(\n    user_genre, user_type, user_actor, user_sentiment, user_description, top_n=5, method=\"tfidf\"\n)\n\nprint(\"Recommended Titles (TF-IDF):\")\nprint(recommended_titles)\nprint(\"Similarity Scores:\", sim_scores)\n\nRecommended Titles (TF-IDF):\n                        title                           listed_in     type\n4482  ADAM SANDLER 100% FRESH                     Stand-Up Comedy    Movie\n1879          Hubie Halloween             Comedies, Horror Movies    Movie\n6089    Adam Ruins Everything                         TV Comedies  TV Show\n5639      Jim Gaffigan: Cinco                     Stand-Up Comedy    Movie\n6271          Bedtime Stories  Children & Family Movies, Comedies    Movie\nSimilarity Scores: [0.3720682  0.22767894 0.1952869  0.17793935 0.16485729]\n\n\n\n\nrecommendation system\n\n# Example: user-based inputs to get recommendations\n\ndef recommend_titles(user_genre, user_type, user_actor, user_sentiment, user_description, top_n=5, method=\"tfidf\"):\n    \"\"\"\n    Return recommended titles based on user inputs and similarity measure.\n\n    Parameters:\n      user_genre (str): Desired genre(s)\n      user_type (str): 'Movie' or 'TV Show'\n      user_actor (str): Actor/actress name(s)\n      user_sentiment (str): Sentiment descriptors (e.g., 'funny', 'heartwarming')\n      user_description (str): Additional keywords\n      top_n (int): Number of recommendations to return\n      method (str): 'tfidf' or 'embedding' for similarity calculation\n\n    Returns:f\n    \"\"\"\n    # Combine the user inputs into a single query string\n    user_query = f\"{user_genre} {user_type} {user_actor} {user_sentiment} {user_description}\"\n\n    if method == \"tfidf\":\n        # Vectorize the user query using the same TF-IDF vectorizer used for your dataset\n        query_vec = vectorizer.transform([user_query])\n        # Compute cosine similarity with the dataset's TF-IDF matrix\n        sims = cosine_similarity(query_vec, X_tfidf).flatten()\n    elif method == \"embedding\":\n        # If you have an embedding-based approach, implement it here\n        query_vec = get_doc_vector(user_query)  # e.g., spaCy or other embedding\n        sims = cosine_similarity([query_vec], doc_vectors).flatten()\n    else:\n        raise ValueError(\"Method must be either 'tfidf' or 'embedding'\")\n\n    # Retrieve the indices of the most similar titles\n    top_indices = np.argsort(sims)[::-1][:top_n]\n\n    # Return the top_n recommendations and their similarity scores\n    recommendations = df.iloc[top_indices][['title', 'listed_in', 'type']]\n    return recommendations, sims[top_indices]\n\n\n# ---------------------------\n# Main code that prompts user input\n# ---------------------------\n\nif __name__ == \"__main__\":\n    # Prompt user for inputs\n    user_genre = input(\"Enter your preferred genre (e.g., 'Comedy'): \")\n    user_type = input(\"Enter your preferred type (e.g., 'Movie' or 'TV Show'): \")\n    user_actor = input(\"Enter an actor/actress name (optional): \")\n    user_sentiment = input(\"Enter sentiment words (e.g., 'funny', 'heartwarming'): \")\n    user_description = input(\"Enter additional description keywords: \")\n\n    # Call the recommendation function\n    recommended_titles, sim_scores = recommend_titles(\n        user_genre=user_genre,\n        user_type=user_type,\n        user_actor=user_actor,\n        user_sentiment=user_sentiment,\n        user_description=user_description,\n        top_n=5,             # Number of recommendations\n        method=\"tfidf\"       # or \"embedding\" if you have an embedding approach\n    )\n\n    # Display results\n    print(\"\\nRecommended Titles (TF-IDF):\")\n    print(recommended_titles)\n    print(\"\\nSimilarity Scores:\")\n    print(sim_scores)\n\nEnter your preferred genre (e.g., 'Comedy'): comedy\nEnter your preferred type (e.g., 'Movie' or 'TV Show'): movie\nEnter an actor/actress name (optional): Adam Sandler\nEnter sentiment words (e.g., 'funny', 'heartwarming'): funny heartwarming\nEnter additional description keywords: family vacation\n\n\n\n---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\n&lt;ipython-input-58-42b89ff5dd84&gt; in &lt;cell line: 0&gt;()\n     52 \n     53     # Call the recommendation function\n---&gt; 54     recommended_titles, sim_scores = recommend_titles(\n     55         user_genre=user_genre,\n     56         user_type=user_type,\n\n&lt;ipython-input-58-42b89ff5dd84&gt; in recommend_titles(user_genre, user_type, user_actor, user_sentiment, user_description, top_n, method)\n     23         query_vec = vectorizer.transform([user_query])\n     24         # Compute cosine similarity with the dataset's TF-IDF matrix\n---&gt; 25         sims = cosine_similarity(query_vec, X_tfidf).flatten()\n     26     elif method == \"embedding\":\n     27         # If you have an embedding-based approach, implement it here\n\n/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py in wrapper(*args, **kwargs)\n    214                     )\n    215                 ):\n--&gt; 216                     return func(*args, **kwargs)\n    217             except InvalidParameterError as e:\n    218                 # When the function is just a wrapper around an estimator, we allow\n\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/pairwise.py in cosine_similarity(X, Y, dense_output)\n   1739     # to avoid recursive import\n   1740 \n-&gt; 1741     X, Y = check_pairwise_arrays(X, Y)\n   1742 \n   1743     X_normalized = normalize(X, copy=True)\n\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/pairwise.py in check_pairwise_arrays(X, Y, precomputed, dtype, accept_sparse, force_all_finite, ensure_all_finite, ensure_2d, copy)\n    227         # Only check the number of features if 2d arrays are enforced. Otherwise,\n    228         # validation is left to the user for custom metrics.\n--&gt; 229         raise ValueError(\n    230             \"Incompatible dimension for X and Y matrices: \"\n    231             \"X.shape[1] == %d while Y.shape[1] == %d\" % (X.shape[1], Y.shape[1])\n\nValueError: Incompatible dimension for X and Y matrices: X.shape[1] == 47360 while Y.shape[1] == 17008\n\n\n\n\nimport numpy as np\nimport pandas as pd\nimport re\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\n\n# Assume you have these pre-defined:\n# 1) df: Your Netflix dataset (DataFrame)\n# 2) tfidf_matrix: TF-IDF matrix for df['combined_features'] or df['description']\n# 3) vectorizer: The fitted TfidfVectorizer\n# 4) doc_vectors: (Optional) for embedding approach\n# 5) get_doc_vector: A function for embedding approach\n\ndef recommend_titles(user_genre, user_type, user_actor, user_sentiment, user_description, top_n=5, method=\"tfidf\"):\n    \"\"\"\n    Recommend titles based on user inputs and similarity measure.\n\n    Parameters:\n      user_genre (str): Desired genre(s)\n      user_type (str): 'Movie' or 'TV Show'\n      user_actor (str): Actor/actress names\n      user_sentiment (str): Sentiment descriptors (e.g., 'funny', 'heartwarming')\n      user_description (str): Additional keywords\n      top_n (int): Number of recommendations to return\n      method (str): 'tfidf' or 'embedding' for similarity calculation\n\n    Returns:\n      (DataFrame, np.ndarray): A tuple containing the top recommended titles\n                               and their similarity scores.\n    \"\"\"\n    # Combine user inputs into a query string\n    user_query = f\"{user_genre} {user_type} {user_actor} {user_sentiment} {user_description}\"\n\n    if method == \"tfidf\":\n        # Vectorize the user query with the same TF-IDF vectorizer\n        query_vec = vectorizer.transform([user_query])\n        # Compute cosine similarity with the TF-IDF matrix of your dataset\n        sims = cosine_similarity(query_vec, tfidf_matrix).flatten()\n    elif method == \"embedding\":\n        # If you have an embedding-based approach, convert user_query to embeddings\n        query_vec = get_doc_vector(user_query)\n        sims = cosine_similarity([query_vec], doc_vectors).flatten()\n    else:\n        raise ValueError(\"Method must be either 'tfidf' or 'embedding'\")\n\n    # Get indices of the top_n most similar titles\n    top_indices = np.argsort(sims)[::-1][:top_n]\n\n    # Return the recommended titles and their similarity scores\n    return df.iloc[top_indices][['title', 'listed_in', 'type']], sims[top_indices]\n\n# -------------------------------\n# Main code prompting user input\n# -------------------------------\nif __name__ == \"__main__\":\n    # Prompt user for inputs\n    user_genre = input(\"Enter your preferred genre (e.g., 'Comedy'): \")\n    user_type = input(\"Enter your preferred type (e.g., 'Movie' or 'TV Show'): \")\n    user_actor = input(\"Enter an actor/actress name (optional): \")\n    user_sentiment = input(\"Enter sentiment words (e.g., 'funny', 'heartwarming'): \")\n    user_description = input(\"Enter additional keywords (optional): \")\n\n    # Call the recommendation function\n    recommended_titles, sim_scores = recommend_titles(\n        user_genre=user_genre,\n        user_type=user_type,\n        user_actor=user_actor,\n        user_sentiment=user_sentiment,\n        user_description=user_description,\n        top_n=5,             # Number of recommendations\n        method=\"tfidf\"       # or \"embedding\" if you have an embedding approach\n    )\n\n    # Display results\n    print(\"\\nRecommended Titles (TF-IDF):\")\n    print(recommended_titles)\n    print(\"\\nSimilarity Scores:\")\n    print(sim_scores)\n\nEnter your preferred genre (e.g., 'Comedy'): comedy\nEnter your preferred type (e.g., 'Movie' or 'TV Show'): movie\nEnter an actor/actress name (optional): tom\nEnter sentiment words (e.g., 'funny', 'heartwarming'): funny\nEnter additional keywords (optional): vacation\n\nRecommended Titles (TF-IDF):\n                                 title  \\\n5639               Jim Gaffigan: Cinco   \n5379     Tom Segura: Completely Normal   \n3388         Jenny Slate: Stage Fright   \n4184  Trigger Warning with Killer Mike   \n2782              Tom Segura: Ball Hog   \n\n                                     listed_in     type  \n5639                           Stand-Up Comedy    Movie  \n5379                           Stand-Up Comedy    Movie  \n3388            Documentaries, Stand-Up Comedy    Movie  \n4184  Docuseries, Stand-Up Comedy & Talk Shows  TV Show  \n2782                           Stand-Up Comedy    Movie  \n\nSimilarity Scores:\n[0.25348861 0.19996897 0.1802892  0.17971545 0.17850016]"
  },
  {
    "objectID": "index.html#featured-projects",
    "href": "index.html#featured-projects",
    "title": "Home",
    "section": "ğŸš€ Featured Projects",
    "text": "ğŸš€ Featured Projects\n\nğŸ½ï¸ Yelp Restaurant Ratings Analysis\nExplored rating trends across cuisines and modeled restaurant success using machine learning.\nTools: Python, Pandas, Random Forest, KNN, Data Visualization\n\n\nğŸ¦ Bank Customer Churn Prediction\nUsed SMOTE and Random Forest to predict attrition and inform retention.\nTools: Python, Scikit-learn\n\n\nğŸ¬ Netflix Recommender & Chatbot\nNLP + chatbot-based content recommendation engine.\nTools: Python, TF-IDF, Cosine Similarity\nğŸ—‚ï¸ View All Projects â†’"
  },
  {
    "objectID": "about.html#jessica-felicia",
    "href": "about.html#jessica-felicia",
    "title": "About Me",
    "section": "ğŸ‘©ğŸ¼â€ğŸ’¼ Jessica Felicia",
    "text": "ğŸ‘©ğŸ¼â€ğŸ’¼ Jessica Felicia\nM.S. in Business Analytics\nPaul Merage School of Business, UC Irvine\nI combine a technical background with a deep interest in solving business problems through data, particularly in marketing analytics, customer insights, and data visualization. My recent work spans customer churn prediction, clustering, recommendation systems, and real-world product and campaign insights.\n\nğŸ’¼ Recent Experience\nStudent Data Analyst â€“ Obagi Medical\nImproved retention tracking and reduced churn risk using cohort analysis and Tableau dashboards. Delivered strategic insights for the marketing team.\nProduct Documentation Specialist â€“ Lin-Zhi International\nMaintained technical documentation and streamlined approval workflows, supporting QA and R&D.\nContent Analyst â€“ Yahoo\nTransformed unstructured data (HTML/XPath) into classified datasets for improving content discovery.\n\n\nğŸ§ª Skills & Tools\nLanguages: Python, SQL, Java, R, HTML\nTools: Tableau, Excel, Git, Google Colab\nLibraries: Pandas, Scikit-learn, Seaborn, Matplotlib\nDatabase: MySQL, NoSQL\nTech: Jupyter, VS Code, GitHub, Regex\n\n\nğŸ“Œ Project Experience\n\nChurn Analysis (Obagi) â€“ Predicted attrition trends, created retention rate dashboards\n\nCustomer Segmentation â€“ Applied K-means to group travelers\n\nNetflix Chatbot & Recommender â€“ Built NLP-based system using TF-IDF + clustering\n\nYelp Rating Analysis â€“ Modeled predictors of restaurant success by cuisine and location\n\nSentiment Analysis (Amazon Reviews) â€“ Classified product reviews using VADER + ML\n\nBank Churn Prediction (Machine Learning) â€“ Used SMOTE & Random Forest to identify high-risk customers\n\n\n\nğŸ¯ Interests\n\nCustomer Retention & Engagement\n\nCampaign Optimization & Analytics\n\nBehavioral Clustering & Segmentation\n\nData Storytelling & Dashboarding\n\n\n\nğŸ¤ Letâ€™s Connect\nğŸ“§ Email\nğŸ”— LinkedIn"
  },
  {
    "objectID": "projects/Yelp-Restaurant-Rating/Yelp Analysis.html",
    "href": "projects/Yelp-Restaurant-Rating/Yelp Analysis.html",
    "title": "My Portfolio",
    "section": "",
    "text": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\n#Read the excel dataset\nYelp = pd.read_excel('/content/data programming project - yelp.xlsx')\n\n\n# Overview of the dataset\n#print(Yelp.head())\nprint(Yelp.info())\n#print(Yelp.describe())\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 2176 entries, 0 to 2175\nData columns (total 36 columns):\n #   Column                          Non-Null Count  Dtype  \n---  ------                          --------------  -----  \n 0   Name                            2176 non-null   object \n 1   Phone                           2073 non-null   object \n 2   Address                         2117 non-null   object \n 3   Email                           982 non-null    object \n 4   Website                         1683 non-null   object \n 5   ServiceArea                     12 non-null     object \n 6   Instagram                       1106 non-null   object \n 7   Facebook                        1046 non-null   object \n 8   Twitter                         268 non-null    object \n 9   Linkedin                        70 non-null     object \n 10  Youtube                         108 non-null    object \n 11  BusinessUrl                     2176 non-null   object \n 12  Rating                          2176 non-null   float64\n 13  ReviewCount                     2176 non-null   int64  \n 14  PriceRange                      1586 non-null   object \n 15  Longitude                       2176 non-null   float64\n 16  Latitude                        2176 non-null   float64\n 17  Alias                           2176 non-null   object \n 18  BizId                           2176 non-null   object \n 19  BusinessSectionUrls_open_hours  2176 non-null   object \n 20  BusinessSectionUrls_reviews     2176 non-null   object \n 21  Categories_0_title              2176 non-null   object \n 22  Categories_0_url                2176 non-null   object \n 23  Categories_1_title              1603 non-null   object \n 24  Categories_1_url                1603 non-null   object \n 25  Categories_2_title              1032 non-null   object \n 26  Categories_2_url                1032 non-null   object \n 27  FormattedAddress                0 non-null      float64\n 28  IsAd                            2176 non-null   bool   \n 29  Neighborhoods_0                 846 non-null    object \n 30  Open_time                       0 non-null      float64\n 31  ParentBusiness                  0 non-null      float64\n 32  Ranking                         2176 non-null   int64  \n 33  RenderAdInfo                    2176 non-null   bool   \n 34  ServicePricing                  0 non-null      float64\n 35  Snippet                         2150 non-null   object \ndtypes: bool(2), float64(7), int64(2), object(25)\nmemory usage: 582.4+ KB\nNone\n\n\n\n# Drop columns with more than 50% missing values as well as columns that are redundant\nYelp = Yelp.dropna(thresh=Yelp.shape[0] * 0.5, axis=1)\nYelp = Yelp.drop(columns=['Website','BusinessUrl','Alias','BizId','BusinessSectionUrls_open_hours','BusinessSectionUrls_reviews','IsAd','RenderAdInfo','Categories_0_url','Categories_1_title', 'Categories_1_url'])\n\n\nprint(Yelp.info(10))\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 2176 entries, 0 to 2175\nData columns (total 12 columns):\n #   Column              Non-Null Count  Dtype  \n---  ------              --------------  -----  \n 0   Name                2176 non-null   object \n 1   Phone               2073 non-null   object \n 2   Address             2117 non-null   object \n 3   Instagram           1106 non-null   object \n 4   Rating              2176 non-null   float64\n 5   ReviewCount         2176 non-null   int64  \n 6   PriceRange          1586 non-null   object \n 7   Longitude           2176 non-null   float64\n 8   Latitude            2176 non-null   float64\n 9   Categories_0_title  2176 non-null   object \n 10  Ranking             2176 non-null   int64  \n 11  Snippet             2150 non-null   object \ndtypes: float64(3), int64(2), object(7)\nmemory usage: 204.1+ KB\nNone\n\n\n\nprint(\"Number of rows (datasets) in the data:\", len(Yelp))\n\nNumber of rows (datasets) in the data: 2176\n\n\n\n#Count missing values in each categories\nmissing_per_column = Yelp.isnull().sum()\nprint(missing_per_column)\n\nName                     0\nPhone                  103\nAddress                 59\nInstagram             1070\nRating                   0\nReviewCount              0\nPriceRange             590\nLongitude                0\nLatitude                 0\nCategories_0_title       0\nRanking                  0\nSnippet                 26\ndtype: int64\n\n\n\n#We will use only Categories 0 title as ou main cuisine type as it has no missing values and correctly represent the true cuisine type of the restaurant\n#Find the most popular cuisine type in the dataset (Top 10)\nfood_category = Yelp['Categories_0_title'].value_counts()\ntop_10 = food_category.head(10)\nprint(top_10)\nplt.figure(figsize=(8, 4))\nsns.barplot(x=top_10.index,y=top_10.values,palette='pastel')\nplt.xlabel('Category')\nplt.ylabel('Count')\nplt.title('Top 10 Cuisine Type by Count')\nplt.xticks(rotation=45)\nplt.show()\n\nCategories_0_title\nMexican          161\nNew American     110\nItalian          108\nKorean            95\nSeafood           93\nJapanese          90\nPizza             80\nMediterranean     62\nChinese           59\nThai              58\nName: count, dtype: int64\n\n\nFutureWarning: \n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n\n  sns.barplot(x=top_10.index,y=top_10.values,palette='pastel')\n\n\n\n\n\n\n\n\n\n\n#Scatter plot to see the correlation between number of reviews and star ratings\nplt.figure(figsize=(8, 4))\nplt.scatter(Yelp['ReviewCount'], Yelp['Rating'], alpha=0.3, color='blue')\nplt.xlabel('Number of Reviews')\nplt.ylabel('Star Ratings')\nplt.title('Scatter Plot: Star Ratings vs. Number of Reviews')\nplt.show()\n\n\n\n\n\n\n\n\n\n# Calculate the correlation between 'ReviewCount' and 'Rating_numeric'\ncorrelation = Yelp['ReviewCount'].corr(Yelp['Rating'])\nprint(f\"Correlation between ReviewCount and Rating: {correlation}\")\n\nCorrelation between ReviewCount and Rating: 0.003222962567526092\n\n\n\n# boxplot to show rating distribution by cuisine types\ntop_categories = Yelp['Categories_0_title'].value_counts().head(10).index\nfiltered_data = Yelp[Yelp['Categories_0_title'].isin(top_categories)]\n\nplt.figure(figsize=(10, 6))\nsns.boxplot(x='Categories_0_title', y='Rating', data=filtered_data, palette=\"Set3\",order=top_categories)\n\nplt.xticks(rotation=45, ha='right')\nplt.title('Rating Distributions (Top 10 Cuisine Types)', fontsize=16)\nplt.xlabel('Cuisine Type', fontsize=14)\nplt.ylabel('Ratings', fontsize=14)\n\nplt.tight_layout()\nplt.show()\n\nFutureWarning: \n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n\n  sns.boxplot(x='Categories_0_title', y='Rating', data=filtered_data, palette=\"Set3\",order=top_categories)\n\n\n\n\n\n\n\n\n\n\n#Correlation between restaurant ranking and star ratings\ncorrelation = Yelp['Ranking'].corr(Yelp['Rating'])\nprint(\"Correlation between Review Count and Rating:\", correlation)\n\nCorrelation between Review Count and Rating: -0.12806450476948608\n\n\n\n#Most prevalent positive and negative words from the cuisine type\nfrom textblob import TextBlob\nfrom wordcloud import WordCloud\nimport matplotlib.pyplot as plt\n\n# Filter data for a specific cuisine type\ncuisine_type = \"Mexican\"\nfiltered_data = Yelp[Yelp['Categories_0_title'] == cuisine_type].copy()\n\n# Function to determine sentiment polarity\ndef get_sentiment(text):\n    try:\n        analysis = TextBlob(str(text))  # Ensure text is converted to a string\n        return \"Positive\" if analysis.sentiment.polarity &gt; 0 else \"Negative\"\n    except:\n        return \"Neutral\"\n\n# Drop NaN values in 'Snippet' and apply sentiment analysis\nfiltered_data = filtered_data.dropna(subset=['Snippet'])\nfiltered_data['Sentiment'] = filtered_data['Snippet'].apply(get_sentiment)\n\n# Combine positive and negative review snippets\npositive_reviews = \" \".join(filtered_data[filtered_data['Sentiment'] == \"Positive\"]['Snippet'])\nnegative_reviews = \" \".join(filtered_data[filtered_data['Sentiment'] == \"Negative\"]['Snippet'])\n\n# Generate word clouds\npositive_wordcloud = WordCloud(width=800, height=400, background_color='white', colormap='Blues').generate(positive_reviews)\nnegative_wordcloud = WordCloud(width=800, height=400, background_color='white', colormap='Reds').generate(negative_reviews)\n\n# Plot the word clouds\nplt.figure(figsize=(16, 8))\n\n# Positive word cloud\nplt.subplot(1, 2, 1)\nplt.imshow(positive_wordcloud, interpolation='bilinear')\nplt.title(f\"Positive Reviews Word Cloud ({cuisine_type})\", fontsize=16)\nplt.axis('off')\n\n# Negative word cloud\nplt.subplot(1, 2, 2)\nplt.imshow(negative_wordcloud, interpolation='bilinear')\nplt.title(f\"Negative Reviews Word Cloud ({cuisine_type})\", fontsize=16)\nplt.axis('off')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n#Most prevalent positive and negative words from the cuisine type\nfrom textblob import TextBlob\nfrom wordcloud import WordCloud\nimport matplotlib.pyplot as plt\n\n# Filter data for a specific cuisine type\ncuisine_type = \"Chinese\"\nfiltered_data = Yelp[Yelp['Categories_0_title'] == cuisine_type].copy()\n\n# Function to determine sentiment polarity\ndef get_sentiment(text):\n    try:\n        analysis = TextBlob(str(text))  # Ensure text is converted to a string\n        return \"Positive\" if analysis.sentiment.polarity &gt; 0 else \"Negative\"\n    except:\n        return \"Neutral\"\n\n# Drop NaN values in 'Snippet' and apply sentiment analysis\nfiltered_data = filtered_data.dropna(subset=['Snippet'])\nfiltered_data['Sentiment'] = filtered_data['Snippet'].apply(get_sentiment)\n\n# Combine positive and negative review snippets\npositive_reviews = \" \".join(filtered_data[filtered_data['Sentiment'] == \"Positive\"]['Snippet'])\nnegative_reviews = \" \".join(filtered_data[filtered_data['Sentiment'] == \"Negative\"]['Snippet'])\n\n# Generate word clouds\npositive_wordcloud = WordCloud(width=800, height=400, background_color='white', colormap='Blues').generate(positive_reviews)\nnegative_wordcloud = WordCloud(width=800, height=400, background_color='white', colormap='Reds').generate(negative_reviews)\n\n# Plot the word clouds\nplt.figure(figsize=(16, 8))\n\n# Positive word cloud\nplt.subplot(1, 2, 1)\nplt.imshow(positive_wordcloud, interpolation='bilinear')\nplt.title(f\"Positive Reviews Word Cloud ({cuisine_type})\", fontsize=16)\nplt.axis('off')\n\n# Negative word cloud\nplt.subplot(1, 2, 2)\nplt.imshow(negative_wordcloud, interpolation='bilinear')\nplt.title(f\"Negative Reviews Word Cloud ({cuisine_type})\", fontsize=16)\nplt.axis('off')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n#Most prevalent positive and negative words from the cuisine type\nfrom textblob import TextBlob\nfrom wordcloud import WordCloud\nimport matplotlib.pyplot as plt\n\n# Filter data for a specific cuisine type\ncuisine_type = \"Italian\"\nfiltered_data = Yelp[Yelp['Categories_0_title'] == cuisine_type].copy()\n\n# Function to determine sentiment polarity\ndef get_sentiment(text):\n    try:\n        analysis = TextBlob(str(text))  # Ensure text is converted to a string\n        return \"Positive\" if analysis.sentiment.polarity &gt; 0 else \"Negative\"\n    except:\n        return \"Neutral\"\n\n# Drop NaN values in 'Snippet' and apply sentiment analysis\nfiltered_data = filtered_data.dropna(subset=['Snippet'])\nfiltered_data['Sentiment'] = filtered_data['Snippet'].apply(get_sentiment)\n\n# Combine positive and negative review snippets\npositive_reviews = \" \".join(filtered_data[filtered_data['Sentiment'] == \"Positive\"]['Snippet'])\nnegative_reviews = \" \".join(filtered_data[filtered_data['Sentiment'] == \"Negative\"]['Snippet'])\n\n# Generate word clouds\npositive_wordcloud = WordCloud(width=800, height=400, background_color='white', colormap='Blues').generate(positive_reviews)\nnegative_wordcloud = WordCloud(width=800, height=400, background_color='white', colormap='Reds').generate(negative_reviews)\n\n# Plot the word clouds\nplt.figure(figsize=(16, 8))\n\n# Positive word cloud\nplt.subplot(1, 2, 1)\nplt.imshow(positive_wordcloud, interpolation='bilinear')\nplt.title(f\"Positive Reviews Word Cloud ({cuisine_type})\", fontsize=16)\nplt.axis('off')\n\n# Negative word cloud\nplt.subplot(1, 2, 2)\nplt.imshow(negative_wordcloud, interpolation='bilinear')\nplt.title(f\"Negative Reviews Word Cloud ({cuisine_type})\", fontsize=16)\nplt.axis('off')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n#Most prevalent positive and negative words from the cuisine type\nfrom textblob import TextBlob\nfrom wordcloud import WordCloud\nimport matplotlib.pyplot as plt\n\n# Filter data for a specific cuisine type\ncuisine_type = \"Seafood\"\nfiltered_data = Yelp[Yelp['Categories_0_title'] == cuisine_type].copy()\n\n# Function to determine sentiment polarity\ndef get_sentiment(text):\n    try:\n        analysis = TextBlob(str(text))  # Ensure text is converted to a string\n        return \"Positive\" if analysis.sentiment.polarity &gt; 0 else \"Negative\"\n    except:\n        return \"Neutral\"\n\n# Drop NaN values in 'Snippet' and apply sentiment analysis\nfiltered_data = filtered_data.dropna(subset=['Snippet'])\nfiltered_data['Sentiment'] = filtered_data['Snippet'].apply(get_sentiment)\n\n# Combine positive and negative review snippets\npositive_reviews = \" \".join(filtered_data[filtered_data['Sentiment'] == \"Positive\"]['Snippet'])\nnegative_reviews = \" \".join(filtered_data[filtered_data['Sentiment'] == \"Negative\"]['Snippet'])\n\n# Generate word clouds\npositive_wordcloud = WordCloud(width=800, height=400, background_color='white', colormap='Blues').generate(positive_reviews)\nnegative_wordcloud = WordCloud(width=800, height=400, background_color='white', colormap='Reds').generate(negative_reviews)\n\n# Plot the word clouds\nplt.figure(figsize=(16, 8))\n\n# Positive word cloud\nplt.subplot(1, 2, 1)\nplt.imshow(positive_wordcloud, interpolation='bilinear')\nplt.title(f\"Positive Reviews Word Cloud ({cuisine_type})\", fontsize=16)\nplt.axis('off')\n\n# Negative word cloud\nplt.subplot(1, 2, 2)\nplt.imshow(negative_wordcloud, interpolation='bilinear')\nplt.title(f\"Negative Reviews Word Cloud ({cuisine_type})\", fontsize=16)\nplt.axis('off')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n#Plot map to see if the location of the restaurant is correlated with the ratings\n!pip install pandas geopandas folium matplotlib\nimport folium\nfrom folium.plugins import MarkerCluster\n\nfiltered_data = Yelp[['Rating', 'Latitude', 'Longitude']].dropna()\n\naverage_lat = filtered_data['Latitude'].mean()\naverage_lon = filtered_data['Longitude'].mean()\nrating_map = folium.Map(location=[average_lat, average_lon], zoom_start=10)\n\nmarker_cluster = MarkerCluster().add_to(rating_map)\n\nfor index, row in filtered_data.iterrows():\n    folium.CircleMarker(\n        location=(row['Latitude'], row['Longitude']),\n        radius=5,\n        color='blue',\n        fill=True,\n        fill_opacity=0.7,\n        fill_color='green' if row['Rating'] &gt;= 4 else 'red',\n        popup=f\"Rating: {row['Rating']}\"\n    ).add_to(marker_cluster)\n\nrating_map.save(\"ratings_map.html\")\nrating_map\n\n\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\nRequirement already satisfied: geopandas in /usr/local/lib/python3.10/dist-packages (1.0.1)\nRequirement already satisfied: folium in /usr/local/lib/python3.10/dist-packages (0.18.0)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\nRequirement already satisfied: numpy&gt;=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\nRequirement already satisfied: python-dateutil&gt;=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\nRequirement already satisfied: pytz&gt;=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\nRequirement already satisfied: tzdata&gt;=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\nRequirement already satisfied: pyogrio&gt;=0.7.2 in /usr/local/lib/python3.10/dist-packages (from geopandas) (0.10.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from geopandas) (24.2)\nRequirement already satisfied: pyproj&gt;=3.3.0 in /usr/local/lib/python3.10/dist-packages (from geopandas) (3.7.0)\nRequirement already satisfied: shapely&gt;=2.0.0 in /usr/local/lib/python3.10/dist-packages (from geopandas) (2.0.6)\nRequirement already satisfied: branca&gt;=0.6.0 in /usr/local/lib/python3.10/dist-packages (from folium) (0.8.0)\nRequirement already satisfied: jinja2&gt;=2.9 in /usr/local/lib/python3.10/dist-packages (from folium) (3.1.4)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from folium) (2.32.3)\nRequirement already satisfied: xyzservices in /usr/local/lib/python3.10/dist-packages (from folium) (2024.9.0)\nRequirement already satisfied: contourpy&gt;=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\nRequirement already satisfied: cycler&gt;=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: fonttools&gt;=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.1)\nRequirement already satisfied: kiwisolver&gt;=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\nRequirement already satisfied: pillow&gt;=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.0.0)\nRequirement already satisfied: pyparsing&gt;=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\nRequirement already satisfied: MarkupSafe&gt;=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2&gt;=2.9-&gt;folium) (3.0.2)\nRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from pyogrio&gt;=0.7.2-&gt;geopandas) (2024.8.30)\nRequirement already satisfied: six&gt;=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil&gt;=2.8.2-&gt;pandas) (1.16.0)\nRequirement already satisfied: charset-normalizer&lt;4,&gt;=2 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;folium) (3.4.0)\nRequirement already satisfied: idna&lt;4,&gt;=2.5 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;folium) (3.10)\nRequirement already satisfied: urllib3&lt;3,&gt;=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;folium) (2.2.3)\n\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\n\n\n\n#Pre-processing the data for machine learning models\nfrom sklearn.preprocessing import LabelEncoder\n\n# Select relevant features and target\nfeatures = Yelp[['Categories_0_title', 'Longitude', 'Latitude', 'ReviewCount']]\ntarget = Yelp['Rating']\n\n# Encode the 'Cuisine_Type' column\nlabel_encoder = LabelEncoder()\nfeatures['Categories_0_title'] = label_encoder.fit_transform(features['Categories_0_title'])\n\n#Bin ratings into categories (e.g., Low, Medium, High)\n# 0 - 2 = low, 2 - 3.5 = medium, 3.5 - 5 = high\ntarget = pd.cut(target, bins=[0, 2.5, 4, 5], labels=['Low', 'Medium', 'High'])\n\nSettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  features['Categories_0_title'] = label_encoder.fit_transform(features['Categories_0_title'])\n\n\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.3, random_state=42)\n\n\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import classification_report, accuracy_score\n#handle missing values\nX_train = X_train.dropna()\ny_train = y_train.dropna()\ny_train = y_train.replace('nan', None).dropna()\ny_test = y_test.replace('nan', None).dropna()\n\nvalid_indices_train = X_train.index.intersection(y_train.index)\nX_train = X_train.loc[valid_indices_train]\ny_train = y_train.loc[valid_indices_train]\n\n# Filter y_test to remove invalid entries before predictions\nvalid_test_indices = y_test.replace('nan', None).dropna().index\ny_test_filtered = y_test.loc[valid_test_indices]\n\n\n#Decision Tree models\ndt_model = DecisionTreeClassifier(random_state=42)\ndt_model.fit(X_train, y_train)\n\n# Re-run predictions for the filtered test set\nX_test_filtered = X_test.loc[valid_test_indices]\ny_pred_dt_filtered = dt_model.predict(X_test_filtered)\n\n# Predict and evaluate\ny_pred_dt = dt_model.predict(X_test)\ny_test = y_test.astype(str)\ny_pred_dt = y_pred_dt.astype(str)\nprint(\"Decision Tree Accuracy:\", accuracy_score(y_test_filtered, y_pred_dt_filtered))\nprint(classification_report(y_test_filtered, y_pred_dt_filtered))\n\nDecision Tree Accuracy: 0.6170542635658914\n              precision    recall  f1-score   support\n\n        High       0.76      0.69      0.72       456\n         Low       0.00      0.00      0.00         6\n      Medium       0.38      0.45      0.41       183\n\n    accuracy                           0.62       645\n   macro avg       0.38      0.38      0.38       645\nweighted avg       0.64      0.62      0.63       645\n\n\n\n\n#Decision Tree model with pruning parameters\ndt_model = DecisionTreeClassifier(\n    random_state=42,\n    max_depth=5,\n    min_samples_split=10,\n    min_samples_leaf=5\n)\n\n# Train the model\ndt_model.fit(X_train, y_train)\n\n# Re-run predictions for the filtered test set\nX_test_filtered = X_test.loc[valid_test_indices]\ny_pred_dt_filtered = dt_model.predict(X_test_filtered)\n\n# Predict and evaluate\ny_pred_dt = dt_model.predict(X_test)\ny_test = y_test.astype(str)\ny_pred_dt = y_pred_dt.astype(str)\n\n# Evaluation metrics\nprint(\"Decision Tree Accuracy:\", accuracy_score(y_test_filtered, y_pred_dt_filtered))\nprint(classification_report(y_test_filtered, y_pred_dt_filtered))\n\nDecision Tree Accuracy: 0.703875968992248\n              precision    recall  f1-score   support\n\n        High       0.77      0.85      0.80       456\n         Low       0.00      0.00      0.00         6\n      Medium       0.48      0.37      0.42       183\n\n    accuracy                           0.70       645\n   macro avg       0.42      0.41      0.41       645\nweighted avg       0.68      0.70      0.69       645\n\n\n\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n\n\n\nfrom sklearn.impute import SimpleImputer\n\n# Apply SimpleImputer to fill missing values in the features with the mean (or median for better robustness)\nimputer = SimpleImputer(strategy='mean')\n\n# Impute missing values for numerical columns in the features\nfeatures_imputed = imputer.fit_transform(features)\n\n# Check for missing values after imputation\nprint(pd.DataFrame(features_imputed).isnull().sum())  # This should show no NaN values now\n\n# Drop rows with missing target values\ntarget = target.dropna()  # Remove rows with NaN in target\n\n# Make sure X aligns with the cleaned y\nfeatures_imputed = features_imputed[target.index]  # Ensure X and y are still aligned after dropping\n\nfrom sklearn.model_selection import train_test_split\n\n# Split the data\nX_train, X_test, y_train, y_test = train_test_split(features_imputed, target, test_size=0.2, random_state=42)\n\n# Check if there are any NaN values in the training and testing sets\nprint(f\"X_train NaNs: {pd.DataFrame(X_train).isnull().sum().sum()}\")\nprint(f\"y_train NaNs: {y_train.isnull().sum()}\")\nprint(f\"X_test NaNs: {pd.DataFrame(X_test).isnull().sum().sum()}\")\nprint(f\"y_test NaNs: {y_test.isnull().sum()}\")\n\n0    0\n1    0\n2    0\n3    0\ndtype: int64\nX_train NaNs: 0\ny_train NaNs: 0\nX_test NaNs: 0\ny_test NaNs: 0\n\n\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# Initialize Random Forest model\nrf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n\n# Train the model\nrf_model.fit(X_train, y_train)\n\n# Predict on the test set\ny_pred_rf = rf_model.predict(X_test)\n\n# Convert predictions and true labels to strings to handle any potential mismatches\ny_test = y_test.astype(str)\ny_pred_rf = y_pred_rf.astype(str)\n\n# Accuracy and classification report\nprint(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\nprint(classification_report(y_test, y_pred_rf))\n\n# Verify the shapes of X_test and y_test\nprint(f\"X_test shape: {X_test.shape}\")\nprint(f\"y_test shape: {y_test.shape}\")\n\nRandom Forest Accuracy: 0.7199074074074074\n              precision    recall  f1-score   support\n\n           0       0.75      0.88      0.81       284\n           1       0.00      0.00      0.00         4\n           2       0.64      0.42      0.51       144\n\n    accuracy                           0.72       432\n   macro avg       0.46      0.43      0.44       432\nweighted avg       0.70      0.72      0.70       432\n\nX_test shape: (432, 4)\ny_test shape: (432,)\n\n\n\nfrom sklearn.decomposition import PCA\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom sklearn.preprocessing import StandardScaler\n\n# Standardize the data (PCA works better with scaled data)\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Apply PCA to reduce dimensions\npca = PCA(n_components=0.95)  # Retain 95% of variance\nX_train_pca = pca.fit_transform(X_train_scaled)\nX_test_pca = pca.transform(X_test_scaled)\n\n# Initialize Random Forest model\nrf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n\n# Train the model on PCA-transformed data\nrf_model.fit(X_train_pca, y_train)\n\n# Predict on the PCA-transformed test set\ny_pred_rf = rf_model.predict(X_test_pca)\n\n# Convert predictions and true labels to strings to handle any potential mismatches\ny_test = y_test.astype(str)\ny_pred_rf = y_pred_rf.astype(str)\n\n# Accuracy and classification report\nprint(\"Random Forest Accuracy(PCA):\", accuracy_score(y_test, y_pred_rf))\nprint(classification_report(y_test, y_pred_rf))\n\n# Check how much variance is explained by the retained components\nexplained_variance = pca.explained_variance_ratio_\nprint(\"Explained Variance by PCA components:\", explained_variance)\nprint(f\"Number of PCA components retained: {pca.n_components_}\")\n\nRandom Forest Accuracy(PCA): 0.6574074074074074\n              precision    recall  f1-score   support\n\n        High       0.70      0.85      0.77       284\n         Low       0.00      0.00      0.00         4\n      Medium       0.49      0.29      0.37       144\n\n    accuracy                           0.66       432\n   macro avg       0.40      0.38      0.38       432\nweighted avg       0.62      0.66      0.63       432\n\nExplained Variance by PCA components: [0.49675527 0.25393994 0.24389005]\nNumber of PCA components retained: 3\n\n\n\n#Try to apply SMOTE to the random forest model\nfrom sklearn.impute import SimpleImputer\n\n# Impute missing values in numerical columns\nimputer = SimpleImputer(strategy='mean')\nX_train = imputer.fit_transform(X_train)\nX_test = imputer.transform(X_test)\n\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\nfrom sklearn.preprocessing import LabelEncoder\n\nlabel_encoder = LabelEncoder()\ny_train = label_encoder.fit_transform(y_train)\ny_test = label_encoder.transform(y_test)\n\nfrom sklearn.model_selection import GridSearchCV\n\nfrom imblearn.over_sampling import SMOTE\n\n# Apply SMOTE to balance the dataset\nsmote = SMOTE(random_state=42)\nX_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n\nrf_remodel = RandomForestClassifier(n_estimators=100, random_state=42)\nrf_remodel.fit(X_train_balanced, y_train_balanced)\n\n# 5. Predict on the test set\ny_pred_rf_remodel = rf_remodel.predict(X_test)\n\n# 6. Evaluate the model\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred_rf_remodel))\nprint(classification_report(y_test, y_pred_rf_remodel))\n\nAccuracy: 0.6620370370370371\n              precision    recall  f1-score   support\n\n           0       0.78      0.74      0.76       284\n           1       0.00      0.00      0.00         4\n           2       0.53      0.53      0.53       144\n\n    accuracy                           0.66       432\n   macro avg       0.44      0.42      0.43       432\nweighted avg       0.69      0.66      0.67       432\n\n\n\n\n#Cross Validation for Random Forest\nfrom sklearn.model_selection import StratifiedKFold, cross_val_score\n\nkf = StratifiedKFold(n_splits=5)\ncv_scores = cross_val_score(rf_model, X_train, y_train, cv=kf, scoring='accuracy')\nprint(\"Cross-Validation Accuracy:\", cv_scores.mean())\n\nCross-Validation Accuracy: 0.7041557128412539\n\n\n\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\n# Assuming 'features' is your dataset\n# If necessary, you can apply scaling (StandardScaler, MinMaxScaler) for better results\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nfeatures_scaled = scaler.fit_transform(features)\nwcss = []\nfor k in range(1, 11):  # Check for k values from 1 to 10\n    kmeans = KMeans(n_clusters=k, init='k-means++', max_iter=300, n_init=10, random_state=42)\n    kmeans.fit(features_scaled)\n    wcss.append(kmeans.inertia_)  # Inertia is the WCSS\nplt.figure(figsize=(8, 6))\nplt.plot(range(1, 11), wcss)\nplt.title('Elbow Method for Optimal k', fontsize=16)\nplt.xlabel('Number of Clusters (k)', fontsize=14)\nplt.ylabel('WCSS (Within-Cluster Sum of Squares)', fontsize=14)\nplt.xticks(range(1, 11))\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# Initialize KNN model\nknn_model = KNeighborsClassifier(n_neighbors=4)  # You can experiment with different values of k\n\n# Train the KNN model\nknn_model.fit(X_train, y_train)\n\n# Predict on the test set\ny_pred_knn = knn_model.predict(X_test)\n\n# Convert predictions and true labels to strings if necessary\ny_test = y_test.astype(str)\ny_pred_knn = y_pred_knn.astype(str)\n\n# Evaluate the KNN model\nprint(\"KNN Accuracy:\", accuracy_score(y_test, y_pred_knn))\nprint(classification_report(y_test, y_pred_knn))\n\n# Verify the shapes of X_test and y_test\nprint(f\"X_test shape: {X_test.shape}\")\nprint(f\"y_test shape: {y_test.shape}\")\n\nKNN Accuracy: 0.6689814814814815\n              precision    recall  f1-score   support\n\n           0       0.69      0.90      0.78       284\n           1       0.00      0.00      0.00         4\n           2       0.52      0.23      0.32       144\n\n    accuracy                           0.67       432\n   macro avg       0.41      0.38      0.37       432\nweighted avg       0.63      0.67      0.62       432\n\nX_test shape: (432, 4)\ny_test shape: (432,)\n\n\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n\n\n\n#KNN afer hyperparameter tune\nfrom sklearn.model_selection import GridSearchCV\n\n# Define parameter grid for tuning\nparam_grid = {'n_neighbors': [3, 5, 7, 9], 'weights': ['uniform', 'distance']}\n\n# Initialize GridSearchCV with cross-validation\ngrid_search = GridSearchCV(KNeighborsClassifier(), param_grid, cv=4, scoring='accuracy')\n\n# Fit the grid search\ngrid_search.fit(X_train, y_train)\n\n# Get the best parameters\nprint(\"Best Parameters:\", grid_search.best_params_)\n\n# Evaluate the model with the best parameters\nbest_knn_model = grid_search.best_estimator_\ny_pred_knn_best = best_knn_model.predict(X_test)\n\n# Convert predictions and true labels to strings if necessary\ny_test = y_test.astype(str)\ny_pred_knn_best = y_pred_knn_best.astype(str)\n\n# Accuracy and classification report for the best model\nprint(\"Best KNN Accuracy:\", accuracy_score(y_test, y_pred_knn_best))\nprint(classification_report(y_test, y_pred_knn_best))\n\nBest Parameters: {'n_neighbors': 9, 'weights': 'uniform'}\nBest KNN Accuracy: 0.6597222222222222\n              precision    recall  f1-score   support\n\n           0       0.70      0.87      0.77       284\n           1       0.00      0.00      0.00         4\n           2       0.49      0.26      0.34       144\n\n    accuracy                           0.66       432\n   macro avg       0.40      0.38      0.37       432\nweighted avg       0.62      0.66      0.62       432\n\n\n\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n\n\n\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# First, make sure to include only numeric columns for correlation\n# You can exclude non-numeric columns such as categorical columns.\ndf_numeric = Yelp.select_dtypes(include=['number'])\n\n# Compute the correlation matrix\ncorrelation_matrix = df_numeric.corr()\n\n# Print the correlation matrix\nprint(correlation_matrix)\n\n# Visualize the correlation matrix using a heatmap\nplt.figure(figsize=(10, 8))\nsns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)\nplt.title('Correlation Matrix')\nplt.show()\n\n               Rating  ReviewCount  Longitude  Latitude   Ranking\nRating       1.000000     0.003223   0.018082 -0.071159 -0.128065\nReviewCount  0.003223     1.000000   0.044630 -0.075662 -0.115116\nLongitude    0.018082     0.044630   1.000000 -0.976865 -0.025678\nLatitude    -0.071159    -0.075662  -0.976865  1.000000  0.002244\nRanking     -0.128065    -0.115116  -0.025678  0.002244  1.000000\n\n\n\n\n\n\n\n\n\n\n#Feature of importance from random forest\nimport matplotlib.pyplot as plt\n\nfeature_importances = rf_model.feature_importances_\n\n# Plot feature importances\nplt.figure(figsize=(10, 6))\nplt.bar(features.columns, feature_importances, color='skyblue')\nplt.xlabel('Features')\nplt.ylabel('Importance')\nplt.title('Feature Importance in Rating Prediction')\nplt.show()\n\n\n\n\n\n\n\n\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom imblearn.over_sampling import SMOTE\n\n# 1. Prepare features and target\nfeatures = Yelp[['Categories_0_title', 'Longitude', 'Latitude', 'ReviewCount']].copy()\nlabel_encoder = LabelEncoder()\nfeatures['Categories_0_title'] = label_encoder.fit_transform(features['Categories_0_title'].astype(str))\n\n# Bin the ratings into categories and remove NaN values\ntarget = Yelp['Rating'].dropna()\ntarget = pd.cut(target, bins=[0, 2, 3.5, 5], labels=['Low', 'Medium', 'High'])\ntarget = target.astype(str)  # Ensure the target is a string type for classification\n\n# 2. Split into training and test sets\nX_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n\n# Ensure no NaN values\nX_train = features.dropna()\ny_train = target[X_train.index]\n\n# 3. Apply SMOTE to balance classes\n# Apply SMOTE to balance classes\nsmote = SMOTE(random_state=42)\nX_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n\n# 4. Train the Decision Tree model\ndt_model = DecisionTreeClassifier(random_state=42)\ndt_model.fit(X_train_resampled, y_train_resampled)\n\n# 5. Predict on the test set\ny_pred = dt_model.predict(X_test)\n\n# 6. Evaluate the model\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\nprint(classification_report(y_test, y_pred))\n\nAccuracy: 1.0\n              precision    recall  f1-score   support\n\n        High       1.00      1.00      1.00       401\n      Medium       1.00      1.00      1.00        30\n         nan       1.00      1.00      1.00         5\n\n    accuracy                           1.00       436\n   macro avg       1.00      1.00      1.00       436\nweighted avg       1.00      1.00      1.00       436\n\n\n\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import LabelEncoder\n\n\n# Train and evaluate Decision Tree model\ndt_model.fit(X_train, y_train)\ny_pred_dt = dt_model.predict(X_test)\ndt_accuracy = accuracy_score(y_test, y_pred_dt)\nprint(\"Decision Tree Stratified Accuracy:\", dt_accuracy)\nprint(classification_report(y_test, y_pred_dt))\n\n# Train and evaluate Random Forest model\nrf_model.fit(X_train, y_train)\ny_pred_rf = rf_model.predict(X_test)\nrf_accuracy = accuracy_score(y_test, y_pred_rf)\nprint(\"Random Forest Stratified Accuracy:\", rf_accuracy)\nprint(classification_report(y_test, y_pred_rf))\n\nDecision Tree Stratified Accuracy: 1.0\n              precision    recall  f1-score   support\n\n        High       1.00      1.00      1.00       401\n      Medium       1.00      1.00      1.00        30\n         nan       1.00      1.00      1.00         5\n\n    accuracy                           1.00       436\n   macro avg       1.00      1.00      1.00       436\nweighted avg       1.00      1.00      1.00       436\n\nRandom Forest Stratified Accuracy: 1.0\n              precision    recall  f1-score   support\n\n        High       1.00      1.00      1.00       401\n      Medium       1.00      1.00      1.00        30\n         nan       1.00      1.00      1.00         5\n\n    accuracy                           1.00       436\n   macro avg       1.00      1.00      1.00       436\nweighted avg       1.00      1.00      1.00       436"
  },
  {
    "objectID": "projects/Yelp-Restaurant-Rating/yelp-restaurant-ratings-analysis.html",
    "href": "projects/Yelp-Restaurant-Rating/yelp-restaurant-ratings-analysis.html",
    "title": "ğŸ½ï¸ Yelp Restaurant Ratings Analysis",
    "section": "",
    "text": "This project analyzes Yelp restaurant data across California to identify key drivers behind customer ratings and provide actionable insights for small restaurant owners. Using machine learning models and data visualizations, the study reveals how cuisine type, location, and customer feedback influence restaurant success."
  },
  {
    "objectID": "projects/Yelp-Restaurant-Rating/yelp-restaurant-ratings-analysis.html#project-overview",
    "href": "projects/Yelp-Restaurant-Rating/yelp-restaurant-ratings-analysis.html#project-overview",
    "title": "ğŸ½ï¸ Yelp Restaurant Ratings Analysis",
    "section": "",
    "text": "This project analyzes Yelp restaurant data across California to identify key drivers behind customer ratings and provide actionable insights for small restaurant owners. Using machine learning models and data visualizations, the study reveals how cuisine type, location, and customer feedback influence restaurant success."
  },
  {
    "objectID": "projects/Yelp-Restaurant-Rating/yelp-restaurant-ratings-analysis.html#objectives",
    "href": "projects/Yelp-Restaurant-Rating/yelp-restaurant-ratings-analysis.html#objectives",
    "title": "ğŸ½ï¸ Yelp Restaurant Ratings Analysis",
    "section": "ğŸ¯ Objectives",
    "text": "ğŸ¯ Objectives\n\nIdentify popular cuisines and their rating patterns\nUnderstand the impact of location and number of reviews on ratings\nPredict restaurant success using classification models\nSupport small restaurant owners with data-driven strategies"
  },
  {
    "objectID": "projects/Yelp-Restaurant-Rating/yelp-restaurant-ratings-analysis.html#data-methods",
    "href": "projects/Yelp-Restaurant-Rating/yelp-restaurant-ratings-analysis.html#data-methods",
    "title": "ğŸ½ï¸ Yelp Restaurant Ratings Analysis",
    "section": "ğŸ—‚ï¸ Data & Methods",
    "text": "ğŸ—‚ï¸ Data & Methods\n\nData Source: Yelp data scraped via Python (2,177 restaurant entries)\nFeatures: Cuisine type, review count, price range, location (lat/lon), rating\nTools: Python, Pandas, Scikit-learn, Matplotlib\nModels Used: Decision Tree, K-Nearest Neighbor, Random Forest"
  },
  {
    "objectID": "projects/Yelp-Restaurant-Rating/yelp-restaurant-ratings-analysis.html#key-insights",
    "href": "projects/Yelp-Restaurant-Rating/yelp-restaurant-ratings-analysis.html#key-insights",
    "title": "ğŸ½ï¸ Yelp Restaurant Ratings Analysis",
    "section": "ğŸ“Š Key Insights",
    "text": "ğŸ“Š Key Insights\n\nTop Cuisines: Mexican, New American, and Italian are the most popular in California\nMexican Cuisine: Shows wide variability in ratings, indicating inconsistent experiences\nLocation & Review Count Matter: These were the most important predictors in rating performance"
  },
  {
    "objectID": "projects/Yelp-Restaurant-Rating/yelp-restaurant-ratings-analysis.html#model-performance",
    "href": "projects/Yelp-Restaurant-Rating/yelp-restaurant-ratings-analysis.html#model-performance",
    "title": "ğŸ½ï¸ Yelp Restaurant Ratings Analysis",
    "section": "ğŸ¤– Model Performance",
    "text": "ğŸ¤– Model Performance\n\n\n\nModel\nAccuracy\nF1 Score\nPrecision\nRecall\n\n\n\n\nDecision Tree\n61.7%\n0.72\n0.76\n0.69\n\n\nKNN (Tuned)\n64.1%\n0.77\n0.66\n0.93\n\n\nRandom Forest\n71.8%\n0.81\n0.74\n0.89\n\n\n\n\nRandom Forest performed best overall, identifying high-rated restaurants effectively.\nKNN excelled in recall, while Decision Tree had the fewest false positives."
  },
  {
    "objectID": "projects/Yelp-Restaurant-Rating/yelp-restaurant-ratings-analysis.html#business-recommendations",
    "href": "projects/Yelp-Restaurant-Rating/yelp-restaurant-ratings-analysis.html#business-recommendations",
    "title": "ğŸ½ï¸ Yelp Restaurant Ratings Analysis",
    "section": "ğŸ’¼ Business Recommendations",
    "text": "ğŸ’¼ Business Recommendations\n\nLocation Strategy: Choose areas with high traffic or market through social platforms to boost visibility in suburban areas.\nReview Management: Actively solicit and respond to reviews to enhance credibility and ratings.\nQuality Consistency: Standardize food and service quality, especially in cuisines with rating volatility like Mexican."
  },
  {
    "objectID": "projects/Yelp-Restaurant-Rating/yelp-restaurant-ratings-analysis.html#conclusion",
    "href": "projects/Yelp-Restaurant-Rating/yelp-restaurant-ratings-analysis.html#conclusion",
    "title": "ğŸ½ï¸ Yelp Restaurant Ratings Analysis",
    "section": "ğŸ§¾ Conclusion",
    "text": "ğŸ§¾ Conclusion\nThis project highlights how Yelp data can help small restaurants better understand customer behavior and optimize operations. By applying machine learning and analysis techniques, restaurant owners can gain strategic insights into location, cuisine impact, and review managementâ€”ultimately leading to better customer satisfaction and improved performance."
  },
  {
    "objectID": "projects/Yelp-Restaurant-Rating/yelp-restaurant-ratings-analysis.html#github-repository",
    "href": "projects/Yelp-Restaurant-Rating/yelp-restaurant-ratings-analysis.html#github-repository",
    "title": "ğŸ½ï¸ Yelp Restaurant Ratings Analysis",
    "section": "ğŸ“ GitHub Repository",
    "text": "ğŸ“ GitHub Repository\nğŸ‘‰ View Code on GitHub"
  }
]